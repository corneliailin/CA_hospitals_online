{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main script to clean PDD data\n",
    "\n",
    "Modules: N/A <br>\n",
    "Author: Cornelia Ilin <br>\n",
    "Email: cilin@ischool.berkeley.edu <br>\n",
    "Date created: March 28, 2022 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = 'C:/Users/cilin/Research/CA_hospitals/Input/interm_data/health/'\n",
    "in_dir_data_selection = 'C:/Users/cilin/Research/CA_hospitals/Input/raw_data/health/'\n",
    "out_dir = 'C:/Users/cilin/Research/CA_hospitals/Input/final_data/health/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``read data``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    ''''''\n",
    "    df = pd.read_csv(\n",
    "        in_dir + 'PDD.csv'\n",
    "    )\n",
    "    \n",
    "    # add source of data\n",
    "    df['data_source'] = 'PDD'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "preprocessing - add, recode, substitute\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``dates``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dates(df):\n",
    "    ''' Add dates for year, month, day of birth for patient\n",
    "        Add dates for year, month, day of hospital visit for patient\n",
    "    '''\n",
    "    # define dates\n",
    "    dates = ['bthdate', 'admtdate']\n",
    "    \n",
    "    for col in dates:\n",
    "        # transform to string\n",
    "        df[col] = df[col].astype(str)\n",
    "        # make sure date is Pandas compatible\n",
    "        df[col] = pd.to_datetime(df[col], errors = 'coerce')\n",
    "\n",
    "    # define bth variable to be added (year, month, day of birth)\n",
    "    newvars = [['bthyear', 'bthmonth', 'bthday'],\n",
    "              ['admtyear', 'admtmonth', 'admtday']]\n",
    "    \n",
    "    for i in range(len(dates)):\n",
    "        # add bth year\n",
    "        df[newvars[i][0]] = pd.DatetimeIndex(df[dates[i]]).year\n",
    "        # add bth month\n",
    "        df[newvars[i][1]] = pd.DatetimeIndex(df[dates[i]]).month\n",
    "        # add bth date\n",
    "        df[newvars[i][2]] = pd.DatetimeIndex(df[dates[i]]).day\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``zip``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_zip(df):\n",
    "    ''' Recode zip of patient\n",
    "    '''\n",
    "    \n",
    "    # define zipcode variables\n",
    "    zips = ['patzip', 'hplzip']\n",
    "    \n",
    "    for val in zips:\n",
    "        # recode zip as string\n",
    "        df[val] = df[val].astype(str)\n",
    "        \n",
    "        # recode XXXXX, YYYYY, ZZZZZ\n",
    "        df[val] = np.where(df[val].eq('XXXXX'), 'nan',\n",
    "                          np.where(df[val].eq('YYYYY'), 'outside of US',\n",
    "                                  np.where(df[val].eq('ZZZZZ'), 'homeless', df[val])))\n",
    "        \n",
    "        # set zip to 'nan' depending on zip length\n",
    "        df['len_zip'] = df[val].str.len()\n",
    "        df[val] = np.where(df['len_zip'].isin((1, 2, 4, 6)), 'nan', df[val])\n",
    "\n",
    "            \n",
    "        # remove .0 or 0000.0 from zip code if it has any\n",
    "        df[val] = np.where(df['len_zip'].isin((7,11)), df[val].str[:5], df[val])\n",
    "        \n",
    "        # drop len_zip\n",
    "        df.drop(columns=['len_zip'], inplace=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``county``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_county(df):\n",
    "    ''' Recode county of patient\n",
    "    '''\n",
    "\n",
    "    cols = ['patcnty', 'hplcnty']\n",
    "    for col in cols:\n",
    "        # transform to string\n",
    "        df[col] = df[col].astype(str)\n",
    "\n",
    "        # read county code and associated names from the data_selection.xlsx file\n",
    "        cnty_values = pd.read_excel(\n",
    "            in_dir_data_selection + 'data_selection.xlsx',\n",
    "            'County_names', skiprows = 2, header = 0\n",
    "        ).iloc[:,1:3] # select only the first 2 columns\n",
    "\n",
    "        cnty_values = cnty_values.astype(str)\n",
    "        cnty_values['county_code'] = cnty_values.county_code + '.0'\n",
    "\n",
    "        # add county names to df\n",
    "        temp_df = df[[col]].merge(\n",
    "            cnty_values,\n",
    "            left_on=col,\n",
    "            right_on='county_code',\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        # rename county_name\n",
    "        temp_df.rename(\n",
    "            columns={'county_name': col+'_name'},\n",
    "            inplace=True\n",
    "        )\n",
    "\n",
    "        # replace values in col+'_name' depending on val in col or col+'_name'\n",
    "        temp_df[col+'_name'] = np.where(temp_df[col].eq('0.0'), 'unknown/outside CA/homeless',\n",
    "                                  np.where(temp_df[col+'_name'].isna(), 'nan', temp_df[col+'_name']))\n",
    "        \n",
    "        # add col+'_name' to original df\n",
    "        df[col+'_name'] = temp_df[col+'_name']\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``diagnosis codes``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_diagnosis_codes(df):\n",
    "    '''\n",
    "    '''\n",
    "    columns = [\n",
    "        'diag00', 'diag01', 'diag02', 'diag03', 'diag04',\n",
    "        'proc00', 'proc01', 'proc02', 'proc03', 'proc04'\n",
    "    ]\n",
    "\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(str)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``zip geometry``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_zip_geometry(df):\n",
    "    ''' Add zip code geometries\n",
    "    '''\n",
    "\n",
    "    ## read/preprocess geometry ##\n",
    "    ##############################\n",
    "    os.chdir(\"C:/Users/cilin/Research/CA_hospitals/Script/ssn_selection/cleaning/\")\n",
    "    %run \"4. geom_cleaning.ipynb\"\n",
    "    \n",
    "    # drop geometry column\n",
    "    gdf_zcta.drop(\n",
    "        columns='ZCTA10_geometry',\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    ## read/preprocess crosswalk ZIP to ZCTA ##\n",
    "    ###########################################\n",
    "    # read crosswalk\n",
    "    cw= pd.read_csv(\n",
    "        'C:/Users/cilin/Research/CA_hospitals/Input/raw_data/census_geo/ZiptoZcta_Crosswalk_2021.csv'\n",
    "    )\n",
    "\n",
    "    # keep if state is CA\n",
    "    cw = cw[cw.STATE.eq('CA')]\n",
    "\n",
    "    # transform to string\n",
    "    cw['ZIP_CODE'] = cw.ZIP_CODE.astype(str)\n",
    "\n",
    "\n",
    "    ## add geography to ZIP ##\n",
    "    ##########################\n",
    "    # define zip columns\n",
    "    columns = ['patzip', 'hplzip']  # add pat hospital zipcode\n",
    "    for idx, col in enumerate(columns):\n",
    "        print(col)\n",
    "\n",
    "        ## preprocess df ##\n",
    "        ###################\n",
    "        # transform zipI to string    \n",
    "        df[col] = df[col].astype(str)\n",
    "        df[col] = df[col].str.split('.').str[0] # remove .0\n",
    "\n",
    "        # grab P, hP initials\n",
    "        if idx==0:\n",
    "            initial='P'\n",
    "        if idx==1:\n",
    "            initial='hP'\n",
    "\n",
    "        ## read unique ZIP in df \n",
    "        temp_df = pd.DataFrame(\n",
    "            df[col].unique(),\n",
    "            columns=[col]\n",
    "        )\n",
    "\n",
    "\n",
    "        # attach ZCTA10 from gdf_zcta file #\n",
    "        ####################################\n",
    "        temp_df = temp_df.merge(\n",
    "            gdf_zcta[['ZCTA10']], \n",
    "            left_on=col,\n",
    "            right_on='ZCTA10',\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        # attach ZCTA from crosswalk file #\n",
    "        ###################################\n",
    "        temp_df = temp_df.merge(\n",
    "            cw[['ZIP_CODE', 'ZCTA']], \n",
    "            left_on=col,\n",
    "            right_on='ZIP_CODE',\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "\n",
    "        # substitute with ZCTA if ZCTA10 is missing\n",
    "        temp_df['ZCTA10'] = np.where(temp_df.ZCTA10.isna(), temp_df.ZCTA, temp_df.ZCTA10)\n",
    "\n",
    "        # drop duplicates \n",
    "        temp_df.drop_duplicates(\n",
    "            [col],\n",
    "            inplace=True\n",
    "        )\n",
    "\n",
    "\n",
    "        # add in geometry #\n",
    "        ###################\n",
    "        temp_df = temp_df.merge(\n",
    "            gdf_zcta, \n",
    "            on='ZCTA10',\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "\n",
    "        # drop cols that are not of interest\n",
    "        temp_df.drop(\n",
    "            columns=['ZIP_CODE', 'ZCTA'],\n",
    "            inplace=True\n",
    "        )\n",
    "\n",
    "\n",
    "        # merge to original df\n",
    "        temp_df = df[[col]].merge(\n",
    "            temp_df,\n",
    "            on=col,\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "\n",
    "        # rename columns \n",
    "        new_cols = list(temp_df.columns[1:])\n",
    "        for new_col in new_cols:\n",
    "            if len(new_col.split('_'))==1:\n",
    "                temp_name = new_col.split('_')[0]+initial\n",
    "            else:\n",
    "                temp_name = new_col.split('_')[0]+initial+'_'+new_col.split('_')[1]\n",
    "            temp_df.rename(\n",
    "                columns={new_col:temp_name},\n",
    "                inplace=True\n",
    "            )\n",
    "\n",
    "        # drop col\n",
    "        temp_df.drop(columns=[col], inplace=True)\n",
    "\n",
    "        # add temp_df cols to original df\n",
    "        for temp_col in temp_df.columns:\n",
    "            df[temp_col] = temp_df[temp_col]\n",
    "\n",
    "        \n",
    "    # if ZCTA geometry of ZCTA10P is missing subsistiute with that of hospital\n",
    "    colsP = ['ZCTA10P', 'ZCTA10P_centroid']\n",
    "    colshP = ['ZCTA10hP', 'ZCTA10hP_centroid']\n",
    "    \n",
    "    for idx3, colP in enumerate(colsP):\n",
    "        df[colP] = np.where(df[colP].isna(), df[colshP[idx3]], df[colP])\n",
    "        \n",
    "    return df      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``keys``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_keys(df):\n",
    "    ''''''\n",
    "    # making sure all vars are strings and strip .0\n",
    "    for col in ['admtyear', 'admtmonth', 'ZCTA10P', 'patcnty']:\n",
    "        df[col] = df[col].astype(str).str.split('.').str[0]\n",
    "    \n",
    "    # create admtyear_ZCTA10P\n",
    "    df['admtyear_ZCTA10P'] = df.admtyear + '_' + df.ZCTA10P\n",
    "    \n",
    "    # create admtyear_patcnty\n",
    "    df['admtyear_patcnty'] = df.admtyear + '_' + df.patcnty\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "preprocessing - drop\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``bthdate ge(1991) only``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bthdate_ge1991_only(df):\n",
    "    '''\n",
    "    '''\n",
    "    # keep only if bthyear >=1991\n",
    "    mini_df = df[df.bthyear.ge(1991.)]\n",
    "\n",
    "    # reset index\n",
    "    mini_df.reset_index(\n",
    "        drop=True,\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    return mini_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``cols of interest``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_cols_of_interest(mini_df):\n",
    "    '''\n",
    "    '''\n",
    "    cols = [\n",
    "        'pat_id', 'rln',\n",
    "        'patzip', 'ZCTA10P',\n",
    "        'patcnty', 'patcnty_name',\n",
    "        'hplzip', 'ZCTA10hP',\n",
    "        'hplcnty', 'hplcnty_name',\n",
    "        'bthdate', 'bthyear', 'bthmonth', 'bthday',\n",
    "        'admtdate', 'admtyear', 'admtmonth', 'admtday',\n",
    "        'admtyear_ZCTA10P', 'admtyear_patcnty', \n",
    "        'charge', \n",
    "        'diag00', 'diag01', 'diag02', 'diag03', 'diag04',\n",
    "        'proc00', 'proc01', 'proc02', 'proc03', 'proc04',\n",
    "        'data_source'\n",
    "    ]\n",
    "\n",
    "    return mini_df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data()\n",
    "print('Shape of data:', df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Data preprocessing - add, recode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``dates``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dates\n",
    "df = add_dates(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``zip``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = recode_zip(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``county``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = recode_county(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``diagnosis codes``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = recode_diagnosis_codes(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``zip geometry``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_zip_geometry(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``add keys for merging or FE``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_keys(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'Shape of data after Step 5: \"Data preprocessing - add, recode\":',\n",
    "    df.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 6: Data preprocessing - drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``birthyear ge(1991) only``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_df = bthdate_ge1991_only(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'Shape of data after Step 6: \"Data preprocessing - drop\":',\n",
    "    mini_df.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols_of_interest(mini_df).to_csv(out_dir + 'PDD_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:pink\">[IMPORTANT: still need to deal with payment category and admission source variables, etc]</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
