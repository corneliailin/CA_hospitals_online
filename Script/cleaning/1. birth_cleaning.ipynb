{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main script to clean Birth data\n",
    "\n",
    "Modules: N/A <br>\n",
    "Author: Cornelia Ilin <br>\n",
    "Email: cilin@ischool.berkeley.edu <br>\n",
    "Date created: March 28, 2022 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Define working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = 'C:/Users/cilin/Research/CA_hospitals/Input/interm_data/health/'\n",
    "in_dir_data_selection = 'C:/Users/cilin/Research/CA_hospitals/Input/raw_data/health/'\n",
    "out_dir = 'C:/Users/cilin/Research/CA_hospitals/Input/final_data/health/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``read data``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    ''''''\n",
    "    df = pd.read_csv(\n",
    "        in_dir + 'Birth.csv'\n",
    "    )\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "preprocessing - add, recode, substitute\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``dates``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_dates(df):\n",
    "    ''' Recode birth and admission dates (transform from SAS format to Pandas)\n",
    "    '''\n",
    "    # define dates\n",
    "    dates = ['bthdate', 'bthdateI', \n",
    "             'mbthdate', 'bthdateM',\n",
    "             'fbthdate',\n",
    "             'admdateI', 'admdateM']\n",
    "    \n",
    "    for i in range(len(dates)):\n",
    "        df[dates[i]] = pd.to_timedelta(df[dates[i]], unit = 'D') + pd.Timestamp('1960-1-1')\n",
    "        \n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_missing_dates(df):\n",
    "    ''' Substitute missing date values in hospital data with values in vital stats data\n",
    "    '''\n",
    "    # substitute birthdate of infant (bthdate is from vital stats data, bthdateI is from hospital data)\n",
    "    df['bthdateI'] = np.where(df.bthdateI.isna(), df.bthdate, df.bthdateI)\n",
    "    \n",
    "    # subsitute birth date of mother (mbthdate is from vital stats data, bthdateM is from hospital data)\n",
    "    df['bthdateM'] = np.where(df.bthdateM.isna(), df.mbthdate, df.bthdateM)\n",
    "    \n",
    "    # drop vars\n",
    "    df.drop(columns=['bthdate', 'mbthdate'], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dates(df):\n",
    "    ''' Add dates for year, month, day of birth for infant, mother, father\n",
    "    '''\n",
    "    # define dates\n",
    "    dates = ['bthdateI', 'bthdateM', 'fbthdate',\n",
    "             'admdateI', 'admdateM']\n",
    "    \n",
    "    # define bth variable to be added (year, month, day of birth)\n",
    "    newvars = [['bthyearI', 'bthmonthI', 'bthdayI'],\n",
    "              ['bthyearM', 'bthmonthM', 'bthdayM'],\n",
    "              ['fbthyear', 'fbthmonth', 'fbthday'],\n",
    "              ['admyearI', 'admmonthI', 'admdayI'],\n",
    "              ['admyearM', 'admmonthM', 'admdayM']]\n",
    "        \n",
    "    for i in range(len(dates)):\n",
    "        # add bth year\n",
    "        df[newvars[i][0]] = pd.DatetimeIndex(df[dates[i]]).year\n",
    "        # add bth month\n",
    "        df[newvars[i][1]] = pd.DatetimeIndex(df[dates[i]]).month\n",
    "        # add bth date\n",
    "        df[newvars[i][2]] = pd.DatetimeIndex(df[dates[i]]).day\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``sex``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_missing_sex(df):\n",
    "    ''' Substitute missing sex values in hospital data with values in vital stats data \n",
    "    '''\n",
    "    # transform to string (nbsex is from vital stats data, sexI is from hospital data))\n",
    "    df['nbsex'] = df.nbsex.astype(str)\n",
    "    df['sexI'] = df.sexI.astype(str)\n",
    "    \n",
    "    # substitute missing sexI with nbsex\n",
    "    df['sexI'] = np.where(df.sexI.isin(('nan', '0.0', '3.0', '4.0')), df.nbsex, df.sexI)\n",
    "\n",
    "    # nbsex has a label 9 = Undetermined, replace with nan\n",
    "    df['sexI'] = np.where(df.sexI.eq('9.0'), 'nan', df.sexI)\n",
    "    \n",
    "    # drop nbsex\n",
    "    df.drop(columns=['nbsex'], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_sex(df):\n",
    "    ''' Recode sex variables\n",
    "    '''\n",
    "    # 1 = Male, 2 = Female\n",
    "    df['sexI'] = np.where(df.sexI.eq('1.0'), 'M',\n",
    "                          np.where(df.sexI.eq('2.0'), 'F', 'nan'))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``race``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_race(df):\n",
    "    ''' Recode race\n",
    "    '''\n",
    "    # transform race vars to string\n",
    "    variables = [\n",
    "        'raceh83I', 'raceh95I', 'nbrace',\n",
    "        'raceh83M', 'raceh95M', 'mrace',\n",
    "        'frace'\n",
    "    ]\n",
    "\n",
    "    for var in variables:\n",
    "        df[var] = df[var].astype(str)\n",
    "\n",
    "    # recode raceh83I to match raceh85I; do the same for raceh83M and raceh95M\n",
    "    df['raceh83I'] = np.where(df.raceh83I == '1.0', 'white',\n",
    "                                    np.where(df.raceh83I == '2.0', 'black', \n",
    "                                            np.where(df.raceh83I == '3.0', 'hisp', \n",
    "                                                    np.where(df.raceh83I == '4.0', 'native american/eskimo/aleut',\n",
    "                                                            np.where(df.raceh83I == '5.0', 'asian/pacific islander', \n",
    "                                                                    np.where(df.raceh83I == '6.0', 'other',\n",
    "                                                                        np.where(df.raceh83I =='7.0', 'unknown',\n",
    "                                                                            np.where(df.raceh83I == '0.0', 'unknown', df.raceh83I))))))))\n",
    "\n",
    "    df['raceh95I'] = np.where(df.raceh95I == '1.0', 'white',\n",
    "                                    np.where(df.raceh95I == '2.0', 'black', \n",
    "                                            np.where(df.raceh95I == '3.0', 'native american/eskimo/aleut', \n",
    "                                                    np.where(df.raceh95I == '4.0', 'asian/pacific islander',\n",
    "                                                            np.where(df.raceh95I == '5.0', 'other', \n",
    "                                                                    np.where(df.raceh95I == '6.0', 'unknown',\n",
    "                                                                            np.where(df.raceh95I == '0.0', 'unknown', df.raceh95I)))))))\n",
    "    \n",
    "    # recode race83I, race83M\n",
    "    race83 = ['raceh83I', 'raceh83M']\n",
    "    for val in race83:\n",
    "        df[val] = np.where(df[val] == '1.0', 'white',\n",
    "                                        np.where(df[val] == '2.0', 'black', \n",
    "                                                np.where(df[val] == '3.0', 'hisp', \n",
    "                                                        np.where(df[val]== '4.0', 'native american/eskimo/aleut',\n",
    "                                                                np.where(df[val] == '5.0', 'asian/pacific islander', \n",
    "                                                                        np.where(df[val] == '6.0', 'other',\n",
    "                                                                            np.where(df[val].isin(('0.0', '7.0')), 'unknown', df[val])))))))\n",
    "    # recode race95I, race95M\n",
    "    race95 = ['raceh95I', 'raceh95M']\n",
    "    for val in race95:\n",
    "        df[val] = np.where(df[val] == '1.0', 'white',\n",
    "                                        np.where(df[val] == '2.0', 'black', \n",
    "                                                np.where(df[val] == '3.0', 'native american/eskimo/aleut', \n",
    "                                                        np.where(df[val] == '4.0', 'asian/pacific islander',\n",
    "                                                                np.where(df[val] == '5.0', 'other', \n",
    "                                                                        np.where(df[val].isin(('0.0','6.0', '7.0')), 'unknown', df[val]))))))\n",
    "\n",
    "    # recode raceh83I, raceh95I, raceh83M, raceh95M as only two variables raceI, raceM\n",
    "    race = ['raceI', 'raceM']\n",
    "    for i, val in enumerate(race):\n",
    "        df[val] = np.where(df[race83[i]] == 'nan', df[race95[i]], df[race83[i]])\n",
    "\n",
    "    # recode nbrace, mrace, frace (these are from vital stats)\n",
    "    races_vs = ['nbrace', 'mrace', 'frace']\n",
    "    for val in races_vs:\n",
    "        df[val] = np.where(df[val] == '10.0', 'white',\n",
    "                          np.where(df[val] == '20.0', 'black',\n",
    "                                  np.where(df[val].isin(('30.0',  '57.0', '58.0')), 'native american/eskimo/aleut',\n",
    "                                          np.where(df[val].isin(('40.0', '41.0', '42.0', '43.0', '44.0', '45.0', '46.0', '47.0', '48.0','52.0','59.0')), 'asian/pacific islander',\n",
    "                                                  np.where(df[val].isin(('51.0', '53.0', '54.0', '55.0', '56.0')), 'other',\n",
    "                                                          np.where(df[val].isin(('9.0', '19.0', '49.0', '98.0', '99.0')), 'unknown', df[val]))))))\n",
    "        \n",
    "    # drop 83 and 95 race vars\n",
    "    df.drop(\n",
    "        columns=['raceh83I', 'raceh83M', 'raceh95I', 'raceh95M'],\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_missing_race(df):\n",
    "    '''Substitute missing race values in hospital data with values in vital stats data\n",
    "    '''\n",
    "    # substitute infant race\n",
    "    df['raceI'] = np.where(df.raceI.isin(('nan', 'unknown')), df.nbrace, df.raceI)\n",
    "    \n",
    "    # substitute mother race\n",
    "    df['raceM'] = np.where(df.raceM.isin(('nan', 'unknown')), df.mrace, df.raceM)\n",
    "    \n",
    "    # drop nbrace and mrace\n",
    "    df.drop(\n",
    "        columns=['nbrace', 'mrace'],\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``education``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_educ(df):\n",
    "    '''\n",
    "    '''\n",
    "    variables = ['meduc', 'feduc', 'meduc06', 'feduc06']\n",
    "    for var in variables:\n",
    "        # transform var to string\n",
    "        df[var] = df[var].astype(str)\n",
    "\n",
    "    # modify string values for feduc\n",
    "    df['feduc'] = np.where(df.feduc.isin(('00', '01', '02', '03', '04', '05', '06', '07', '08', '09')), df.feduc.str[1:]+'.0',\n",
    "                           np.where(df.feduc.isin(('10', '11', '12', '13', '14', '15', '16', '17', '99')), df.feduc+'.0',\n",
    "                                   np.where(df.feduc.isin(('61', '69', 'CO', 'NI')), '99.0', df.feduc)))    \n",
    "    \n",
    "    \n",
    "    # encode education before 2006\n",
    "    educ_b_06 = ['meduc', 'feduc']\n",
    "    for var in educ_b_06:\n",
    "        df[var] = np.where(df[var].isin(('0.0', '1.0', '2.0', '3.0',\n",
    "                                                '4.0', '5.0', '6.0', '7.0',\n",
    "                                                '8.0', '9.0', '10.0', '11.0', '12.0')), 'high school or less',\n",
    "                                  np.where(df[var].isin(('13.0', '14.0', '15.0')), 'college (1-3 years)', \n",
    "                                          np.where(df[var] == '16.0', 'college (4 years)',\n",
    "                                                  np.where(df[var] == '17.0', 'masters or phd',\n",
    "                                                        np.where(df[var].isin(('0.0', '18.0', '19.0', '24.0','99.0')), 'unknown or other', df[var])))))\n",
    "\n",
    "        \n",
    "    # encode education after 2006\n",
    "    educ06 = ['meduc06', 'feduc06']\n",
    "    for var in educ06:\n",
    "        df[var] = np.where(df[var].isin(('1.0', '2.0', '3.0')), 'high school or less',\n",
    "                                  np.where(df[var].isin(('4.0', '5.0')), 'college (1-3 years)', \n",
    "                                          np.where(df[var] == '6.0', 'college (4 years)',\n",
    "                                                  np.where(df[var].isin(('7.0', '8.0')), 'masters or phd',\n",
    "                                                        np.where(df[var].isin(('0.0', '9.0')), 'unknown or other', df[var])))))\n",
    "\n",
    "        \n",
    "    # recode meduc, meduc06, feduc, feduc06 as meduc, feduc\n",
    "    educ = ['meduc', 'feduc']\n",
    "    for i, val in enumerate(educ):\n",
    "        df[val] = np.where(df[educ_b_06[i]] == 'nan', df[educ06[i]], df[educ_b_06[i]])\n",
    "        \n",
    "    \n",
    "    # drop meduc06 and feduc06\n",
    "    df.drop(\n",
    "        columns=['meduc06', 'feduc06'],\n",
    "        inplace=True\n",
    "    )\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``zip``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_zip(df):\n",
    "    ''' For infant and mother: Recode zip at birth\n",
    "    '''\n",
    "    \n",
    "    # define zipcode variables\n",
    "    zips = ['hplzipI', 'hplzipM', 'zipI', 'zipM', 'zipresm']\n",
    "    \n",
    "    for val in zips:\n",
    "        # recode zip as string\n",
    "        df[val] = df[val].astype(str)\n",
    "        \n",
    "        # recode XXXXX, YYYYY, ZZZZZ\n",
    "        df[val] = np.where(df[val].eq('XXXXX'), 'nan',\n",
    "                          np.where(df[val].eq('YYYYY'), 'outside of US',\n",
    "                                  np.where(df[val].eq('ZZZZZ'), 'homeless', df[val])))\n",
    "        \n",
    "        # set zip to 'nan' depending on zip length\n",
    "        df['len_zip'] = df[val].str.len()\n",
    "        df[val] = np.where(df['len_zip'].isin((1, 2, 4, 6)), 'nan', df[val])\n",
    "        \n",
    "        if val=='zipres':\n",
    "            df[val] = np.where(df['len_zip'].eq(5), 'nan', df[val])\n",
    "            \n",
    "        # remove .0 or 0000.0 from zip code if it has any\n",
    "        df[val] = np.where(df['len_zip'].isin((7,11)), df[val].str[:5], df[val])\n",
    "        \n",
    "        # drop len_zip\n",
    "        df.drop(columns=['len_zip'], inplace=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_missing_zip(df):\n",
    "    ''' For mother only: substitute missing zip residence values in hospital data with values in vital stats data (this information is only available for mother)\n",
    "        For infant only: substitute missing zipI with zipM, hplzipI, hplzipM -> in this order\n",
    "    '''\n",
    "    df['zipM'] = np.where(df.zipM.eq('nan'), df.zipresm, df.zipM)\n",
    "    \n",
    "    columns = ['zipM', 'hplzipI', 'hplzipM']\n",
    "    for col in columns:\n",
    "        df['zipI'] = np.where(df.zipI.eq('nan'), df[col], df.zipI)\n",
    "    \n",
    "    # drop zipresm\n",
    "    df.drop(columns=['zipresm'], inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``county``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_county(df):\n",
    "    ''' For infant and mother: Recode county at birth\n",
    "    '''\n",
    "\n",
    "    cols = ['cntyresI', 'cntyresM', 'hplcntyI', 'hplcntyM']\n",
    "    for col in cols:\n",
    "        # transform to string\n",
    "        df[col] = df[col].astype(str)\n",
    "\n",
    "        # read county code and associated names from the data_selection.xlsx file\n",
    "        cnty_values = pd.read_excel(\n",
    "            in_dir_data_selection + 'data_selection.xlsx',\n",
    "            'County_names', skiprows = 2, header = 0\n",
    "        ).iloc[:,1:3] # select only the first 2 columns\n",
    "\n",
    "        cnty_values = cnty_values.astype(str)\n",
    "        cnty_values['county_code'] = cnty_values.county_code + '.0'\n",
    "\n",
    "        # add county names to df\n",
    "        temp_df = df[[col]].merge(\n",
    "            cnty_values,\n",
    "            left_on=col,\n",
    "            right_on='county_code',\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        # rename county_name\n",
    "        temp_df.rename(\n",
    "            columns={'county_name': col+'_name'},\n",
    "            inplace=True\n",
    "        )\n",
    "\n",
    "        # replace values in col+'_name' depending on val in col or col+'_name'\n",
    "        temp_df[col+'_name'] = np.where(temp_df[col].eq('0.0'), 'unknown/outside CA/homeless',\n",
    "                                  np.where(temp_df[col+'_name'].isna(), 'nan', temp_df[col+'_name']))\n",
    "        \n",
    "        # add col+'_name' to original df\n",
    "        df[col+'_name'] = temp_df[col+'_name']\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``state``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_state_m(df):\n",
    "    ''' For mother only: Recode state at birth\n",
    "    '''\n",
    "    # transform to string\n",
    "    df['matresst'] = df.matresst.astype(str)\n",
    "\n",
    "    # read state code and associate names from the data_selection.xlsx file\n",
    "    st_values = pd.read_excel(\n",
    "        in_dir_data_selection + 'data_selection.xlsx',\n",
    "        'State_names', skiprows = 2, header = 0\n",
    "    )\n",
    "    st_values = st_values.astype(str)\n",
    "\n",
    "    # substitute state names for matresst coding\n",
    "    temp_df = df[['matresst']].merge(\n",
    "        st_values,\n",
    "        left_on=['matresst'],\n",
    "        right_on=['state_code'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # code 98.0 doesn't exist in data_selection.xlsx\n",
    "    temp_df['state_name'] = np.where(\n",
    "        temp_df.matresst.eq('98.0'), 'Unknown Nativity', temp_df.state_name\n",
    "    )\n",
    "\n",
    "    df['matresst_name'] = temp_df.state_name\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_state_mob(df):\n",
    "    ''' For mother only: Recode state/country at mother's own birth\n",
    "    '''\n",
    "    ##############\n",
    "    ## bthresmb ##\n",
    "    ##############\n",
    "    df['bthresmb'] = df.bthresmb.astype(str)\n",
    "    # read state abbreviation and name from data_selection.xlsx file\n",
    "    state_values = pd.read_excel(\n",
    "        in_dir_data_selection + 'data_selection.xlsx',\n",
    "        'State_names', skiprows = 2, header = 0\n",
    "    ).iloc[:,4:6] # read only cols 4 and 5\n",
    "    state_values = state_values.astype(str)  \n",
    "\n",
    "\n",
    "    # rename columns\n",
    "    state_values.rename(\n",
    "        columns={'state_code2': 'code',\n",
    "                 'state_name2': 'name'}, inplace=True)\n",
    "\n",
    "    # add country/state name to bthresmb\n",
    "    temp_df = df[['bthresmb']].merge(\n",
    "        state_values,\n",
    "        left_on='bthresmb',\n",
    "        right_on='code',\n",
    "        how='left'\n",
    "    )\n",
    "    temp_df['name'] = np.where(temp_df.name.isna(), 'nan', temp_df.name)\n",
    "\n",
    "    temp_df.rename(\n",
    "        columns={'name':'bthresmb_name'}, inplace=True\n",
    "    )\n",
    "    temp_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # add bthresmb_name to df\n",
    "    df['bthresmb_name'] = temp_df.bthresmb_name\n",
    "    \n",
    "    ################\n",
    "    ## bthresmb06 ##\n",
    "    ################\n",
    "    df['bthresmb06'] = df.bthresmb06.astype(str)\n",
    "    # read state abbreviation and name from data_selection.xlsx file\n",
    "    state_values = pd.read_excel(\n",
    "        in_dir_data_selection + 'data_selection.xlsx',\n",
    "        'State_names', skiprows = 2, header = 0\n",
    "    ).iloc[:,7:9] # read only cols 7 and 8\n",
    "    state_values = state_values.astype(str)    \n",
    "    state_values['state_code3'] = state_values.state_code3.str.split('.').str[0] # remove .0\n",
    "    state_values['state_name3'] = state_values.state_name3.str.lstrip() # remove leading white spaces\n",
    "    \n",
    "    # read country/state marc codes\n",
    "    country_values_marc = pd.read_excel(\n",
    "        in_dir_data_selection + 'data_selection.xlsx',\n",
    "        'Country_names', skiprows = 2, header = 0\n",
    "    ).iloc[:,[8,9]]\n",
    "    country_values_marc = country_values_marc.astype(str)\n",
    "\n",
    "\n",
    "    # rename columns in state_/country_values\n",
    "    state_values.rename(\n",
    "        columns={'state_code3': 'code',\n",
    "                 'state_name3': 'name'}, inplace=True)\n",
    "\n",
    "    country_values_marc.rename(\n",
    "        columns={'MARC': 'code',\n",
    "            'Country': 'name'},inplace=True)\n",
    "\n",
    "    # concatenate state_/country_values\n",
    "    sc_values = pd.concat(\n",
    "        [state_values, country_values_marc],\n",
    "        axis=0\n",
    "    )\n",
    "\n",
    "    # clean sc_values\n",
    "    sc_values = sc_values.astype(str)\n",
    "    sc_values = sc_values[~sc_values.code.eq('nan')]\n",
    "    sc_values['name'] = sc_values.name.str.replace('\\xa0', ' ')\n",
    "    sc_values.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "    # add country/state name to bthresmb06\n",
    "    temp_df = df[['bthresmb06']].merge(\n",
    "        sc_values,\n",
    "        left_on='bthresmb06',\n",
    "        right_on='code',\n",
    "        how='left'\n",
    "    )\n",
    "    temp_df['name'] = np.where(temp_df.name.isna(), 'nan', temp_df.name)\n",
    "\n",
    "    temp_df.rename(\n",
    "        columns={'name':'bthresmb06_name'}, inplace=True\n",
    "    )\n",
    "    temp_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # add bthresmb06_name to df\n",
    "    df['bthresmb06_name'] = temp_df.bthresmb06_name\n",
    "\n",
    "    \n",
    "    # set difference (names after 2006 that didn't exist before)\n",
    "    set_diff = np.setdiff1d(df.bthresmb06_name.unique(), df.bthresmb_name.unique())\n",
    "    df['bthresmb06_limited'] = np.where(df.bthresmb06_name.isin(set_diff), 'RE', df.bthresmb06)\n",
    "    df['bthresmb06_limited_name'] = np.where(df.bthresmb06_name.isin(set_diff), 'Reminder of the World', df.bthresmb06_name)\n",
    "    \n",
    "    # combine bthresmb, bthresmb_name, bthresmb06_limited, bthresmb06_limited_name\n",
    "    df['bthresmb'] = np.where(df.bthresmb.eq('nan'), df.bthresmb06_limited, df.bthresmb)\n",
    "    df['bthresmb_name'] = np.where(df.bthresmb_name.eq('nan'), df.bthresmb06_limited_name, df.bthresmb_name)\n",
    "\n",
    "    df.drop(\n",
    "        columns=['bthresmb06_limited', 'bthresmb06_limited_name'],\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``caesar``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_caesar(df):\n",
    "    '''\n",
    "    '''\n",
    "    # define columns\n",
    "    columns = ['caesar', 'caesar05']\n",
    "    for val in columns:\n",
    "        # transform cols to string\n",
    "        df[val] = df[val].astype(str)\n",
    "        # remove .0 from string\n",
    "        df[val] = df[val].str.split('.').str[0]\n",
    "        \n",
    "    ## caesar ##\n",
    "    ############\n",
    "    df['caesar_name'] = np.where(df.caesar.eq('1'), 'C-section, Primary',\n",
    "                           np.where(df.caesar.eq('2'), 'C-section, Repeat',\n",
    "                                   np.where(df.caesar.eq('3'), 'Vaginal, Spontaneous',\n",
    "                                           np.where(df.caesar.isin(('34', '43')), 'Vaginal, Spontenous after prev. C-section',\n",
    "                                                   np.where(df.caesar.eq('5'), 'Vaginal, Forceps',\n",
    "                                                           np.where(df.caesar.isin(('54','45')), 'Vaginal, Forceps after prev. C-section',\n",
    "                                                                   np.where(df.caesar.eq('6'), 'Vaginal, Vacuum',\n",
    "                                                                           np.where(df.caesar.isin(('64', '46')), 'Vaginal, Vacuum after prev. C-section',\n",
    "                                                                                   np.where(df.caesar.isin(('56', '65', '456', '465', '546', '564', '654')), 'Others', 'nan')))))))))\n",
    "    \n",
    "    ## caesar05 ##\n",
    "    ##############\n",
    "    df['caesar05_name'] = np.where(df.caesar05.isin(('1', '11', '21', '31')), 'C-section, Primary',\n",
    "                           np.where(df.caesar05.isin(('2', '12', '22', '32')), 'C-section, Repeat',\n",
    "                                   np.where(df.caesar05.eq('3'), 'Vaginal, Spontaneous',\n",
    "                                           np.where(df.caesar05.eq('4'), 'Vaginal, Spontenous after prev. C-section',\n",
    "                                                   np.where(df.caesar05.eq('5'), 'Vaginal, Forceps',\n",
    "                                                           np.where(df.caesar05.eq('15'), 'Vaginal, Forceps after prev. C-section',\n",
    "                                                                   np.where(df.caesar05.eq('6'), 'Vaginal, Vacuum',\n",
    "                                                                           np.where(df.caesar05.eq('16'), 'Vaginal, Vacuum after prev. C-section',\n",
    "                                                                                    np.where(df.caesar05.isin(('88', '99')), 'Others', 'nan')))))))))\n",
    "    \n",
    "    # add caesar05 and caesar05_name to caesar and caesar_name\n",
    "    df['caesar'] = np.where(df.caesar.eq('na'), df.caesar05, df.caesar)\n",
    "    df['caesar_name'] = np.where(df.caesar_name.eq('na'), df.caesar05_name, df.caesar_name)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``complications``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_probl(df):\n",
    "    ''' Recode complications during and before pregnancy, during labor, and complications with the newborn\n",
    "    '''\n",
    "    # probl_1: Complications pregnancy/concurrent illnesses\n",
    "    # probl_2: Complications labor/delivery \n",
    "    # probl_3: Complications newborn (Abnormal Conditions/Clinical Procedures)\n",
    "    columns = ['probl_1', 'probl_2', 'probl_3']\n",
    "\n",
    "    for col in columns:\n",
    "        # transform column to string\n",
    "        df[col] = df[col].astype(str)\n",
    "\n",
    "        # drop .0\n",
    "        df[col] = df[col].str.split('.').str[0]\n",
    "\n",
    "        # measure length\n",
    "        df[col+'_len'] = df[col].str.len()\n",
    "\n",
    "        # measure mode\n",
    "        df[col+'_len_mode'] = np.mod(df[col+'_len'], 2)\n",
    "\n",
    "        # add 0 if mode is odd (i.e., number is not divisible by 2)\n",
    "        df[col] = np.where(df[col+'_len'].eq(0), 'nan',\n",
    "                          np.where(df[col+'_len_mode'].eq(1), str(0)+ df[col], df[col]))\n",
    "\n",
    "        # replace if col == 0nan\n",
    "        df[col] = np.where(df[col].eq('0nan'), 'nan', df[col])\n",
    "\n",
    "        # split each string into 2 charcaters and form a list\n",
    "        df[col+'_list'] = df[col].str.findall('..')\n",
    "\n",
    "        # drop cols\n",
    "        df.drop(\n",
    "            columns=[col+'_len', col+'_len_mode'],\n",
    "            inplace=True\n",
    "        )\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``pregnancy precare``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_precare(df):\n",
    "    ''' Recode prenatal care\n",
    "    '''\n",
    "    variables = ['precare', 'prevsts']\n",
    "    for var in variables:\n",
    "        # transform to string\n",
    "        df[var] = df[var].astype(str)\n",
    "        # remove .0 from string\n",
    "        df[var] = df[var].str.split('.').str[0]\n",
    "    \n",
    "    ## month prenatal care bagan ##\n",
    "    ###############################\n",
    "    df['precare_name'] = np.where(df.precare.eq('0'), 'no precare',\n",
    "                                  np.where(df.precare.eq('-'), 'unknown or not reported',\n",
    "                                          np.where(df.precare.eq('nan'), 'nan', 'began in '+ df.precare+'th month of pregnancy')))\n",
    "    \n",
    "    ## number of prenatal care visits ##\n",
    "    ####################################\n",
    "    df['prevsts_name'] = np.where(df.prevsts.eq('0'), 'no precare visits',\n",
    "                                 np.where(df.prevsts.eq('99'), 'unknown or not reported', \n",
    "                                         np.where(df.prevsts.eq('nan'), 'nan', df.prevsts+' precare visits')))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``previous births``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_prev_births(df):\n",
    "    '''\n",
    "    '''\n",
    "    variables = ['prevlbl', 'prevlbd', 'llbmths', 'term_a20wks', 'term_b20wks', 'cebl', 'ceb']\n",
    "    for col in variables:\n",
    "        # transform to string\n",
    "        df[col] = df[col].astype(str)\n",
    "        # remove .0 from string\n",
    "        df[col] = df[col].str.split('.').str[0]\n",
    "\n",
    "    ## previous live births now alive ##\n",
    "    ####################################\n",
    "    # does not include current birth\n",
    "    df['prevlbl_name'] = np.where(df.prevlbl.eq('0'), 'no previous births',\n",
    "                                  np.where(df.prevlbl.isin(('98', '99')), 'unknown or not reported',\n",
    "                                          np.where(df.prevlbl.eq('nan'), 'nan', df.prevlbl+' previous live births now alive')))\n",
    "    \n",
    "    # includes current birth\n",
    "    df['cebl_name'] = np.where(df.cebl.eq('0'), 'no previous birth incl. current birth',\n",
    "                               np.where(df.cebl.isin(('98', '99')), 'unknown or not reported',\n",
    "                                        np.where(df.cebl.eq('nan'), 'nan', df.cebl+ ' children ever born alive, incl.current birth')))\n",
    "                                        \n",
    "    ## previous live births and pregnancy terminations > 20 weeks gestation ##\n",
    "    ##########################################################################\n",
    "    df['ceb_name'] = np.where(df.ceb.eq('0'), 'no previous birth incl. current birth',\n",
    "                               np.where(df.ceb.isin(('98', '99')), 'unknown or not reported',\n",
    "                                        np.where(df.ceb.eq('nan'), 'nan', df.ceb+ ' children ever born alive + pregnancy term > 20 weeks')))\n",
    "                                        \n",
    "                               \n",
    "\n",
    "    ## previous live births now dead ##\n",
    "    ###################################\n",
    "    # does not include current birth\n",
    "    df['prevlbd_name'] = np.where(df.prevlbd.eq('0'), 'no previous births',\n",
    "                                 np.where(df.prevlbd.isin(('98','99')), 'unknown or not reported', \n",
    "                                         np.where(df.prevlbd.eq('nan'), 'nan', df.prevlbd+' previous live births now dead')))\n",
    "    \n",
    "    ## months since last live birth ##\n",
    "    ##################################\n",
    "    \n",
    "    ## Pregnancy terminations > 20wks or < 20wks gestation ##\n",
    "    #########################################################\n",
    "    for col in ['term_a20wks', 'term_b20wks']:\n",
    "        df[col+'_name'] = np.where(df[col].eq('0'), 'no previous pregnancy terminations',\n",
    "                                       np.where(df[col].eq('nan'), 'nan',\n",
    "                                               np.where(df[col].isin(('98', '99')), 'unknown or not reported', df[col] + 'previous preganancy terminations')))\n",
    "        \n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``gestation length``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_gest_days(df):\n",
    "    ''' Calculated by subtracting the date of last normal menses from the date of birth\n",
    "    '''\n",
    "    variables = ['gest_days']\n",
    "    for var in variables:\n",
    "        # transform to string\n",
    "        df[var] = df[var].astype(str)\n",
    "        # remove .0 from string\n",
    "        df[var] = df[var].str.split('.').str[0]\n",
    "\n",
    "    ## previous live births now alive ##\n",
    "    ####################################\n",
    "    # does not include current birth\n",
    "    df['gest_days_name'] = np.where(df.gest_days.eq('999'), 'unknown or not reported',\n",
    "                                          np.where(df.gest_days.eq('nan'), 'nan', df.gest_days+' days of gestation'))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``admission source``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_admission_src(df):\n",
    "    '''\n",
    "    '''\n",
    "    variables = ['admsrc83I', 'admsrc83M', 'admsrc953I', 'admsrc953M']\n",
    "    for col in variables:\n",
    "        # transform to string\n",
    "        df[col] = df[col].astype(str)\n",
    "        # remove .0 from string\n",
    "        df[col] = df[col].str.split('.').str[0]\n",
    "        \n",
    "    ## admission source ##\n",
    "    ######################\n",
    "    df['admsrcI'] = np.where((df.admsrc83I.eq('12') | (df.admsrc952I.eq('1') & df.admsrc953I.eq('1'))), 'ER', 'other')\n",
    "    df['admsrcM'] = np.where((df.admsrc83M.eq('12') | (df.admsrc952M.eq('1') & df.admsrc953M.eq('1'))), 'ER', 'other')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``diagnosis codes``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_diagnosis_codes(df):\n",
    "    '''\n",
    "    '''\n",
    "    columns = [\n",
    "        'diagM00',\t'diagM01',\t'diagM02',\t'diagM03',\t'diagM04',\n",
    "        'proc_edasM00',\t'proc_edasM01',\t'proc_edasM02',\t'proc_edasM03',\t'proc_edasM04',\n",
    "        'procM00', 'procM01',\t'procM02',\t'procM03',\t'procM04',\n",
    "        'diagI00',\t'diagI01',\t'diagI02',\t'diagI03',\t'diagI04',\n",
    "        'proc_edasI00',\t'proc_edasI01',\t'proc_edasI02',\t'proc_edasI03',\t'proc_edasI04',\n",
    "        'procI00',\t'procI01',\t'procI02',\t'procI03',\t'procI04'\n",
    "    ]\n",
    "\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(str)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "preprocessing - add, drop\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``linked births only``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linked_births_only(df):\n",
    "    ''' Keep births only if  vital stats birth, infant, and maternal discharge records are linked\n",
    "    '''\n",
    "    # find birth ids that are linked \n",
    "    births_linked = df[df['_linkedB'].eq('Y')]['_brthid'].unique()\n",
    "    print('Number of unique linked birth IDs:', births_linked.shape[0])\n",
    "\n",
    "    # subset df to keep only birth ids that are linked\n",
    "    # call it mini_df\n",
    "    mini_df = df[df['_brthid'].isin(births_linked)]\n",
    "    mini_df.reset_index(\n",
    "        drop=True,\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    return mini_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``zip geometry``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_drop_zip_geometry(df):\n",
    "    ''' Add zip code geometries\n",
    "    '''\n",
    "\n",
    "    ## read/preprocess geometry ##\n",
    "    ##############################\n",
    "    os.chdir(\"C:/Users/cilin/Research/CA_hospitals/Script/ssn_selection/cleaning/\")\n",
    "    %run \"4. geom_cleaning.ipynb\"\n",
    "    \n",
    "    # drop geometry column\n",
    "    gdf_zcta.drop(\n",
    "        columns='ZCTA10_geometry',\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    ## read/preprocess crosswalk ZIP to ZCTA ##\n",
    "    ###########################################\n",
    "    # read crosswalk\n",
    "    cw= pd.read_csv(\n",
    "        'C:/Users/cilin/Research/CA_hospitals/Input/raw_data/census_geo/ZiptoZcta_Crosswalk_2021.csv'\n",
    "    )\n",
    "\n",
    "    # keep if state is CA\n",
    "    cw = cw[cw.STATE.eq('CA')]\n",
    "\n",
    "    # transform to string\n",
    "    cw['ZIP_CODE'] = cw.ZIP_CODE.astype(str)\n",
    "\n",
    "\n",
    "    ## add geometry to ZIP ##\n",
    "    #########################\n",
    "    # define zip columns\n",
    "    columns = ['zipI', 'zipM', 'hplzipI', 'hplzipM'] \n",
    "    for idx, col in enumerate(columns):\n",
    "        #print(col)\n",
    "\n",
    "        ## preprocess df ##\n",
    "        ###################\n",
    "        # transform zipI to string    \n",
    "        df[col] = df[col].astype(str)\n",
    "        df[col] = df[col].str.split('.').str[0] # remove .0\n",
    "\n",
    "        # grab I, M, hI, hM initials\n",
    "        if idx==2:\n",
    "            initial='hI'\n",
    "        elif idx==3:\n",
    "            initial='hM'\n",
    "        else:\n",
    "            initial=columns[idx][3:]\n",
    "\n",
    "\n",
    "        ## read unique ZIP in df \n",
    "        temp_df = pd.DataFrame(\n",
    "            df[col].unique(),\n",
    "            columns=[col]\n",
    "        )\n",
    "\n",
    "\n",
    "        # attach ZCTA10 from gdf_zcta file #\n",
    "        ####################################\n",
    "        temp_df = temp_df.merge(\n",
    "            gdf_zcta[['ZCTA10']], \n",
    "            left_on=col,\n",
    "            right_on='ZCTA10',\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "        # attach ZCTA from crosswalk file #\n",
    "        ###################################\n",
    "        temp_df = temp_df.merge(\n",
    "            cw[['ZIP_CODE', 'ZCTA']], \n",
    "            left_on=col,\n",
    "            right_on='ZIP_CODE',\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "\n",
    "        # substitute with ZCTA if ZCTA10 is missing\n",
    "        temp_df['ZCTA10'] = np.where(temp_df.ZCTA10.isna(), temp_df.ZCTA, temp_df.ZCTA10)\n",
    "\n",
    "        # drop duplicates \n",
    "        temp_df.drop_duplicates(\n",
    "            [col],\n",
    "            inplace=True\n",
    "        )\n",
    "\n",
    "\n",
    "        # add in geometry #\n",
    "        ###################\n",
    "        temp_df = temp_df.merge(\n",
    "            gdf_zcta, \n",
    "            on='ZCTA10',\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "\n",
    "        # drop cols that are not of interest\n",
    "        temp_df.drop(\n",
    "            columns=['ZIP_CODE', 'ZCTA'],\n",
    "            inplace=True\n",
    "        )\n",
    "\n",
    "\n",
    "        # merge to original df\n",
    "        temp_df = df[[col]].merge(\n",
    "            temp_df,\n",
    "            on=col,\n",
    "            how='left'\n",
    "        )\n",
    "\n",
    "\n",
    "        # rename columns \n",
    "        new_cols = list(temp_df.columns[1:])\n",
    "        for new_col in new_cols:\n",
    "            if len(new_col.split('_'))==1:\n",
    "                temp_name = new_col.split('_')[0]+initial\n",
    "            else:\n",
    "                temp_name = new_col.split('_')[0]+initial+'_'+new_col.split('_')[1]\n",
    "            temp_df.rename(\n",
    "                columns={new_col:temp_name},\n",
    "                inplace=True\n",
    "            )\n",
    "\n",
    "        # drop col\n",
    "        temp_df.drop(columns=[col], inplace=True)\n",
    "\n",
    "        # add temp_df cols to original df\n",
    "        for temp_col in temp_df.columns:\n",
    "            df[temp_col] = temp_df[temp_col]\n",
    "    \n",
    "    ## if ZCTA geometry of ZCTA10I is missing substitute with that of mom or hospital\n",
    "    colsI = ['ZCTA10I', 'ZCTA10I_centroid']\n",
    "    colsM = ['ZCTA10M', 'ZCTA10M_centroid']\n",
    "    colshI = ['ZCTA10hI', 'ZCTA10hI_centroid']\n",
    "    colshM = ['ZCTA10hM', 'ZCTA10hM_centroid']\n",
    "    \n",
    "    for idx, colI in enumerate(colsI):\n",
    "        df[colI] = np.where(df[colI].isna(), df[colsM[idx]], df[colI])\n",
    "        df[colI] = np.where(df[colI].isna(), df[colshI[idx]], df[colI])\n",
    "        df[colI] = np.where(df[colI].isna(), df[colshM[idx]], df[colI])\n",
    "    \n",
    "    # drop if ZCTAI_centroid isna()\n",
    "    df = df[~df.ZCTA10I_centroid.isna()]\n",
    "    df.reset_index(drop=True, inplace=True)   \n",
    "    \n",
    "    return df\n",
    "\n",
    "    '''\n",
    "    ## if ZCTA geometries are missing (for I, M, hI, hM), find ZCTA10I geometry for the 4 digits zipI \n",
    "    temp_df = df[df.ZCTA10I_centroid.isna()]\n",
    "    temp_df.drop_duplicates(subset='zipI', inplace=True)\n",
    "    \n",
    "    # keep only 'zipI'\n",
    "    temp_df = temp_df[['zipI']]\n",
    "    \n",
    "    # find 4d zipI, ZCTA10I, and ZIP_CODE\n",
    "    temp_df['zipI_4d'] = temp_df.zipI.str[:4]\n",
    "    gdf_zcta['ZCTA10_4d'] = gdf_zcta.ZCTA10.str[:4]\n",
    "    cw['ZIP_CODE_4d'] = cw.ZIP_CODE.str[:4]\n",
    "    \n",
    "    # add geometries for 4d zipI\n",
    "    temp_df = temp_df.merge(\n",
    "        gdf_zcta['ZCTA10_4d'],\n",
    "        left_on='zipI_4d',\n",
    "        right_on='ZCTA10_4d',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    temp_df.drop_duplicates(subset='zipI', inplace=True)\n",
    "    \n",
    "    # attach ZCTA_4d from crosswalk file\n",
    "    temp_df = temp_df.merge(\n",
    "        cw[['ZIP_CODE_4d', 'ZCTA']], \n",
    "        left_on='zipI_4d',\n",
    "        right_on='ZIP_CODE_4d',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # substitute with ZCTA_4d if ZCTA10_4d is missing\n",
    "    temp_df['ZCTA10_4d'] = np.where(temp_df.ZCTA10_4d.isna(), temp_df.ZCTA.str[:4], temp_df.ZCTA10_4d)\n",
    "    \n",
    "    temp_df.drop_duplicates(subset='zipI', inplace=True)\n",
    "    temp_df = temp_df[['zipI', 'ZCTA10_4d']]\n",
    "   \n",
    "    # add geometry\n",
    "    temp_df = temp_df.merge(gdf_zcta,\n",
    "            on='ZCTA10_4d',\n",
    "            how='left'  \n",
    "    )\n",
    "    \n",
    "    temp_df.drop_duplicates(subset='zipI', inplace=True)\n",
    "    \n",
    "    temp_df.rename(columns={'ZCTA10_centroid': 'ZCTA10_4d_centroid'}, inplace=True)\n",
    "\n",
    "    # merge to original df\n",
    "    df = df.merge(\n",
    "            temp_df,\n",
    "            on='zipI',\n",
    "            how='left'\n",
    "        )\n",
    "    \n",
    "    # populate missing ZCTA1010_centroid\n",
    "    df['ZCTA10I_centroid'] = np.where(df['ZCTA10I_centroid'].isna(), df['ZCTA10_4d_centroid'], df['ZCTA10I_centroid'])\n",
    "    \n",
    "    # drop cols\n",
    "    df.drop(columns=['ZCTA10_4d_centroid'], inplace=True)\n",
    "    \n",
    "    # drop if ZCTA10_centroid is not available\n",
    "    df = df[~df.ZCTA10I_centroid.isna()]\n",
    "    \n",
    "    df.reset_index(drop=True, inplace=True)   \n",
    "    \n",
    "    return df     \n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``rlnI status``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rlnI_status(mini_df):\n",
    "    ''' Define rlnI status: at birth, first year of life, or not assigned at all\n",
    "    '''\n",
    "    # generate variable to show if rlnI is missing at the observation level\n",
    "    mini_df['rlnI_obs_missing'] = np.where(mini_df.rlnI.isin(('---------', np.nan)), 1, 0)\n",
    "\n",
    "    ## rlnI assigned at birth ##\n",
    "    ############################\n",
    "    # find birth ids for which rlnI was assigned at birth\n",
    "    births_w_rln_at_birth = mini_df[\n",
    "        (mini_df['_input'].eq(\"B\")) & (~mini_df['rlnI'].isin(('---------', np.nan)))\n",
    "    ]['_brthid'].unique()\n",
    "\n",
    "    ## rlnI assigned 1st year of life ##\n",
    "    ####################################\n",
    "    # find birth ids for which rlnI was assigned in first year of life\n",
    "    births_w_rln_1yol = mini_df[\n",
    "        (~mini_df['_brthid'].isin(births_w_rln_at_birth)) & (mini_df.rlnI_obs_missing.eq(0))\n",
    "    ]['_brthid'].unique()\n",
    "\n",
    "    ## rlnI status ##\n",
    "    #################\n",
    "    # create rlnI status variable to indicate if/when the rlnI was assigned\n",
    "    # this will help remove birth ids w/o a rlnI\n",
    "    mini_df['rlnI_status'] = np.where(mini_df['_brthid'].isin(births_w_rln_at_birth), 'rlnI assigned at birth',\n",
    "                                     np.where(mini_df['_brthid'].isin(births_w_rln_1yol), 'rlnI assigned 1st year of life', 'rlnI not assigned'))\n",
    "    \n",
    "\n",
    "    return mini_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``keys``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_keys(mini_df):\n",
    "    ''''''\n",
    "    # making sure all vars are strings and strip .0\n",
    "    for col in ['ZCTA10I', 'bthmonthI', 'bthyearI']:\n",
    "        mini_df[col] = mini_df[col].astype(str).str.split('.').str[0]\n",
    "\n",
    "    # create key with birthyear, birthmonth and birthzip of infant\n",
    "    mini_df['ZCTA10I_month_year'] = mini_df.ZCTA10I + '_' + mini_df.bthmonthI + '_' + mini_df.bthyearI\n",
    "\n",
    "    # create key with birthyear and birthmonth of infant\n",
    "    mini_df['bthI_month_year'] = mini_df.bthmonthI+  '_' + mini_df.bthyearI\n",
    "    \n",
    "    return mini_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dfs_rlnI(mini_df):\n",
    "    '''\n",
    "    '''\n",
    "    #########################\n",
    "    ##  rlnI not assigned ##\n",
    "    ########################\n",
    "    mini_df_no_rlnI = mini_df[\n",
    "        mini_df.rlnI_status.eq('rlnI not assigned')\n",
    "    ]\n",
    "    \n",
    "    # reset index\n",
    "    mini_df_no_rlnI.reset_index(\n",
    "        drop=True,\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    # save to csv\n",
    "    mini_df_no_rlnI.to_csv(in_dir + 'Birth_pre_final_no_rlnI.csv')\n",
    "\n",
    "    ###################\n",
    "    ## rlnI assigned ##\n",
    "    ###################\n",
    "    # NOTE: if you want to do record linkage the following line of code should not be executed\n",
    "    mini_df_rlnI = mini_df[\n",
    "        ~mini_df.rlnI_status.eq('rlnI not assigned')\n",
    "    ]\n",
    "\n",
    "    # reset index\n",
    "    mini_df_rlnI.reset_index(\n",
    "        drop=True,\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    #save to csv\n",
    "    mini_df_rlnI.to_csv(in_dir + 'Birth_pre_final_rlnI.csv')\n",
    "    \n",
    "    return mini_df_rlnI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``process rlnI births``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rlnI_births_process(mini_df):\n",
    "    ''' Preprocess if birthID has a rlnI assigned at birth or in first year of life\n",
    "    '''\n",
    "\n",
    "    ############################\n",
    "    ## number of unique rlnIs ##\n",
    "    ############################\n",
    "    # find the total number of unique rlnI for each birth id\n",
    "    rlnI_nunique = mini_df.groupby('_brthid', as_index=False).rlnI.nunique() # 6 unique rlnIs is max\n",
    "\n",
    "    # rename\n",
    "    rlnI_nunique.rename(\n",
    "        columns={'rlnI': 'rlnI_total'},\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    # create dictionary with birth ids that have more than 1 (up to 6) unique rlnIs\n",
    "    b_rlnIs = {}\n",
    "    keys = [\n",
    "        'b_w2rln',\n",
    "        'b_w3rln',\n",
    "        'b_w4rln',\n",
    "        'b_w5rln',\n",
    "        'b_w6rln',\n",
    "    ]\n",
    "    for idx, key in enumerate(keys):\n",
    "        b_rlnIs[key] = rlnI_nunique[rlnI_nunique.rlnI_total.eq(idx+2)]['_brthid'].unique()\n",
    "\n",
    "    # create number of unique rlnI variable\n",
    "    mini_df['rlnI_total'] = np.where(mini_df['_brthid'].isin(b_rlnIs['b_w2rln']), '2',\n",
    "                                    np.where(mini_df['_brthid'].isin(b_rlnIs['b_w3rln']), '3',\n",
    "                                            np.where(mini_df['_brthid'].isin(b_rlnIs['b_w4rln']), '4',\n",
    "                                                    np.where(mini_df['_brthid'].isin(b_rlnIs['b_w5rln']), '5',\n",
    "                                                            np.where(mini_df['_brthid'].isin(b_rlnIs['b_w6rln']), '6', '1')))))\n",
    "\n",
    "    ##########################################\n",
    "    ## keep birth ID with at most XXXX rlnI ##\n",
    "    ##########################################\n",
    "    # add here if you want to remove anything\n",
    "\n",
    "\n",
    "\n",
    "    ###############################\n",
    "    ## assign most frequent rlnI ##\n",
    "    ###############################\n",
    "    def helper(grp):\n",
    "        ''' \n",
    "        '''\n",
    "        # get most frequent rlnI value\n",
    "        most_freq_rln = grp[~grp.rlnI.eq('---------')].rlnI.mode() # remove '-------'; nan values are also removed by default with mode()\n",
    "        grp['rlnI_updated'] = most_freq_rln[0]\n",
    "        return grp\n",
    "\n",
    "    mini_df = mini_df.groupby('_brthid').apply(helper)\n",
    "    \n",
    "    ## keep only rlnI that have a single birthid ##\n",
    "    ##############################################\n",
    "    temp_df = mini_df.groupby(\n",
    "        ['rlnI_updated'],\n",
    "        as_index=False\n",
    "    )['_brthid'].nunique()\n",
    "\n",
    "    rlnI_1brthid = temp_df[temp_df['_brthid'].eq(1)].rlnI_updated.unique()\n",
    "    mini_df = mini_df[mini_df.rlnI_updated.isin(rlnI_1brthid)]\n",
    "\n",
    "    return mini_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``total hospital visits``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_hosp_vists(mini_df):\n",
    "    ''' Compute number of hospital visits before and after birth (for mother and infant)\n",
    "    '''\n",
    "    def helper(grp):\n",
    "        ''''''\n",
    "        # number of mother visits 9 month pre-partum (9mpp)\n",
    "        grp['visitsM_9mpp'] = grp[grp._input.eq('M') & grp._diffM.lt(0)].shape[0]\n",
    "        # number of mother visits 1st year post-partum (1ypp)\n",
    "        grp['visitsM_1ypp'] = grp[grp._input.eq('M') & grp._diffM.gt(0)].shape[0]\n",
    "        # number of infant visits 1st year of life (1yol)\n",
    "        grp['visitsI_1yol'] = grp[grp._input.eq('I')].shape[0]\n",
    "        return grp\n",
    "\n",
    "    mini_df = mini_df.groupby('_brthid').apply(helper)\n",
    "    \n",
    "    return mini_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``cols of interest``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_cols_of_interest(mini_df):\n",
    "    cols = [\n",
    "        '_brthid',\t'_brthIDHST',\n",
    "        '_linkedB',\t'_linkidB',\t'_linkidI',\n",
    "        '_linkidM',\t'_twinB',\t'_twinI',\n",
    "        '_twinM',\t'_twinwght',\t'typebth',\n",
    "        'bthorder',\t'rlnI',\t'rlnM',\t\n",
    "        'rlnI_status', 'rlnI_total', 'rlnI_updated',\n",
    "        'bthdateM', 'bthyearM',\t'bthmonthM', 'bthdayM',\n",
    "        'bthdateI',\t'bthyearI',\t'bthmonthI',\n",
    "        'bthdayI', 'bthI_month_year', 'fbthdate',\t'fbthyear',\n",
    "        'fbthmonth',\t'fbthday',\n",
    "        'zipM', 'ZCTA10M', 'ZCTA10M_centroid',\n",
    "        'zipI',\t'ZCTA10I', 'ZCTA10I_centroid',\n",
    "        'hplzipM', 'ZCTA10hM',  'ZCTA10hM_centroid',\n",
    "        'hplzipI', 'ZCTA10hI', 'ZCTA10hI_centroid',\n",
    "        'ZCTA10I_month_year', \n",
    "        'cntyresM',\t'cntyresM_name', 'cntyresI',\n",
    "        'cntyresI_name', 'hplcntyM', 'hplcntyM_name',\n",
    "        'hplcntyI',\t'hplcntyI_name', 'matresst',\n",
    "        'matresst_name', 'bthresmb', 'bthresmb_name',\n",
    "        'bthresmb06', 'bthresmb06_name', 'raceM',\n",
    "        'frace', 'meduc', 'feduc', 'sexI', 'raceI',\n",
    "        'admdateM',\t'admyearM',\t'admmonthM',\n",
    "        'admdayM',\t'admdateI',\t'admyearI',\n",
    "        'admmonthI', 'admdayI',\t\n",
    "        'hplidI', 'hospidM',\t'_sortid',\t'_input',\n",
    "        'visitsM_9mpp', 'visitsM_1ypp', 'visitsI_1yol',\n",
    "        '_diffI',\t'_diffM',\t'_losI', '_losM',\n",
    "        'lenstayI',\t'lenstayM',\t'_chargesI',\n",
    "        '_chargesM', 'paycatI',\t'paycatM',\n",
    "        'payplanI',\t'payplanM',\t'paytypeI',\n",
    "        'paytypeM',\t'admsrcI',\t'admsrcM',\n",
    "        'precare', 'precare_name',\n",
    "        'prevlbd',\t'prevlbd_name', \n",
    "        'prevlbl', 'prevlbl_name', 'cebl', 'cebl_name',\n",
    "        'ceb', 'ceb_name', 'prevsts', 'prevsts_name',\n",
    "        'gest_days', 'gest_days_name', 'bthhour', 'bthwghtI',\n",
    "        'caesar', 'caesar_name',\n",
    "        'probl_1', 'probl_1_list',\n",
    "        'probl_2',\t'probl_2_list',\n",
    "        'probl_3',\t'probl_3_list',\n",
    "        'llbmths',\t'llbyr',\t'ltamth',\t'ltamths',\t'ltayr',\n",
    "        'term_a20wks', 'term_a20wks_name',\n",
    "        'term_b20wks', 'term_b20wks_name',\n",
    "        'diagM00',\t'diagM01',\t'diagM02',\t'diagM03',\t'diagM04',\n",
    "        'proc_edasM00',\t'proc_edasM01',\t'proc_edasM02',\t'proc_edasM03',\t'proc_edasM04',\n",
    "        'procM00', 'procM01',\t'procM02',\t'procM03',\t'procM04',\n",
    "        'diagI00',\t'diagI01',\t'diagI02',\t'diagI03',\t'diagI04',\n",
    "        'proc_edasI00',\t'proc_edasI01',\t'proc_edasI02',\t'proc_edasI03',\t'proc_edasI04',\n",
    "        'procI00',\t'procI01',\t'procI02',\t'procI03',\t'procI04'\n",
    "    ]\n",
    "        \n",
    "    return mini_df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 4: Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data()\n",
    "print('Shape of data:', df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 5: Data preprocessing - add, recode, substitute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``sort values``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort values\n",
    "df.sort_values(\n",
    "    by=['_brthid', '_sortid'],\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# reset index\n",
    "df.reset_index(\n",
    "    drop=True,\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``dates``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode, substitute and add dates\n",
    "df = add_dates(sub_missing_dates(recode_dates(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``sex``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode, substitute sex\n",
    "df = recode_sex(sub_missing_sex(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``race``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode, substitute race\n",
    "df = sub_missing_race(recode_race(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``education``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode educ\n",
    "df = recode_educ(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``zip`` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode, substitute zip at birth for infant and mother\n",
    "df = sub_missing_zip(recode_zip(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``county``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode county at birth for infant and mother\n",
    "df = recode_county(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``state/country``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode state/country at birth for mother\n",
    "df = recode_state_m(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode state/country at mother's own birth\n",
    "df = recode_state_mob(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``caesar``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode C-section at birth\n",
    "df = recode_caesar(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``pregnancy, labor, newborn complications``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode complications with preganancy, labor or newborn\n",
    "df = recode_probl(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``preganncy precare``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode precare variables (month prenanatal care began and number of previous visits)\n",
    "df = recode_precare(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``previous births``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode previous births now dead or alive\n",
    "df = recode_prev_births(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``gestation length``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = recode_gest_days(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``admission source``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = recode_admission_src(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``diagnosis codes``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = recode_diagnosis_codes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'Shape of data after Step 5: \"Data preprocessing - add, recode, substitute\":',\n",
    "    df.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(in_dir + 'Birth_after_step5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 6: Data preprocessing - add, drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``keep if _linkedB=='Y``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(in_dir + 'Birth_after_step5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep births only if  vital stats birth, infant, and maternal discharge records are linked\n",
    "mini_df = linked_births_only(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print shape after this cleaning\n",
    "print('Df shape after _linkedB record cleaning:', mini_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``add ZIP geography. drop if zipI geography is nan()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_df = add_drop_zip_geometry(mini_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print shape after this cleaning\n",
    "print('Df shape after ZCTA10I_centroid cleaning:', mini_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``add rlnI status``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add rlnI status variable\n",
    "mini_df = rlnI_status(mini_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``add keys for merging or FE``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_df = add_keys(mini_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_df.to_csv(in_dir + 'Birth_after_step6.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``save dfs``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df based on rlnI status (no rlnI; rlnI present at birth or 1st year of life)\n",
    "# return only df with rlnI present\n",
    "mini_df_rlnI = save_dfs_rlnI(mini_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Df shape after rlnI cleaning:', mini_df_rlnI.shape)\n",
    "print(\n",
    "    'Share of birth IDs retained relative to original dataset:',\n",
    "     mini_df_rlnI._brthid.nunique()/df._brthid.nunique()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:pink\">[RESTART KERNEL HERE, otherwise you run out of memory]</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``process if rlnI assigned``\n",
    "\n",
    "<span style=\"color:white\">[important section if you do record linkeage later on]</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Read data:')\n",
    "mini_df_rlnI = pd.read_csv(in_dir + 'Birth_pre_final_rlnI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if more than one rlnI, assign the most frequent one\n",
    "# if more than one rlnI and all have the same frequency, assign mode()\n",
    "mini_df_rlnI = rlnI_births_process(mini_df_rlnI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``add total hospital visits`` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute number of visits for mother and child\n",
    "print('Compute total hosp visits:')\n",
    "mini_df_rlnI = total_hosp_vists(mini_df_rlnI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    'Shape of data after Step 6: \"Data preprocessing - drop, add\":',\n",
    "    mini_df_rlnI.shape\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 7: Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only cols of interest and output to .csv\n",
    "keep_cols_of_interest(mini_df_rlnI).to_csv(out_dir + 'Birth_final.csv') #birth, infant, mother records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are zip codes in CA but they don't have a county assigned\n",
    "#df[(df.cntyresI_name.eq('nan')) & (~df.zipI.isin(('nan', 'outside of US', 'homeless'))) & df.zipI.str[:2].isin(('90', '91', '92', '93', '94', '95', '96'))]['zipI'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
