{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a7b76c6",
   "metadata": {},
   "source": [
    "# Main script to merge PPE, fires, pm25 and wind data\n",
    "\n",
    "Modules: N/A <br>\n",
    "Author: Cornelia Ilin <br>\n",
    "Email: cilin@wisc.edu <br>\n",
    "Date created: April 27, 2022 <br>\n",
    "\n",
    "**Citations (data sources)**\n",
    "    \n",
    "**Citations (persons)**\n",
    "1. N/A\n",
    "\n",
    "**Preferred environment**\n",
    "1. Code written in Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfec329",
   "metadata": {},
   "source": [
    "### Step 1: Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7c1558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "\n",
    "import geopandas as gpd\n",
    "import ast\n",
    "from shapely.geometry import Point\n",
    "from geopy.distance import distance\n",
    "from shapely import wkt\n",
    "import math\n",
    "import pyproj\n",
    "import sklearn.neighbors\n",
    "dist = sklearn.neighbors.DistanceMetric.get_metric('haversine')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "%matplotlib inline\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778548e0",
   "metadata": {},
   "source": [
    "### Step 2: Define working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ab6d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_health = 'C:/Users/cilin/Research/CA_hospitals/Input/final_data/health/'\n",
    "in_fires = 'C:/Users/cilin/Research/CA_hospitals/Input/final_data/fires/'\n",
    "in_pm25 = 'C:/Users/cilin/Research/CA_hospitals/Input/final_data/pollution/satellite/UW/monthly/'\n",
    "in_winds = 'C:/Users/cilin/Research/CA_hospitals/Input/final_data/winds/'\n",
    "out_dir = 'C:/Users/cilin/Research/CA_hospitals/Input/final_data/all_combined/'\n",
    "#out_dir = 'C:/Users/cilin/Research/CA_hospitals/Figures/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3bfd87",
   "metadata": {},
   "source": [
    "### Step 3: Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0d0bd3",
   "metadata": {},
   "source": [
    "``read data``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7200ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_health():\n",
    "    ''''''\n",
    "    return pd.read_csv(in_health + 'BPE_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b053a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fires():\n",
    "    ''''''\n",
    "    return pd.read_csv(in_fires + 'fires_long.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add1f5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pm25():\n",
    "    ''''''\n",
    "    df = pd.DataFrame()\n",
    "    # read files\n",
    "    for file in os.listdir(in_pm25):\n",
    "        temp_df = pd.read_csv(in_pm25 + file)\n",
    "        df = pd.concat([df, temp_df], axis=0)\n",
    "     \n",
    "    #df = pd.read_csv(in_pm25 + 'pm25_uw_zip_monthly.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0b3851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_winds():\n",
    "    ''''''\n",
    "    return pd.read_csv(in_winds + 'winds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edd868a",
   "metadata": {},
   "source": [
    "``preprocess data``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d2220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_health(df, for_df=True):\n",
    "    '''\n",
    "    '''\n",
    "    \n",
    "    # drop if ZCTA10_centroid is nan()\n",
    "    df = df[~df['ZCTA10I_centroid'].isna()]\n",
    "    \n",
    "    # transform ZCTA10_centroid column to string\n",
    "    df['ZCTA10I_centroid'] = df['ZCTA10I_centroid'].astype(str)\n",
    "    \n",
    "    for col in ['ZCTA10I', 'bthmonthI', 'bthyearI']:\n",
    "        # transform to string\n",
    "        df[col] = df[col].astype(str)\n",
    "        \n",
    "        # remove .0\n",
    "        df[col] = df[col].str.split('.').str[0]\n",
    "        \n",
    "    # create key with birthyear, birthmonth and birthzip of infant\n",
    "    df['ZCTA10I_month_year'] = df.ZCTA10I + '_' + df.bthmonthI + '_' + df.bthyearI\n",
    "    \n",
    "    # create key with birthyear and birthmonth of infant\n",
    "    df['bthI_month_year'] = df.bthmonthI+  '_' + df.bthyearI\n",
    "\n",
    "    if for_df:\n",
    "        return df\n",
    "    \n",
    "    else:\n",
    "        # keep only cols of interest\n",
    "        df = df[\n",
    "            ['ZCTA10I_month_year', 'bthI_month_year', 'ZCTA10I_centroid']\n",
    "        ]\n",
    "\n",
    "        # drop duplicates of ZCTA10I_month_year\n",
    "        df.drop_duplicates(\n",
    "            subset=['ZCTA10I_month_year'],\n",
    "            inplace=True\n",
    "        )\n",
    "\n",
    "        # transform the centroid column to geometry and then to geopandas\n",
    "        df['ZCTA10I_centroid']= gpd.GeoSeries.from_wkt(df['ZCTA10I_centroid'])\n",
    "        gdf = gpd.GeoDataFrame(df, geometry='ZCTA10I_centroid', crs=\"EPSG:4269\")  \n",
    "\n",
    "\n",
    "        # transform bthI_month_yearto date format\n",
    "        gdf['bthI_month_year'] =  pd.to_datetime(gdf.bthI_month_year, format=\"%m_%Y\")\n",
    "\n",
    "        # add 9 months prior birth\n",
    "        gdf['bthI_month_year_9mbb'] = gdf['bthI_month_year'] - DateOffset(months=9)\n",
    "\n",
    "        # add 12 months after birth\n",
    "        gdf['bthI_month_year_12mab'] = gdf['bthI_month_year'] + DateOffset(months=12)\n",
    "\n",
    "        # transform back to string\n",
    "        gdf['bthI_month_year'] = gdf['bthI_month_year'].dt.to_period('M').astype(str)\n",
    "        gdf['bthI_month_year_9mbb'] = gdf['bthI_month_year_9mbb'].dt.to_period('M').astype(str)\n",
    "        gdf['bthI_month_year_12mab'] = gdf['bthI_month_year_12mab'].dt.to_period('M').astype(str)\n",
    "\n",
    "        gdf['bthI_month_year'] = gdf['bthI_month_year'].str.split('-').str[1] + \"-\" + gdf['bthI_month_year'].str.split('-').str[0]\n",
    "        gdf['bthI_month_year_9mbb'] = gdf['bthI_month_year_9mbb'].str.split('-').str[1] + \"-\" + gdf['bthI_month_year_9mbb'].str.split('-').str[0]\n",
    "        gdf['bthI_month_year_12mab'] = gdf['bthI_month_year_12mab'].str.split('-').str[1] + \"-\" + gdf['bthI_month_year_12mab'].str.split('-').str[0]\n",
    "\n",
    "        gdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "        return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4222c253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fires(df):\n",
    "    '''\n",
    "    '''\n",
    "    for col in ['fire_name', 'fire_month', 'fire_year']:\n",
    "        # transform to string\n",
    "        df[col] = df[col].astype(str)\n",
    "        # remove .0\n",
    "        df[col] = df[col].str.split('.').str[0]\n",
    "        \n",
    "    # create key fire_name_year_month\n",
    "    df['fire_month_year'] = df.fire_name + '_' + df.fire_month + '_' + df.fire_year\n",
    "\n",
    "    df['month_year'] = df.fire_month + '_' + df.fire_year\n",
    "\n",
    "    # keep only cols of interest\n",
    "    df = df[['fire_month_year', 'month_year', 'fire_centroid', 'fire_area_km2',\t'fire_duration_days']]\n",
    "\n",
    "    # transform the centroid column to geometry and then to geopandas\n",
    "    df['fire_centroid']= gpd.GeoSeries.from_wkt(df['fire_centroid'])\n",
    "    gdf = gpd.GeoDataFrame(df, geometry='fire_centroid', crs=\"EPSG:4269\")    \n",
    "    gdf.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # change format of month_year\n",
    "    gdf['month_year'] = pd.to_datetime(gdf.month_year, format=\"%m_%Y\")\n",
    "    gdf['month_year'] = gdf['month_year'].dt.to_period('M').astype(str)\n",
    "    gdf['month_year'] = gdf['month_year'].str.split('-').str[1] + \"-\" + gdf['month_year'].str.split('-').str[0]\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a98022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pm25(df):\n",
    "    '''\n",
    "    '''\n",
    "    # preprocess month to eliminate the 0 for months 1-9\n",
    "    df['month'] = df.year_month.str[5:7]\n",
    "    df['month'] = np.where(df.month.str.startswith('0'), df.month.str[1:], df.month)\n",
    "\n",
    "    # add zcta_month_year column\n",
    "    df['ZCTA10_month_year'] = df.year_month_zcta.str[8:13] +\\\n",
    "                            '_' + df.month +\\\n",
    "                            '_' + df.year_month_zcta.str[0:4]\n",
    "    \n",
    "    # keep only cols of interest\n",
    "    df = df[['ZCTA10_month_year', 'pm25']]\n",
    "    \n",
    "    df.sort_values(\n",
    "        by=['ZCTA10_month_year'],\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    # reset index\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a92ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_winds(df):\n",
    "    '''\n",
    "    '''\n",
    "    for col in ['ZCTA10', 'year_month']:\n",
    "        df[col] = df[col].astype(str)\n",
    "    \n",
    "    # create month and year\n",
    "    df['year'] = df.year_month.str[0:4]\n",
    "    df['month'] = df.year_month.str[4:6]\n",
    "    df['month'] = np.where(df.month.str.startswith('0'), df.month.str[1:], df.month)\n",
    "\n",
    "    # create zcta_month_year column\n",
    "    df['ZCTA10_month_year'] = df.ZCTA10 + \"_\" + df.month + \"_\" + df.year\n",
    "    \n",
    "    \n",
    "    # keep only cols of interest\n",
    "    df = df[['ZCTA10_month_year', 'wdir', 'wspd']]\n",
    "    \n",
    "    # sort values\n",
    "    df.sort_values(\n",
    "        by=['ZCTA10_month_year'],\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    # reset index\n",
    "    df.reset_index(drop=True, inplace=True)     \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f4d008-a01d-43f1-822e-3718e9feb04f",
   "metadata": {},
   "source": [
    "``impute missing values``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed1858b-eadd-486b-92e1-a33d18f006a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_PM25(df_h, df_pm):\n",
    "    ''''''\n",
    "    # create vars\n",
    "    df_h['bthmonthI'] = df_h.bthI_month_year.str.split('-').str[0].astype(int)\n",
    "    df_h['bthyearI'] = df_h.bthI_month_year.str.split('-').str[1].astype(int)\n",
    "    df_h['ZCTA10I'] = df_h.ZCTA10I_month_year.str.split('_').str[0].astype(int)\n",
    "    df_h['year_ZCTA10I'] = df_h.ZCTA10I_month_year.str.split('_').str[2] + '_' + df_h.ZCTA10I_month_year.str.split('_').str[0]\n",
    "    #df_h['ZCTA10I_month'] = df_h.ZCTA10I_month_year.str.split('_').str[0] + '_' + df_h.ZCTA10I_month_year.str.split('_').str[1]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # merge df_h and df_pm to see which ZCTA10_month_year are missing\n",
    "    df_hpm = df_h.merge(\n",
    "        df_pm[['ZCTA10_month_year', 'pm25']],\n",
    "        left_on='ZCTA10I_month_year',\n",
    "        right_on='ZCTA10_month_year',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # sort values \n",
    "    df_hpm = df_hpm.sort_values(['year_ZCTA10I', 'bthmonthI'])\n",
    "    df_hpm.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # take mean of pm25 by year_ZCTA10I and add to df_hpm\n",
    "    df_hpm_mean = df_hpm.groupby('year_ZCTA10I', as_index=False).pm25.mean()\n",
    "    df_hpm_mean.rename(columns={'pm25': 'pm25_mean'}, inplace=True)\n",
    "    \n",
    "    # take mean of pm25 by bthI_month and add to df_hpm\n",
    "    df_hpm_mean_z = df_hpm.groupby('ZCTA10I', as_index=False).pm25.mean()\n",
    "    df_hpm_mean_z.rename(columns={'pm25': 'pm25_mean_z'}, inplace=True)\n",
    "    \n",
    "    # merge\n",
    "    df_hpm = df_hpm.merge(\n",
    "        df_hpm_mean, \n",
    "        on='year_ZCTA10I',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    df_hpm = df_hpm.merge(\n",
    "        df_hpm_mean_z, \n",
    "        on='ZCTA10I',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "\n",
    "    # drop if pm_25_mean or pm_25_mean_my is nan()\n",
    "    df_hpm = df_hpm[~df_hpm.pm25_mean.isna()]\n",
    "    df_hpm = df_hpm[~df_hpm.pm25_mean_z.isna()]\n",
    "    df_hpm.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    df_hpm = df_hpm.sort_values(['ZCTA10I', 'bthyearI', 'bthmonthI'])\n",
    "    df_hpm.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # if pm25 is missing, substitute with pm25_mean\n",
    "    #df_hpm['pm25'] = np.where(df_hpm.pm25.isna(), df_hpm.pm25_mean, df_hpm.pm25)\n",
    "    \n",
    "    # if pm25 is missing again, subsitute with pm25_mean_my\n",
    "    #df_hpm['pm25'] = np.where(df_hpm.pm25.isna(), df_hpm.pm25_mean_z, df_hpm.pm25)\n",
    "    \n",
    "    # create 9 mmonths before birth pm25 mean value and 12 months after birth pm25 mean value\n",
    "    def helper(grp):\n",
    "        ''''''\n",
    "        pm_9m_lag = pd.concat(\n",
    "        [\n",
    "            grp.pm25,\n",
    "            grp.pm25.shift(1), grp.pm25.shift(2),\n",
    "            grp.pm25.shift(3), grp.pm25.shift(4),\n",
    "            grp.pm25.shift(5), grp.pm25.shift(6),\n",
    "            grp.pm25.shift(7), grp.pm25.shift(8),\n",
    "            grp.pm25.shift(9)\n",
    "        ], axis=1).mean(axis=1) # mean by row\n",
    "\n",
    "        pm_12_fw = pd.concat(\n",
    "        [\n",
    "            grp.pm25,\n",
    "            grp.pm25.shift(-1), grp.pm25.shift(-2),\n",
    "            grp.pm25.shift(-3), grp.pm25.shift(-4),\n",
    "            grp.pm25.shift(-5), grp.pm25.shift(-6),\n",
    "            grp.pm25.shift(-7), grp.pm25.shift(-8),\n",
    "            grp.pm25.shift(-9), grp.pm25.shift(-10),\n",
    "            grp.pm25.shift(-11)\n",
    "        ], axis=1).mean(axis=1) # mean by row\n",
    "\n",
    "        grp['pm25_9mbb'] = pm_9m_lag   \n",
    "        grp['pm25_12mab'] = pm_12_fw \n",
    "        return grp\n",
    "\n",
    "    df_hpm = df_hpm.groupby('ZCTA10I', as_index=False).apply(helper)\n",
    "    \n",
    "    # add new pm25, pm25_9mbb and pm25_12mab to df_pm\n",
    "    df_pm = df_pm.drop(columns=['pm25'])\n",
    "    df_pm = df_pm.merge(\n",
    "        df_hpm[['ZCTA10_month_year', 'pm25', 'pm25_9mbb', 'pm25_12mab']],\n",
    "        on='ZCTA10_month_year',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # keep only if 'ZCTA10_month_year' is in df_h\n",
    "    df_pm = df_pm[df_pm.ZCTA10_month_year.isin(df_h.ZCTA10I_month_year.unique())]\n",
    "    df_pm.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df_pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6244e68-c5d9-40c7-a604-8d1638a0172a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_winds(df_h, df_w):\n",
    "    ''''''\n",
    "    # create vars\n",
    "    df_h['bthmonthI'] = df_h.bthI_month_year.str.split('-').str[0].astype(int)\n",
    "    df_h['bthyearI'] = df_h.bthI_month_year.str.split('-').str[1].astype(int)\n",
    "    df_h['ZCTA10I'] = df_h.ZCTA10I_month_year.str.split('_').str[0].astype(int)\n",
    "    df_h['year_ZCTA10I'] = df_h.ZCTA10I_month_year.str.split('_').str[2] + '_' + df_h.ZCTA10I_month_year.str.split('_').str[0]\n",
    "    \n",
    "    \n",
    "    # merge df_h and df_pm to see which ZCTA10_month_year are missing\n",
    "    df_hw = df_h.merge(\n",
    "        df_w[['ZCTA10_month_year', 'wdir', 'wspd']],\n",
    "        left_on='ZCTA10I_month_year',\n",
    "        right_on='ZCTA10_month_year',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # sort values \n",
    "    df_hw = df_hw.sort_values(['year_ZCTA10I', 'bthmonthI'])\n",
    "    df_hw.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "\n",
    "    # take mean of 'wdir', 'wspd' and add to df_hw\n",
    "    df_hw_mean = df_hw.groupby('year_ZCTA10I', as_index=False)['wdir', 'wspd'].mean()\n",
    "    df_hw_mean.rename(columns={'wdir': 'wdir_mean', 'wspd': 'wspd_mean'}, inplace=True)\n",
    "    \n",
    "    df_hw = df_hw.merge(\n",
    "        df_hw_mean, \n",
    "        on='year_ZCTA10I',\n",
    "        how='left'\n",
    "    )\n",
    "   \n",
    "\n",
    "    # drop if wdir_mean or wspd_mean is nan()\n",
    "    df_hw = df_hw[~df_hw.wdir_mean.isna()]\n",
    "    df_hw = df_hw[~df_hw.wspd_mean.isna()]\n",
    "    df_hw.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    df_hw = df_hw.sort_values(['ZCTA10I', 'bthyearI', 'bthmonthI'])\n",
    "    df_hw.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # if 'wdir', 'wspd' is missing, substitute with their means\n",
    "    #df_hw['wdir'] = np.where(df_hw.wdir.isna(), df_hw.wdir_mean, df_hw.wdir)\n",
    "    #df_hw['wspd'] = np.where(df_hw.wspd.isna(), df_hw.wspd_mean, df_hw.wspd)\n",
    "    \n",
    "    # create 9 mmonths before birth and 12 months after birth wdor/wspd values (take mean over the period)\n",
    "    def helper(grp):\n",
    "        ''''''\n",
    "        lag_9m = {}\n",
    "        fw_12m = {}\n",
    "        for val in ['wdir', 'wspd']:\n",
    "            lag_9m[val] = pd.concat(\n",
    "            [\n",
    "                grp[val],\n",
    "                grp[val].shift(1), grp[val].shift(2),\n",
    "                grp[val].shift(3), grp[val].shift(4),\n",
    "                grp[val].shift(5), grp[val].shift(6),\n",
    "                grp[val].shift(7), grp[val].shift(8),\n",
    "                grp[val].shift(9)\n",
    "            ], axis=1).mean(axis=1) # mean by row\n",
    "\n",
    "            fw_12m[val] = pd.concat(\n",
    "            [\n",
    "                grp[val],\n",
    "                grp[val].shift(-1), grp[val].shift(-2),\n",
    "                grp[val].shift(-3), grp[val].shift(-4),\n",
    "                grp[val].shift(-5), grp[val].shift(-6),\n",
    "                grp[val].shift(-7), grp[val].shift(-8),\n",
    "                grp[val].shift(-9), grp[val].shift(-10),\n",
    "                grp[val].shift(-11)\n",
    "            ], axis=1).mean(axis=1) # mean by row\n",
    "        \n",
    "        # add columns\n",
    "        grp['wdir_9mbb'] = lag_9m['wdir']   \n",
    "        grp['wdir_12mab'] = fw_12m['wdir']\n",
    "        grp['wspd_9mbb'] = lag_9m['wspd']  \n",
    "        grp['wspd_12mab'] = fw_12m['wspd'] \n",
    "        \n",
    "        return grp\n",
    "\n",
    "    df_hw = df_hw.groupby('ZCTA10I', as_index=False).apply(helper)\n",
    "    \n",
    "    # add new wspd columns to df_winds\n",
    "    df_w = df_w.drop(columns=['wspd', 'wdir'])\n",
    "    df_w = df_w.merge(\n",
    "        df_hw[['ZCTA10_month_year', 'wdir', 'wdir_9mbb', 'wdir_12mab', 'wspd', 'wspd_9mbb', 'wspd_12mab']],\n",
    "        on='ZCTA10_month_year',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # keep only if 'ZCTA10_month_year' is in df_h\n",
    "    df_w = df_w[df_w.ZCTA10_month_year.isin(df_h.ZCTA10I_month_year.unique())]\n",
    "    df_w.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df_w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c69926",
   "metadata": {},
   "source": [
    "``distance``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f864ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance_bearing(gdf_h, gdf_f, time_period):\n",
    "    ''' Merge fire and health data and compute distance between fires centroid and birth zip centroid\n",
    "    '''\n",
    "    gdf = gdf_h.groupby(\n",
    "        ['ZCTA10I_month_year'],\n",
    "        as_index=False\n",
    "    ).apply(helper, gdf_f, time_period)\n",
    "\n",
    "    # reset index\n",
    "    gdf.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd56978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper(grp, gdf_f, time_period):\n",
    "    '''\n",
    "    '''\n",
    "    # find month year in health data (grp)\n",
    "    month_year = grp.bthI_month_year.unique()[0]\n",
    "    month_year_9mbb = grp.bthI_month_year_9mbb.unique()[0]\n",
    "    month_year_12mab = grp.bthI_month_year_12mab.unique()[0]\n",
    "    \n",
    "    if time_period=='9mbb':\n",
    "        month_year_range = pd.date_range(\n",
    "            month_year_9mbb, month_year, freq='MS'\n",
    "        ).strftime(\"%m-%Y\").tolist()\n",
    "        \n",
    "    if time_period=='12mab':\n",
    "        month_year_range = pd.date_range(\n",
    "            month_year, month_year_12mab, freq='MS'\n",
    "        ).strftime(\"%m-%Y\").tolist()\n",
    "        \n",
    "\n",
    "    # grab only fires in this month and year\n",
    "    if time_period=='current':\n",
    "        temp_fires = gdf_f[gdf_f.month_year.eq(month_year)]\n",
    "    else:\n",
    "        temp_fires = gdf_f[gdf_f.month_year.isin(month_year_range)]\n",
    "    temp_fires.reset_index(drop=True, inplace=True)\n",
    "    #print(temp_fires.shape)\n",
    " \n",
    "    if temp_fires.shape[0]:\n",
    "        # add variable to indicate there were fires in this month and year\n",
    "        grp['fires_in_bthI_month_year'] = 'yes'\n",
    "        # replicate grp to match size of fires\n",
    "        grp = pd.concat([grp]*temp_fires.shape[0], ignore_index=True)\n",
    "        # match grp and fires\n",
    "        grp = pd.concat([grp, temp_fires], axis=1)\n",
    "\n",
    "        # compute distance and bearing angle between each fire centroid and birth zip code centroid #\n",
    "        #############################################################################################\n",
    "        # bearing angle intuition: https://www.mathsteacher.com.au/year7/ch08_angles/07_bear/bearing.htm\n",
    "        # beearing angle online tool: https://www.igismap.com/map-tool/bearing-angle\n",
    "        # bearing angle online tool: https://www.movable-type.co.uk/scripts/latlong.html\n",
    "        geodesic = pyproj.Geod(ellps='WGS84')\n",
    "        fwd_azimuth, back_azimuth, distance = geodesic.inv(\n",
    "            grp.fire_centroid.x, grp.fire_centroid.y, # this is for fire centroid (lon, lat); # notice that this lines defines the fire centroid as the starting point\n",
    "            grp.ZCTA10I_centroid.x, grp.ZCTA10I_centroid.y # this is for zip centroid (lon, lat)\n",
    "        )\n",
    "        \n",
    "        # define bearing_angle as the fwd_azimuth\n",
    "        grp['bearing_angle'] = fwd_azimuth\n",
    "        \n",
    "        # Note that the bearing angle is btw -180° and + 180°, we want to transoform it to a compas bearing from 0 to 360\n",
    "        # See also: https://towardsdatascience.com/calculating-the-bearing-between-two-geospatial-coordinates-66203f57e4b4\n",
    "        grp['bearing_angle'] = (grp.bearing_angle + 360) % 360 # degrees from the north;\n",
    "        \n",
    "        # distance is originally reported in meters; divide by 1000 to transform in km\n",
    "        grp['fire_ZCTA10I_dist'] = distance/1000  \n",
    "        \n",
    "    else:\n",
    "        # add variable to indicate there were no fires in this month and year\n",
    "        grp['fires_in_bthI_month_year'] = 'no'\n",
    "    \n",
    "    return grp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec41630",
   "metadata": {},
   "source": [
    "``merge``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee4c5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dfs(gdf_hf, df_p, df_w):\n",
    "    ''''''\n",
    "    \n",
    "    # merge health and pm25\n",
    "    gdf = gdf_hf.merge(\n",
    "        df_p,\n",
    "        left_on='ZCTA10I_month_year',\n",
    "        right_on='ZCTA10_month_year',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # drop to avoid duplicates with df_w\n",
    "    gdf.drop(columns=['ZCTA10_month_year'], inplace=True)\n",
    "    \n",
    "    # merge health + pm25 and winds\n",
    "    gdf = gdf.merge(\n",
    "        df_w, \n",
    "        left_on='ZCTA10I_month_year',\n",
    "        right_on='ZCTA10_month_year',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567964d0-73c0-4dc8-9227-9fe83b77883c",
   "metadata": {},
   "source": [
    "``add instrument``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e406dc54-9538-4ca9-9690-34c48815706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_instrument(gdf, time_period):\n",
    "    ''''''\n",
    "    ## for wind direction ##\n",
    "    ########################\n",
    "    if time_period=='current':\n",
    "        windcol = 'wdir'\n",
    "    if time_period=='9mbb':\n",
    "        windcol = 'wdir_9mbb'\n",
    "    if time_period=='12mab':\n",
    "        windcol = 'wdir_12mab'\n",
    "\n",
    "\n",
    "    # add compas bins for wind direction\n",
    "    gdf['binned_wdir']=pd.cut(\n",
    "        x=gdf[windcol],\n",
    "        bins=np.arange(0,390,30) # 12 bins in total\n",
    "    )\n",
    "\n",
    "    # add dummies for binned wind direction\n",
    "    gdf = pd.concat(\n",
    "        [gdf, pd.get_dummies(gdf.binned_wdir, prefix='bwdir')],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "    ## for bearing angles ##\n",
    "    ########################\n",
    "    # add compas bins for bearing angle between fires and birth zip code centroid;\n",
    "    gdf['binned_bearing']=pd.cut(\n",
    "        x=gdf.bearing_angle,\n",
    "        bins=np.arange(0,390,30) # 12 bins in total\n",
    "    )\n",
    "\n",
    "    # add dummies for binned compass bins\n",
    "    gdf = pd.concat(\n",
    "        [gdf, pd.get_dummies(gdf.binned_bearing, prefix='bfire')],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    \n",
    "    ## create wildfire instrument ##\n",
    "    ################################\n",
    "    # define bins in gdf\n",
    "    bins12 = [\n",
    "        '_(0, 30]', '_(30, 60]', '_(60, 90]',\n",
    "        '_(90, 120]', '_(120, 150]', '_(150, 180]',\n",
    "        '_(180, 210]', '_(210, 240]', '_(240, 270]',\n",
    "        '_(270, 300]', '_(300, 330]', '_(330, 360]'\n",
    "    ]\n",
    "\n",
    "    bins9 = [\n",
    "        '_(0, 45]', '_(45, 90]', '_(90, 135]',\n",
    "        '_(135, 180]', '_(180, 225]', '_(225, 270]',\n",
    "        '_(270, 315]', '_(315, 360]',\n",
    "    ]\n",
    "\n",
    "\n",
    "    # compute weighed wildfire exposure for each bin\n",
    "    for val in bins12:\n",
    "        # wind direction matches bearing is 1\n",
    "        gdf['wfe'+val] = gdf['bwdir'+val].astype(int) * gdf['bfire'+val].astype(int) \n",
    "\n",
    "        # account for wind speed and distance between fire and zip at birth\n",
    "        #gdf_hfpw['wfe'+val] = gdf_hfpw['wfe'+val] * gdf_hfpw.wspd/gdf_hfpw.fire_ZCTA10I_dist\n",
    "        gdf['wfe'+val] = gdf['wfe'+val]/gdf.fire_ZCTA10I_dist\n",
    "\n",
    "    # add instrument (sum over wildfire exposure (wfe) columns)\n",
    "    cols = [col for col in gdf.columns if col.startswith('wfe')]\n",
    "    gdf['wfe'] = gdf[cols].sum(axis=1)\n",
    "\n",
    "    # take average across all fires for a given ZCTA10I_month_year\n",
    "    gdf = gdf.groupby(['ZCTA10I_month_year'], as_index=False).wfe.sum()\n",
    "    \n",
    "    # rename wfe column\n",
    "    if time_period in ['9mbb', '12mab']:\n",
    "        gdf.rename(columns={'wfe':'wfe'+'_'+time_period}, inplace=True)\n",
    "\n",
    "    gdf.reset_index(\n",
    "        drop=True, \n",
    "        inplace=True\n",
    "    )\n",
    "    'ZCTA10I_centroid', 'ZCTA10I'\n",
    "    # keep only cols of interest\n",
    "    keep_cols = [val for val in gdf.columns if val.startswith(('ZCTA10I','wfe'))]\n",
    "    gdf = gdf[keep_cols]\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a3aa8f",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 4: Read and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571ce0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_health = preprocess_health(read_health())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c2820",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_health= preprocess_health(df_health, for_df=False)\n",
    "gdf_health.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_fires = preprocess_fires(read_fires())\n",
    "gdf_fires.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5942d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pm25 = preprocess_pm25(read_pm25())\n",
    "df_pm25.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf1fbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winds = preprocess_winds(read_winds())\n",
    "df_winds.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0074161f-0bb2-4e59-8411-57ab5cc8aceb",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 5: Impute missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a825cae-b14b-445a-a14b-f1096282cfc1",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">for PM25, and add averaged for 9 months before and 12 months after birth</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0453cf5-54c6-43bb-b37b-83ff8a59210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pm25 = impute_missing_PM25(gdf_health, df_pm25)\n",
    "df_pm25.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc9449e-bca7-4c1c-a2ba-487c4722ea09",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">for winds, and add averaged for 9 months before and 12 months after birth</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d0e072-ca6e-471e-a2ff-f910846b7572",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_winds = impute_missing_winds(gdf_health, df_winds)\n",
    "df_winds.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8345db6",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 6: Compute distance between fires and health zip code centroid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b112690a-10b3-4632-a95e-4b5ca964c0af",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">for current month of birth, and for 9 months before and 12 months after birth</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfbafdb-ed63-45c6-8f16-6c206be028a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for month and year of birth\n",
    "%time gdf_hf = compute_distance_bearing(gdf_health, gdf_fires, 'current')\n",
    "gdf_hf.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5251cf-b1a3-4678-9dd4-9faceec9bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 9 months before birth\n",
    "%time gdf_hf_9mbb = compute_distance_bearing(gdf_health, gdf_fires, '9mbb')\n",
    "gdf_hf_9mbb.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c738ed9d-49f9-4181-919a-6ca60e333b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 12 months after birth\n",
    "%time gdf_hf_12mab = compute_distance_bearing(gdf_health, gdf_fires, '12mab')\n",
    "gdf_hf_12mab.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005e10a7-b67a-43bf-9e70-7519915bf6c5",
   "metadata": {},
   "source": [
    "IMPORTANT: Note that some month_year (current, 9 months before or 12 months after birth) did not have a fire. Check fires_in_bthI_month_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22898572",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 7: Merge health, pm25, winds, and fires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78cdbdc-251e-4c5d-93f2-c81f0adf75e5",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">for current month of birth, and for 9 months before and 12 months after birth</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220ef739",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_hfpw = merge_dfs(gdf_hf, df_pm25, df_winds)\n",
    "gdf_hfpw_9mbb = merge_dfs(gdf_hf_9mbb, df_pm25, df_winds)\n",
    "gdf_hfpw_12mab = merge_dfs(gdf_hf_12mab, df_pm25, df_winds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b8321d-ac4b-4ea8-b796-70b3666ed8d8",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 8: Add wildfire instrument"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd44903-908b-4a4e-8acd-d7e439636084",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">for current month of birth, and for 9 months before and 12 months after birth</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0479fdc6-880b-4e74-92c7-b3aafa160fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_hfpwi = add_instrument(gdf_hfpw, time_period='current')\n",
    "gdf_hfpwi_9mbb = add_instrument(gdf_hfpw_9mbb, time_period='9mbb')\n",
    "gdf_hfpwi_12mab = add_instrument(gdf_hfpw_12mab, time_period='12mab')\n",
    "\n",
    "# merge all 3\n",
    "gdf_hfpwi = gdf_hfpwi.merge(\n",
    "    gdf_hfpwi_9mbb,\n",
    "    on='ZCTA10I_month_year',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "\n",
    "gdf_hfpwi = gdf_hfpwi.merge(\n",
    "    gdf_hfpwi_12mab,\n",
    "    on='ZCTA10I_month_year',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "gdf_hfpwi.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ac734c-f3ab-4de3-875b-ccb91c6cdea2",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 9: Add to health data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1f4bd7-1a8f-4c74-be10-0baf1b185718",
   "metadata": {},
   "source": [
    "the data is at the patient level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29174623",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Step 9: Merge with original health data\n",
    "# merge to original health data, df_health\n",
    "gdf_hfpwi = df_health.merge(\n",
    "    gdf_hfpwi,\n",
    "    on=['ZCTA10I_month_year'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# add pm25 again\n",
    "gdf_hfpwi = gdf_hfpwi.merge(\n",
    "        df_pm25,\n",
    "        left_on='ZCTA10I_month_year',\n",
    "        right_on='ZCTA10_month_year',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "# rename pm25 and wfe\n",
    "gdf_hfpwi.rename(\n",
    "    columns={'pm25':'pm25I',\n",
    "             'pm25_9mbb': 'pm25I_9mbb',\n",
    "             'pm25_12mab': 'pm25I_12mab',\n",
    "             'wfe':'wfeI',\n",
    "             'wfe_9mbb':'wfeI_9mbb',\n",
    "             'wfe_12mab':'wfeI_12mab'\n",
    "            },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "gdf_hfpwi.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfe0965",
   "metadata": {},
   "source": [
    "#### Step 9: Export to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cd434a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_hfpwi.to_csv(out_dir + 'analysis_data_birth_pdd_edd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91199ae-50d3-47f9-b5f5-9335faf17f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from icd9cms.icd9 import search\n",
    "temp = gdf_hfpwi.groupby('diagI00', as_index=False).data_source.count()\n",
    "temp.sort_values('data_source', ascending=False, inplace=True)\n",
    "temp.reset_index(drop=True, inplace=True)\n",
    "temp['diagI00_3d'] = temp.diagI00.str[:3]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397d6050-76ef-41ca-a3bd-2cb7d5e6b3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## find names of diagnosis in vocab ##\n",
    "######################################\n",
    "diag_vocab = temp[temp.diagI00_3d.str.startswith('9')].diagI00_3d.unique()\n",
    "diag_3d_dict = {}\n",
    "\n",
    "for val in diag_vocab:\n",
    "    try:\n",
    "        code = str(search(val)).split(':')[:2] # search() function is from icd9cms.icd9\n",
    "        diag_3d_dict[code[0]] = code[1]\n",
    "    except:\n",
    "        # if diag code is not in icd9cms.icd9, continue\n",
    "        continue\n",
    "diag_3d_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4e5d7f-2459-4b45-988f-2c1e46db4851",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[temp.diagI00_3d.str.startswith('54')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63e5095-f8bd-4ca4-8936-292a556ac347",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[temp.diagI00_3d.str.startswith('9')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
