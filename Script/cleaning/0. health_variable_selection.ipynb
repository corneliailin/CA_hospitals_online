{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main script to clean Health data\n",
    "\n",
    "Modules: N/A <br>\n",
    "Author: Cornelia Ilin <br>\n",
    "Email: cilin@ischool.berkeley.edu <br>\n",
    "Date created: March 24, 2022 <br>\n",
    "\n",
    "**Citations (online sources)**\n",
    "1. Birth Data source:\n",
    "    - California Department of Public Health\n",
    "2. Patient Dischrarge and Emergency Room:\n",
    "    - California Office of Statewide Health Planning and Development\n",
    "    \n",
    "**Citations (persons)**\n",
    "1. N/A\n",
    "\n",
    "**Preferred environment**\n",
    "1. Code written in Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Set working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = 'C:/Users/cilin/Research/CA_hospitals/Input/raw_data/health/'\n",
    "out_dir = 'C:/Users/cilin/Research/CA_hospitals/Input/interm_data/health/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReadFile:\n",
    "    ''' A class that reads .xlsx and .csv files\n",
    "    '''\n",
    "    def __init__(self, localdir, filename):\n",
    "        self.localdir = localdir\n",
    "        self.filename = filename\n",
    "        self.filepath = os.path.join(self.localdir, self.filename).replace('\\\\', '/')\n",
    "        \n",
    "    # read data    \n",
    "    def get_xlsx(self, sheetname, skiprows, header):\n",
    "        ''' A method that reads .xlsx files\n",
    "        # param sheetname: string, indicating the name of the tab in the Excel file\n",
    "        # param skiprows: integer, indicating the number of rows to skip in a tab\n",
    "        # param header: integer, set to 0 if  read first row as header; 1 otherwise\n",
    "        # return df\n",
    "        '''\n",
    "        self._data = pd.read_excel(self.filepath, sheetname, skiprows = skiprows, header = header)\n",
    "        return self._data\n",
    "    \n",
    "    def get_csv(self):\n",
    "        '''\n",
    "        # param: none\n",
    "        # return df\n",
    "        '''\n",
    "        self._data = pd.read_csv(self.filepath, sep = ',', dtype='str')\n",
    "        return self._data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ``read csv file names``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_file_names():\n",
    "    ''' Read .csv file names for each dataset\n",
    "    params:\n",
    "    -------\n",
    "    None\n",
    "    \n",
    "    return:\n",
    "    -------\n",
    "    csv_files (nested list): csv_files[i], where i indicates the index in data_names\n",
    "    '''\n",
    "    temp = []\n",
    "    csv_files = []\n",
    "    \n",
    "    # for each datasets\n",
    "    for i in range(len(data_names)): \n",
    "        # for each .csv file (year) in a dataset\n",
    "        dir_name = os.path.join(in_dir, data_names[i]).replace('\\\\','/')\n",
    "        for idx, file in enumerate(os.listdir(dir_name)): \n",
    "            if file.startswith(file_names[i]):\n",
    "                temp.append(file)\n",
    "        csv_files.append(temp) \n",
    "        temp = []\n",
    "    \n",
    "    print('Read .csv file names: Done')\n",
    "\n",
    "    return csv_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``select variables of interest``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_selection():\n",
    "    ''' For each .csv file, keep only vars of interest\n",
    "    params:\n",
    "    -------\n",
    "    None\n",
    "    \n",
    "    return:\n",
    "    -------\n",
    "    var_dict (dict): dictionary with variable names for each dataset = {Birth, PDD, EDD}\n",
    "    '''\n",
    "    var_dict = {}\n",
    "    for idx, key in enumerate(data_names):\n",
    "        var_dict[key] = pd.DataFrame() \n",
    "    \n",
    "    # for each dataset\n",
    "    for i, data in enumerate(data_names): \n",
    "        # open the data_selection.xlsx file and grab the tab of interest (tab_names)\n",
    "        var_dict[data] = ReadFile(in_dir, 'data_selection.xlsx') \n",
    "        var_dict[data] = var_dict[data].get_xlsx(tab_names[i], 2, 0)\n",
    "        \n",
    "        # keep var only if it's of use in the analysis\n",
    "        var_dict[data] = var_dict[data][\n",
    "            var_dict[data]['Use in the analysis [behrt]'].eq(1)\n",
    "        ]\n",
    "        \n",
    "        print('Variable selection for', data_names[i], 'data: Done')\n",
    "        \n",
    "    return var_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``read data``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    ''''''\n",
    "\n",
    "    # create empty dictionary with a df for each dataset in data_names\n",
    "    df_dict = {}\n",
    "    for idx, key in enumerate(data_names):\n",
    "        df_dict[key] = pd.DataFrame() \n",
    "\n",
    "    # for each dataset (Birth/PDD/EDD), read files and concatenate years\n",
    "    for i, data in enumerate(data_names):\n",
    "        print('-----------------------------------')\n",
    "        print(data, 'cleaning for each year...')\n",
    "        print('-----------------------------------')\n",
    "\n",
    "        # read .csv files\n",
    "        for idx, file in enumerate(csv_files[i]):\n",
    "            print('File:', file)\n",
    "            temp_df = ReadFile(in_dir + data + '/', file) \n",
    "            temp_df = temp_df.get_csv()\n",
    "\n",
    "            # check if var_dict for the year corresponding to the csv_file has more columns than temp_df\n",
    "            temp_col = np.setdiff1d(var_dict[data][years[i][idx]], temp_df.columns)\n",
    "            # if yes, then add the extra columns to temp_df\n",
    "            for col in temp_col:\n",
    "                temp_df[col] = np.nan\n",
    "\n",
    "            # keep only vars of interest\n",
    "            temp_df = temp_df.loc[:, var_dict[data][years[i][idx]]]\n",
    "\n",
    "            # standardize var name over time\n",
    "            temp_df.columns =  var_dict[data]['std_variable_name']  \n",
    "\n",
    "            # concat years\n",
    "            df_dict[data] = pd.concat(\n",
    "                [df_dict[data], temp_df],\n",
    "                axis=0\n",
    "            )\n",
    "\n",
    "        # reset index\n",
    "        df_dict[data].reset_index(\n",
    "            drop=True, \n",
    "            inplace=True\n",
    "        )\n",
    "        \n",
    "        # save to csv\n",
    "        #df_dict[data].to_csv(out_dir, data + '_all.csv')\n",
    "        \n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Create global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list with data names\n",
    "data_names = ['Birth', 'PDD', 'EDD']\n",
    "\n",
    "# create list with .csv data names\n",
    "file_names = ['lb', 'pdd', 'edd']\n",
    "\n",
    "# create list with tab names of interest as listed in the variable_names.xlsx file\n",
    "tab_names = ['Birth_all_sorted', 'PDD_all_sorted', 'EDD_all_sorted']\n",
    "\n",
    "# create list with year ranges for each dataset: Birth, PDD, EDD\n",
    "years = [np.arange(1991, 2013, 1), np.arange(1991, 2018, 1), np.arange(2005, 2018, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for each dataset (Birth/PDD/EDD) and each year ##\n",
    "\n",
    "# create list with .csv file names \n",
    "csv_files = csv_file_names()\n",
    "\n",
    "# keep only vars of interest\n",
    "var_dict = var_selection()\n",
    "\n",
    "# read data\n",
    "df_dict = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print shape of data\n",
    "obs = 0\n",
    "for idx, data in enumerate(data_names):\n",
    "    print(data + ' shape:', df_dict[data].shape)\n",
    "    obs+=df_dict[data].shape[0]\n",
    "    if idx==2:\n",
    "        print('Total obs across datasets:', obs/1000000, 'mil')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Export data to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in data_names:\n",
    "    print('Writing ' + data + ' to csv')\n",
    "    df_dict[data].to_csv(\n",
    "        out_dir + data +'.csv'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
