{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main script for Prediction Task\n",
    "\n",
    "Modules: N/A <br>\n",
    "Author: Cornelia Ilin <br>\n",
    "Email: cilin@wisc.edu <br>\n",
    "Date created: June 8, 2022 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import importlib\n",
    "import glob\n",
    "import re\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "# sklearn and others\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score as APS\n",
    "from sklearn.metrics import roc_auc_score as ROC_AUC\n",
    "from sklearn.metrics import precision_recall_curve as PRC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from itertools import cycle\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# user defined\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../../')\n",
    "from embeddings import utils_dt_prep\n",
    "from  embeddings import utils_MLM\n",
    "from embeddings import utils_embeddings\n",
    "import utils_dt_prep_pred_all\n",
    "import utils_classifier\n",
    "import utils_classifier_plus\n",
    "import utils_eval_downstream\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 2: Set-up config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    MAX_LEN = 40\n",
    "    BATCH_SIZE = 32\n",
    "    PAT_MIN_LENGTH = 3 #minimum number of visits\n",
    "    DIAG_PER_VISIT = 3 #diagnosis per visit to consider\n",
    "    DIAG_LENGTH = 2 # how many digits from diagnosis code to consider\n",
    "    train_pct = 0.8\n",
    "    val_pct = 0.1\n",
    "    seed = [1235, 1789, 2134, 1455, 1112] #1235\n",
    "    KEYS_diag = ['diag']\n",
    "    KEYS_diag_age = ['diag', 'age']\n",
    "    KEYS_diag_cnty = ['diag', 'cnty']\n",
    "    KEYS_diag_age_cnty = ['diag', 'age', 'cnty']\n",
    "    top_diag=10 #top diagmosis based on rocauc or aps\n",
    "    draw_train_val_test = False\n",
    "    create_Xy=False\n",
    "    save_model=True\n",
    "    load_model=False\n",
    "    \n",
    "    \n",
    "config = Config()\n",
    "config.seed = config.seed[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 3: Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read medical records for all patients with SSN and birth records\n",
    "df_init = utils_dt_prep.read_data_bpe()\n",
    "\n",
    "# print shapes and head\n",
    "print('Unique patients ', df_init.rlnI_updated.nunique())\n",
    "print('Number of encounters (shape of data) ', df_init.shape)\n",
    "df_init.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``drop observations and add features``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_dt_prep)\n",
    "print('Unique patients before preprocessing', df_init.rlnI_updated.nunique())\n",
    "\n",
    "# drop pbervations\n",
    "%time df = utils_dt_prep.drop_observations(df_init, config.PAT_MIN_LENGTH)\n",
    "# add features, includes visit summary (for diag, age, cnty)\n",
    "%time df = utils_dt_prep.add_features(df, config.DIAG_PER_VISIT, config.DIAG_LENGTH)\n",
    "\n",
    "# print stats\n",
    "print('Unique patients after preprocessing', df.rlnI_updated.nunique())\n",
    "print('Number of encounters after preprocessing (shape of data) ', df.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``create train, val, and test datasets``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.draw_train_val_test:\n",
    "    # find unique rlnIs in df\n",
    "    rlnIs = df.rlnI_updated.unique()\n",
    "\n",
    "    # split rlnIs into training, val, and test\n",
    "    np.random.seed(config.seed)\n",
    "    train_rlnI = np.random.choice(rlnIs, int(rlnIs.shape[0]*Config.train_pct), replace=False)\n",
    "    val_rlnI = np.random.choice(train_rlnI, int(train_rlnI.shape[0]*Config.val_pct), replace=False)\n",
    "    test_rlnI = list(set(rlnIs) - set(train_rlnI) - set (val_rlnI))\n",
    "    # save train_rlnIs, val_rlnIs, and test_rlnIs\n",
    "    np.save(\"./data/train_rlnI.npy\", train_rlnI)\n",
    "    np.save(\"./data/val_rlnI.npy\", val_rlnI)\n",
    "    np.save(\"./data/test_rlnI.npy\", test_rlnI)\n",
    "    \n",
    "else:\n",
    "    # load\n",
    "    train_rlnI = np.load(\"./data/train_rlnI.npy\", allow_pickle=\"TRUE\")\n",
    "    val_rlnI = np.load(\"./data/val_rlnI.npy\", allow_pickle=\"TRUE\")\n",
    "    test_rlnI = np.load(\"./data/test_rlnI.npy\", allow_pickle=\"TRUE\")\n",
    "    \n",
    "\n",
    "# pull train and test from df\n",
    "df_train = df[df.rlnI_updated.isin(train_rlnI)]\n",
    "df_val = df[df.rlnI_updated.isin(val_rlnI)]\n",
    "df_test = df[df.rlnI_updated.isin(test_rlnI)]\n",
    "\n",
    "print('Shape of df_train ', df_train.shape)\n",
    "print('Shape of df_val ', df_val.shape)\n",
    "print('Shape of df_test', df_test.shape)\n",
    "\n",
    "print('Unique patients in df_train ', df_train.rlnI_updated.nunique())\n",
    "print('Unique patients in df_val ', df_val.rlnI_updated.nunique())\n",
    "print('Unique patients in df_test ', df_test.rlnI_updated.nunique())\n",
    "\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_val.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">create input-output pairs</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_dt_prep_pred_all)\n",
    "df_train_in, df_train_out = utils_dt_prep_pred_all.input_output_pairs(df_train, config.PAT_MIN_LENGTH)\n",
    "df_val_in, df_val_out = utils_dt_prep_pred_all.input_output_pairs(df_val, config.PAT_MIN_LENGTH)\n",
    "df_test_in, df_test_out = utils_dt_prep_pred_all.input_output_pairs(df_test, config.PAT_MIN_LENGTH)\n",
    "\n",
    "# add df data to a dictionary and keep only cols of interest (used for Fairness tasks)\n",
    "cols = ['rlnI_updated', 'age', 'bthyearI', 'cntyresI', 'cntyresI_name', 'pm25I', 'wfeI', 'sexI', 'raceI', \n",
    "    'patcnty', 'raceM', 'meduc', 'precare', 'visitsM_9mpp', 'visitsM_1ypp', 'visitsI_1yol',\n",
    "    'bthresmb_name', 'prevsts']\n",
    "\n",
    "df_dict = {\n",
    "    'train_in': df_train_in[cols], 'val_in': df_val_in[cols], 'test_in': df_test_in[cols],\n",
    "    'train_out': df_train_out[cols], 'val_out': df_val_out[cols],'test_out': df_test_out[cols]\n",
    "}\n",
    "\n",
    "# drop duplicates\n",
    "for key in df_dict.keys():\n",
    "    df_dict[key].drop_duplicates(subset=['rlnI_updated'], inplace=True)\n",
    "    df_dict[key].reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print shapes\n",
    "for key in df_dict.keys():\n",
    "    print('Shape of df ' + key, df_dict[key].shape)\n",
    "    \n",
    "for key in df_dict.keys():\n",
    "    if 'out' in key:\n",
    "        print('Unique patients in df ' + key.split('_')[0], df_dict[key].rlnI_updated.nunique())\n",
    "        # drop rlnI_updated column\n",
    "        df_dict[key].drop(columns='rlnI_updated', inplace=True)\n",
    "    else:\n",
    "        df_dict[key].drop(columns='rlnI_updated', inplace=True)\n",
    "        \n",
    "# save data dict\n",
    "np.save('./data/df_dict.npy', df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">create patient history for df_in data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(utils_dt_prep)\n",
    "\n",
    "print('df_train_in')\n",
    "print('-----------')\n",
    "%time hist_dict_train_in = utils_dt_prep.add_history(df_train_in)\n",
    "\n",
    "print('df_train_in')\n",
    "print('-----------')\n",
    "%time hist_dict_val_in = utils_dt_prep.add_history(df_val_in)\n",
    "\n",
    "print('\\ndf_test_in')\n",
    "print('-----------')\n",
    "%time hist_dict_test_in = utils_dt_prep.add_history(df_test_in)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print example patient in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_in[df_train_in.rlnI_updated.eq('00003PWWP')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_out[df_train_out.rlnI_updated.eq('00003PWWP')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Step 5: Create vocab used in MLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">import data used in MLM</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mlm = np.load(\"../../../embeddings/data/X.npy\", allow_pickle=\"TRUE\").item()\n",
    "\n",
    "print('X', X_mlm.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">load vocab used in MLM</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vect layer\n",
    "vect_layer = {}\n",
    "for key in config.KEYS_diag_age_cnty:\n",
    "    vect_layer[key] = tf.keras.models.load_model('../../../embeddings/vectorizers/vect_layer_'+key)\n",
    "    vect_layer[key] = vect_layer[key].layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mask token id for masked language model\n",
    "mask_token_id = vect_layer['diag']([\"[MASK]\"]).numpy()[0][0]\n",
    "print('ID of masked token', mask_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">Create id2token and token2id mappings</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty dict\n",
    "id2token = {}\n",
    "token2id = {}\n",
    "\n",
    "for key in config.KEYS_diag_age_cnty:\n",
    "    id2token[key] = dict(enumerate(vect_layer[key].get_vocabulary()))\n",
    "    token2id[key] = {y: x for x, y in id2token[key].items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 6: Encode downstream data based on MLM vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">Create features and labels</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.create_Xy:\n",
    "    # create empty dict\n",
    "    X_train = {}\n",
    "    X_val = {}\n",
    "    X_test = {}\n",
    "\n",
    "    # add key and value for each feature\n",
    "    for key in config.KEYS_diag_age_cnty:\n",
    "        X_train[key] = hist_dict_train_in[key]['pat_'+key+'_hist'].values\n",
    "        X_val[key] = hist_dict_val_in[key]['pat_'+key+'_hist'].values\n",
    "        X_test[key] = hist_dict_test_in[key]['pat_'+key+'_hist'].values\n",
    "\n",
    "    # create outcome for each patient\n",
    "    df_train_out['diag00_2d'] = df_train_out['diag00_2d'].astype(str)\n",
    "    df_val_out['diag00_2d'] = df_val_out['diag00_2d'].astype(str)\n",
    "    df_test_out['diag00_2d'] = df_test_out['diag00_2d'].astype(str)\n",
    "    y_train = df_train_out.diag00_2d # predict main diagnosis code in next visit\n",
    "    y_val = df_val_out.diag00_2d # predict main diagnosis code in next visit\n",
    "    y_test = df_test_out.diag00_2d # predict main diagnosis code in next visit\n",
    "    \n",
    "    # save\n",
    "    np.save('./data/X_train.npy', X_train)\n",
    "    np.save('./data/X_val.npy', X_val)\n",
    "    np.save('./data/X_test.npy', X_test)\n",
    "    np.save('./data/y_train.npy', y_train)\n",
    "    np.save('./data/y_val.npy', y_val)\n",
    "    np.save('./data/y_test.npy', y_test)\n",
    "    \n",
    "else:\n",
    "    # load data\n",
    "    X_train = np.load(\"./data/X_train.npy\", allow_pickle=\"TRUE\").item()\n",
    "    X_val = np.load(\"./data/X_val.npy\", allow_pickle=\"TRUE\").item()\n",
    "    X_test = np.load(\"./data/X_test.npy\", allow_pickle=\"TRUE\").item()\n",
    "    y_train = np.load(\"./data/y_train.npy\", allow_pickle=\"TRUE\")\n",
    "    y_val = np.load(\"./data/y_val.npy\", allow_pickle=\"TRUE\")\n",
    "    y_test = np.load(\"./data/y_test.npy\", allow_pickle=\"TRUE\")\n",
    "    df_dict = np.load('./data/df_dict.npy', allow_pickle=\"TRUE\").item()\n",
    "\n",
    "    print('Shape of X_train_diag ', X_train['diag'].shape)\n",
    "    print('Shape of X_train_age ', X_train['age'].shape)\n",
    "    print('Shape of y_train ', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">Encode features</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty dict\n",
    "X_train_tokenized = {}\n",
    "X_val_tokenized = {}\n",
    "X_test_tokenized = {}\n",
    "\n",
    "for key in config.KEYS_diag_age_cnty:\n",
    "    X_train_tokenized[key] = utils_dt_prep.encode(vect_layer[key], X_train[key])\n",
    "    X_val_tokenized[key] = utils_dt_prep.encode(vect_layer[key], X_val[key])\n",
    "    X_test_tokenized[key] = utils_dt_prep.encode(vect_layer[key], X_test[key])\n",
    "\n",
    "# print shape\n",
    "print('Shape of X_train_tokenized ', X_train_tokenized['diag'].shape)\n",
    "print('Shape of X_val_tokenized ', X_val_tokenized['diag'].shape)\n",
    "print('Shape of X_test_tokenized ', X_test_tokenized['age'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">Encode outcomes</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# union of train and test\n",
    "y_union = np.union1d(y_train, y_val).tolist()\n",
    "y_union = np.union1d(y_union, y_test).tolist()\n",
    "y_union_tokenized = utils_dt_prep.encode(vect_layer['diag'], y_union)[:,0]\n",
    "y_union_tokenized = np.unique(y_union_tokenized, axis=0) #token 1 shows up two times\n",
    "\n",
    "# train\n",
    "y_train_tokenized = utils_dt_prep.encode(vect_layer['diag'], y_train)[:,0]\n",
    "y_train_tokenized = pd.get_dummies(y_train_tokenized, drop_first=False).reindex(columns = y_union_tokenized, fill_value=0)\n",
    "y_train_tokenized_cols = np.array(y_train_tokenized.columns)\n",
    "y_train_tokenized = y_train_tokenized.to_numpy()\n",
    "\n",
    "# val\n",
    "y_val_tokenized = utils_dt_prep.encode(vect_layer['diag'], y_val)[:,0]\n",
    "y_val_tokenized = pd.get_dummies(y_val_tokenized, drop_first=False).reindex(columns = y_union_tokenized, fill_value=0)\n",
    "y_val_tokenized_cols = np.array(y_val_tokenized.columns)\n",
    "y_val_tokenized = y_val_tokenized.to_numpy()\n",
    "\n",
    "# test\n",
    "y_test_tokenized = utils_dt_prep.encode(vect_layer['diag'], y_test)[:,0]\n",
    "y_test_tokenized = pd.get_dummies(y_test_tokenized, drop_first=False).reindex(columns = y_union_tokenized, fill_value=0)\n",
    "y_test_tokenized_cols = np.array(y_test_tokenized.columns)\n",
    "y_test_tokenized = y_test_tokenized.to_numpy()\n",
    "\n",
    "print('Shape y_train_tokenized ', y_train_tokenized.shape)\n",
    "print('Shape y_val_tokenized ', y_val_tokenized.shape)\n",
    "print('Shape y_test_tokenized ', y_test_tokenized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect non-encoded and encoded histories and outcome in next visit for the first patient in my training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient history\n",
    "for key in config.KEYS_diag_age_cnty:\n",
    "    print(key, 'nenc: ', X_train[key][0])\n",
    "    print(key, 'enc: ', X_train_tokenized[key][0])\n",
    "    print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient outcome in the next visit (first 20)\n",
    "y_train_tokenized[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tokenized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:orange\">!! Decide what embeddings you will use</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = config.KEYS_diag_age_cnty\n",
    "\n",
    "# define subset of X_train_tokenized\n",
    "X_train_tokenized_subset = {}\n",
    "for key in keys:\n",
    "    X_train_tokenized_subset[key] = X_train_tokenized[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = config.KEYS_diag_age_cnty\n",
    "\n",
    "# define subset of X_train_tokenized\n",
    "X_val_tokenized_subset = {}\n",
    "for key in keys:\n",
    "    X_val_tokenized_subset[key] = X_val_tokenized[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = config.KEYS_diag_age_cnty\n",
    "# other options are config.KEYS_diag_seg_pos_age_zip, config.KEYS_diag_seg_pos\n",
    "\n",
    "# define subset of X_train_tokenized\n",
    "X_test_tokenized_subset = {}\n",
    "for key in keys:\n",
    "    X_test_tokenized_subset[key] = X_test_tokenized[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">Convert train, val, and test subsets to tensors</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(config.seed)\n",
    "\n",
    "# create sample_weights (this is how the MLM was trained)\n",
    "sample_weights_train = np.ones(y_train_tokenized.shape[0])\n",
    "\n",
    "train_tensor = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_train_tokenized_subset, y_train_tokenized, sample_weights_train)))\n",
    "train_tensor = train_tensor.shuffle(1000).batch(config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(config.seed)\n",
    "\n",
    "# create sample_weights (this is how the MLM was trained)\n",
    "sample_weights_val = np.ones(y_val_tokenized.shape[0])\n",
    "\n",
    "val_tensor = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_val_tokenized_subset, y_val_tokenized, sample_weights_val)))\n",
    "val_tensor = val_tensor.shuffle(1000).batch(config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(config.seed)\n",
    "\n",
    "# create sample_weights (this is how the MLM was trained)\n",
    "sample_weights_test = np.ones(y_test_tokenized.shape[0])\n",
    "\n",
    "test_tensor = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_test_tokenized_subset, y_test_tokenized, sample_weights_test)))\n",
    "test_tensor = test_tensor.shuffle(1000).batch(config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 7: Next visit diagnosis (downstream task)\n",
    "\n",
    "I will use my self-supervised MLM model on a downstream task of next visit diagnosis classification.\n",
    "To do this, I will import the trained MLM model, and I will create a multilabel classifier by adding a pooling layer and a Dense layer on top of the pretrained MLM features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``import TDecoder model``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained bert model\n",
    "TDecoder_model = keras.models.load_model(\n",
    "    \"../../../embeddings/TDecoder_age_cnty.h5\"\n",
    ")\n",
    "\n",
    "# remove the classification layer\n",
    "pretrained_TDecoder_model = tf.keras.Model(\n",
    "    TDecoder_model.input, TDecoder_model.get_layer(\"encoder_0/ffn_layernormalization\").output\n",
    ")\n",
    "\n",
    "pretrained_TDecoder_model.trainable = True\n",
    "\n",
    "# Freeze it\n",
    "#pretrained_TDecoder_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "temp =  train_tensor.take(10)\n",
    "temp_embeddings = pretrained_TDecoder_model.predict(temp)\n",
    "temp_embeddings.shape\n",
    "\n",
    "\n",
    "token_emb = mlm_model.get_layer(\"encoder_0/ffn_layernormalization\").output\n",
    "token_emb_average = tf.keras.layers.GlobalAveragePooling1D()(token_emb)\n",
    "token_emb_averageg\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">extract token (patient visit) embeddings</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this only prints the output of the encoder_0/ffn_layernormalization of the mlm model\n",
    "#train_token_embeddings = pretrained_TDecoder_model.predict(X_train_tokenized)\n",
    "#train_token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this only prints the output of the encoder_0/ffn_layernormalization of the mlm model\n",
    "#test_token_embeddings = pretrained_TDecoder_model.predict(X_test_tokenized)\n",
    "#test_token_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">extract sentence (patient history) embeddings</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_pool_embeddings = tf.keras.layers.GlobalAveragePooling1D()(train_token_embeddings).numpy()\n",
    "#train_pool_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_pool_embeddings = tf.keras.layers.GlobalAveragePooling1D()(test_token_embeddings).numpy()\n",
    "#test_pool_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Downstream task``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">calculate initial bias</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "calc_init_bias = False\n",
    "if calc_init_bias:\n",
    "    importlib.reload(utils_classifier) \n",
    "    bias_init, class_weight = utils_classifier.initial_weights(vect_layer, df, y_union, y_train_tokenized_cols)\n",
    "    print('Length of initial bias', len(bias_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">add early stopping</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = True\n",
    "if early_stopping:\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    verbose=1,\n",
    "    patience=2,\n",
    "    mode='min',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">define model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(utils_classifier) \n",
    "classifier_model = utils_classifier.classifier_model(\n",
    "    pretrained_TDecoder_model,\n",
    "    y_train_tokenized.shape[1],\n",
    "    keys,\n",
    "    #bias_init\n",
    ")\n",
    "classifier_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">fit model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the classifier with unfrozen BERT MLM layers\n",
    "hist = classifier_model.fit(\n",
    "    train_tensor,\n",
    "    validation_data=val_tensor,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">plot loss and accuracy</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab history\n",
    "history = hist.history\n",
    "\n",
    "# plot loss for train and validation\n",
    "fig = plt.figure(figsize=(12, 2))\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "plt.plot(history['loss'], lw=2, color='darkgoldenrod')\n",
    "plt.plot(history['val_loss'], lw=2, color='indianred')\n",
    "plt.legend(['Train', 'Validation'], fontsize=10)\n",
    "#plt.ylim(0,0.2)\n",
    "ax.set_xlabel('Epochs', size=10)\n",
    "ax.set_title('Loss');\n",
    "\n",
    "# plot accuracy for train and validation\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "plt.plot(history['accuracy'], lw=2, color='darkgoldenrod')\n",
    "plt.plot(history['val_accuracy'], lw=2, color='indianred')\n",
    "plt.legend(['Train', 'Validation'], fontsize=10)\n",
    "#plt.ylim(0.7,1)\n",
    "ax.set_xlabel('Epochs', size=10)\n",
    "ax.set_title('Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">save or load model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.save_model:\n",
    "    classifier_model.save(\"./cls_model_base+age+cnty(TDecoder).h5\", include_optimizer=False)\n",
    "if config.load_model:\n",
    "    classifier_model = keras.models.load_model(\"./cls_model_base+age+cnty(TDecoder).h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">predictions  (on test data)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_tokenized_pred = classifier_model.predict(X_train_tokenized_subset)\n",
    "#y_train_tokenized_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_tokenized_pred = classifier_model.predict(X_test_tokenized_subset)\n",
    "y_test_tokenized_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">example predictions for next visit diagnosis</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat_id = 145\n",
    "# find ground truth diagnosis\n",
    "print('Next visit diagnosis for patient ID', pat_id)\n",
    "print('---------------------------------------')\n",
    "print('Ground truth diagnosis: ', y_test[pat_id])\n",
    "\n",
    "# find predicted probability of next visit diagnosis\n",
    "diag_index = np.where(y_test_tokenized[pat_id] == 1)\n",
    "diag_prob = y_test_tokenized_pred[pat_id][diag_index]\n",
    "print('Ground truth predict prob: ', diag_prob)\n",
    "\n",
    "# find top 5 predicted probabilities of next visit diagnosis\n",
    "top5_diag_index = y_test_tokenized_pred[pat_id].argsort()[-5 :][::-1]\n",
    "top5_diag_prob = y_test_tokenized_pred[pat_id][top5_diag_index]\n",
    "print('Top 5 diag predict prob: ', top5_diag_prob)\n",
    "\n",
    "# find diag codes associated with top 5 predicted probabilities \n",
    "top5_tokens = y_test_tokenized_cols[top5_diag_index]\n",
    "top5_diag_code = \" \".join([id2token['diag'][t] for t in top5_tokens if t != 0])\n",
    "print('Top 5 diag codes: ', top5_diag_code)\n",
    "\n",
    "# find previous diag history\n",
    "print(X_test['diag'][pat_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">Metrics (model evaluation)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at the diagnostic level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_eval_downstream)\n",
    "start_time= time.time()\n",
    "recall_diag, precision_diag, fpr_diag, tpr_diag, df_aps_auc_diag, df_y_cols = utils_eval_downstream.metrics_each_diagnosis(\n",
    "    y_union_tokenized,\n",
    "    id2token,\n",
    "    y_test_tokenized_pred,\n",
    "    y_test_tokenized,\n",
    "    y_test\n",
    ")\n",
    "\n",
    "# print execution time\n",
    "print('Execution time:', np.round((time.time()-start_time)/60, 2), 'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at the micro or samples level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time= time.time()\n",
    "precision_micro, recall_micro, fpr_micro, tpr_micro, aps_samples, area_micro = utils_eval_downstream.metrics_averages(\n",
    "    y_union_tokenized,\n",
    "    id2token,\n",
    "    y_test_tokenized_pred,\n",
    "    y_test_tokenized\n",
    ")\n",
    "\n",
    "# print execution time\n",
    "print('Execution time:', np.round((time.time()-start_time)/60, 2), 'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print TDecoder (micro/samples) metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average precission score:',\n",
    "      np.round(aps_samples,3)\n",
    ")\n",
    "print('ROC AUC:',\n",
    "      np.round(area_micro,3)\n",
    ")\n",
    "\n",
    "# add APS and ROC areato a df\n",
    "temp_df = pd.DataFrame(\n",
    "        {'metric': ['APS', 'AUC'],\n",
    "         'value': [aps_samples, area_micro]\n",
    "        }\n",
    "    )\n",
    "\n",
    "temp_df['seed'] = config.seed\n",
    "\n",
    "# export metrics to csv\n",
    "temp_df.to_csv('./results/ApsAucDownstream__base+age+cnty(TDecoder).csv', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print TDecoder (for each disease) plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_eval_downstream)\n",
    "start_time= time.time()\n",
    "utils_eval_downstream.plot_pr_roc(\n",
    "    recall_diag, precision_diag, fpr_diag,\n",
    "    tpr_diag, df_aps_auc_diag, precision_micro,\n",
    "    recall_micro, fpr_micro, tpr_micro, aps_samples,\n",
    "    area_micro, config.top_diag)\n",
    "\n",
    "\n",
    "# save data to dictionary\n",
    "dict_metrics = {\n",
    "    'recall_diag': recall_diag,\n",
    "    'precision_diag': precision_diag,\n",
    "    'fpr_diag': fpr_diag,\n",
    "    'tpr_diag': tpr_diag,\n",
    "    'df_aps_auc_diag': df_aps_auc_diag,\n",
    "    'precision_micro': precision_micro,\n",
    "    'recall_micro': recall_micro,\n",
    "    'fpr_micro': fpr_micro,\n",
    "    'tpr_micro': tpr_micro,\n",
    "    'aps_samples': aps_samples,\n",
    "    'area_micro': area_micro,\n",
    "    'config.top_diag': config.top_diag\n",
    "}\n",
    "\n",
    "# print execution time\n",
    "print('Execution time:', np.round((time.time()-start_time)/60, 2), 'minutes')\n",
    "\n",
    "np.save('./results/EachApsAucDownstream__base+age+cnty(TDecoder)_'+ str(config.seed)+ '_.npy', dict_metrics) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`FairAware tasks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time= time.time()\n",
    "temp_df_test_out = df_dict['test_out'].copy()\n",
    "importlib.reload(utils_eval_downstream)\n",
    "\n",
    "temp_df_test_out = utils_eval_downstream.fairaware_cleaning(temp_df_test_out)\n",
    "utils_eval_downstream.fairaware_plots(\n",
    "    temp_df_test_out, y_test_tokenized_cols,\n",
    "    id2token, y_test_tokenized_pred, y_test_tokenized\n",
    ")\n",
    "\n",
    "# print execution time\n",
    "print('Execution time:', np.round((time.time()-start_time)/60, 2), 'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Extrinsic Evaluation of Embeddings based on prediction distribution by sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings_extrinsic_eval = pd.DataFrame()\n",
    "for disease in ['Congenital Anomalies', 'Tuberculosis']:\n",
    "    # find the index of the disease of interest\n",
    "    #print('Index of disease of interest:')\n",
    "    #print('-----------------------------')\n",
    "    idx  = df_y_cols[df_y_cols.diag_name.str.startswith(disease)].index[0]\n",
    "    display(idx)\n",
    "    #print('\\n')\n",
    "\n",
    "    # pull out ground truth for disease at idx = idx (these will be binary 0 or 1)\n",
    "    #print('Ground truth')\n",
    "    #print('------------')\n",
    "    temp_tokenized = y_test_tokenized[:, idx]\n",
    "    #display(temp_tokenized)\n",
    "    #print('\\n')\n",
    "\n",
    "    # pull out predictions for disease at idx = idx (these will be probabilities)\n",
    "    #print('Predictions (probabilities)')\n",
    "    #print('---------------------------')\n",
    "    temp_tokenized_pred = y_test_tokenized_pred[:, idx]\n",
    "    #display(temp_tokenized_pred)\n",
    "    #print('\\n')\n",
    "\n",
    "    # pull out sexI values from df_test_out\n",
    "    #print('Gender values')\n",
    "    sexI = temp_df_test_out.sexI.values\n",
    "    #display(sexI)\n",
    "    #print('\\n')\n",
    "\n",
    "    # print distribution of those M vs. F if probability greater than the mean probability\n",
    "    # this means the predicted outcomes is that is has the disease of interest\n",
    "    temp_pred = list(sexI[temp_tokenized_pred>temp_tokenized_pred.mean()])\n",
    "    temp_pred = pd.DataFrame({'disease': disease, 'sexI_distribution': temp_pred})\n",
    "    \n",
    "    # add to df\n",
    "    embeddings_extrinsic_eval = pd.concat([embeddings_extrinsic_eval, temp_pred], axis=0) \n",
    "    \n",
    "embeddings_extrinsic_eval[embeddings_extrinsic_eval.disease.eq('Tuberculosis')].sexI_distribution.hist()\n",
    "embeddings_extrinsic_eval[embeddings_extrinsic_eval.disease.eq('Congenital Anomalies')].sexI_distribution.hist()\n",
    "\n",
    "# save to pdf\n",
    "embeddings_extrinsic_eval.to_csv('./results/embeddings_extrinsic_eval_base+age+cnty(TDecoder)_'+str(config.seed)+'_.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "``downstream task + extra features``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">extract patient (sentence) embeddings from classifier_model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define embeddings model \n",
    "classifier_model_embed = tf.keras.Model(\n",
    "    classifier_model.input, classifier_model.get_layer(\"global_max_pooling1d\").output\n",
    ")\n",
    "\n",
    "# extract embeddings from classification model\n",
    "train_embeddings_pool = classifier_model_embed.predict(X_train_tokenized_subset)\n",
    "val_embeddings_pool = classifier_model_embed.predict(X_val_tokenized_subset)\n",
    "test_embeddings_pool = classifier_model_embed.predict(X_test_tokenized_subset)\n",
    "\n",
    "print('Shape of train:', train_embeddings_pool.shape)\n",
    "print('Shape of train:', val_embeddings_pool.shape)\n",
    "print('Shape of test:', test_embeddings_pool.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">create extra features</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_tokenized_subset_plus = utils_classifier_plus.create_extra_features(df_dict['train_in'], train_embeddings_pool)\n",
    "X_val_tokenized_subset_plus = utils_classifier_plus.create_extra_features(df_dict['val_in'], val_embeddings_pool)\n",
    "X_test_tokenized_subset_plus = utils_classifier_plus.create_extra_features(df_dict['test_in'], test_embeddings_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for columns that are extra between training and validation\n",
    "col_diff_train_val = np.setdiff1d(list(X_train_tokenized_subset_plus.columns), list(X_val_tokenized_subset_plus.columns))\n",
    "col_diff_train_val = list(col_diff_train_val)\n",
    "print('Columns difference train_val', col_diff_train_val)\n",
    "# drop column from X_train_tokenized_subset_plus\n",
    "X_train_tokenized_subset_plus.drop(columns=col_diff_train_val, inplace=True)\n",
    "\n",
    "## check for columns that are extra between training and test\n",
    "col_diff_train_test = np.setdiff1d(list(X_train_tokenized_subset_plus.columns), list(X_test_tokenized_subset_plus.columns))\n",
    "col_diff_train_test = list(col_diff_train_test)\n",
    "print('Columns difference train_test', col_diff_train_test)\n",
    "# drop column from X_train_tokenized_subset_plus\n",
    "X_train_tokenized_subset_plus.drop(columns=col_diff_train_test, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">convert train, val, and test sets to tensors</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(config.seed)\n",
    "\n",
    "train_plus_tensor = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_train_tokenized_subset_plus, y_train_tokenized)))\n",
    "train_plus_tensor = train_plus_tensor.shuffle(1000).batch(config.BATCH_SIZE)\n",
    "\n",
    "val_plus_tensor = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_val_tokenized_subset_plus, y_val_tokenized)))\n",
    "val_plus_tensor = val_plus_tensor.shuffle(1000).batch(config.BATCH_SIZE)\n",
    "\n",
    "test_plus_tensor = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_test_tokenized_subset_plus, y_test_tokenized)))\n",
    "test_plus_tensor = test_plus_tensor.shuffle(1000).batch(config.BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">define model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_classifier_plus)\n",
    "classifier_plus_model = utils_classifier_plus.classifier_plus_model(\n",
    "    X_train_tokenized_subset_plus.shape[1],\n",
    "    y_train_tokenized.shape[1]\n",
    ")\n",
    "classifier_plus_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">fit model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "hist = classifier_plus_model.fit(\n",
    "    train_plus_tensor,\n",
    "    validation_data=val_plus_tensor,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">plot loss and accuracy</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab history\n",
    "history = hist.history\n",
    "\n",
    "# plot loss for train and validation\n",
    "fig = plt.figure(figsize=(12, 2))\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "plt.plot(history['loss'], lw=2, color='darkgoldenrod')\n",
    "plt.plot(history['val_loss'], lw=2, color='indianred')\n",
    "plt.legend(['Train', 'Validation'], fontsize=10)\n",
    "#plt.ylim(0,0.2)\n",
    "ax.set_xlabel('Epochs', size=10)\n",
    "ax.set_title('Loss');\n",
    "\n",
    "# plot accuracy for train and validation\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "plt.plot(history['accuracy'], lw=2, color='darkgoldenrod')\n",
    "plt.plot(history['val_accuracy'], lw=2, color='indianred')\n",
    "plt.legend(['Train', 'Validation'], fontsize=10)\n",
    "#plt.ylim(0.7,1)\n",
    "ax.set_xlabel('Epochs', size=10)\n",
    "ax.set_title('Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">save or load</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.save_model:\n",
    "    classifier_model.save(\"./cls_model_plus_base+age+cnty(TDecoder).h5\", include_optimizer=False)\n",
    "if config.load_model:\n",
    "    classifier_model = keras.models.load_model(\"./cls_model_plus_base+age+cnty(TDecoder).h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">predictions  (on train and test data)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_tokenized_plus_pred = classifier_plus_model.predict(X_train_tokenized_subset_plus)\n",
    "#y_train_tokenized_plus_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_tokenized_plus_pred = classifier_plus_model.predict(X_test_tokenized_subset_plus)\n",
    "y_test_tokenized_plus_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">Metrics (model evaluation)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at the micro or samples level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time= time.time()\n",
    "precision_micro_plus, recall_micro_plus,\\\n",
    "fpr_micro_plus, tpr_micro_plus,\\\n",
    "aps_samples_plus, area_micro_plus = utils_eval_downstream.metrics_averages(\n",
    "    y_test_tokenized_cols,\n",
    "    id2token,\n",
    "    y_test_tokenized_plus_pred,\n",
    "    y_test_tokenized\n",
    ")\n",
    "\n",
    "# print execution time\n",
    "print('Execution time:', np.round((time.time()-start_time)/60, 2), 'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print TDecoder (for each disease) plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average precission score:',\n",
    "      np.round(aps_samples_plus,3)\n",
    ")\n",
    "print('ROC AUC:',\n",
    "      np.round(area_micro_plus,3)\n",
    ")\n",
    "\n",
    "# add APS and ROC areato a df\n",
    "metrics_plus = pd.DataFrame(\n",
    "        {'metric': ['APS', 'AUC'],\n",
    "         'value': [aps_samples_plus, area_micro_plus]\n",
    "        }\n",
    "    )\n",
    "\n",
    "metrics_plus['seed'] = config.seed\n",
    "# export metrics to csv\n",
    "metrics_plus.to_csv('./results/ApsAucDownstreamExtra__base+age+cnty(TDecoder).csv', mode='a')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
