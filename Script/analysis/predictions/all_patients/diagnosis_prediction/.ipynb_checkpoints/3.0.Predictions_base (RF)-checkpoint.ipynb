{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main script for Prediction Task\n",
    "\n",
    "Modules: N/A <br>\n",
    "Author: Cornelia Ilin <br>\n",
    "Email: cilin@wisc.edu <br>\n",
    "Date created: June 8, 2022 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import importlib\n",
    "import glob\n",
    "import re\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "# sklearn and others\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score as APS\n",
    "from sklearn.metrics import roc_auc_score as ROC_AUC\n",
    "from sklearn.metrics import precision_recall_curve as PRC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from itertools import cycle\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# user defined\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../../')\n",
    "from embeddings import utils_dt_prep\n",
    "from  embeddings import utils_MLM\n",
    "import utils_dt_prep_pred_all\n",
    "import utils_classifier_random_embed\n",
    "import utils_classifier_logistic\n",
    "import utils_classifier_plus\n",
    "import utils_eval_downstream\n",
    "from embeddings import utils_embeddings\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 2: Set-up config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    MAX_LEN = 40\n",
    "    BATCH_SIZE = 32\n",
    "    PAT_MIN_LENGTH = 3 #minimum number of visits\n",
    "    DIAG_PER_VISIT = 3 #diagnosis per visit to consider\n",
    "    DIAG_LENGTH = 2 # how many digits from diagnosis code to consider\n",
    "    PRIMARY_DIAG_ONLY = True\n",
    "    DIAG3 = True\n",
    "    train_pct = 0.8\n",
    "    val_pct = 0.1\n",
    "    seed = [1235, 1789, 2134, 1455, 1112] #1235\n",
    "    top_diag = 10 #top diagmosis based on rocauc or aps\n",
    "    draw_train_val_test = False\n",
    "    save_model = True\n",
    "    load_model = False\n",
    "    \n",
    "config = Config()\n",
    "config.seed = config.seed[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 3: Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_dt_prep)\n",
    "# read medical records for all patients with SSN and birth records\n",
    "df_init = utils_dt_prep.read_data_bpe()\n",
    "\n",
    "# print shapes and head\n",
    "print('Unique patients ', df_init.rlnI_updated.nunique())\n",
    "print('Number of encounters (shape of data) ', df_init.shape)\n",
    "df_init.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``drop observations and add features``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_dt_prep)\n",
    "print('Unique patients before preprocessing', df_init.rlnI_updated.nunique())\n",
    "\n",
    "# drop pbervations\n",
    "%time df = utils_dt_prep.drop_observations(df_init, config.PAT_MIN_LENGTH)\n",
    "# add features, includes visit summary (for diag, age, cnty)\n",
    "%time df = utils_dt_prep.add_features(df, config.DIAG_PER_VISIT, config.DIAG_LENGTH)\n",
    "\n",
    "# print stats\n",
    "print('Unique patients after preprocessing', df.rlnI_updated.nunique())\n",
    "print('Number of encounters after preprocessing (shape of data) ', df.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``create train, val, and test datasets``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.draw_train_val_test:\n",
    "    # find unique rlnIs in df\n",
    "    rlnIs = df.rlnI_updated.unique()\n",
    "\n",
    "    # split rlnIs into training, val, and test\n",
    "    np.random.seed(config.seed)\n",
    "    train_rlnI = np.random.choice(rlnIs, int(rlnIs.shape[0]*Config.train_pct), replace=False)\n",
    "    val_rlnI = np.random.choice(train_rlnI, int(train_rlnI.shape[0]*Config.val_pct), replace=False)\n",
    "    test_rlnI = list(set(rlnIs) - set(train_rlnI) - set (val_rlnI))\n",
    "    # save train_rlnIs, val_rlnIs, and test_rlnIs\n",
    "    np.save(\"./data/train_rlnI.npy\", train_rlnI)\n",
    "    np.save(\"./data/val_rlnI.npy\", val_rlnI)\n",
    "    np.save(\"./data/test_rlnI.npy\", test_rlnI)\n",
    "    \n",
    "else:\n",
    "    # load\n",
    "    train_rlnI = np.load(\"./data/train_rlnI.npy\", allow_pickle=\"TRUE\")\n",
    "    val_rlnI = np.load(\"./data/val_rlnI.npy\", allow_pickle=\"TRUE\")\n",
    "    test_rlnI = np.load(\"./data/test_rlnI.npy\", allow_pickle=\"TRUE\")\n",
    "    \n",
    "\n",
    "# pull train and test from df\n",
    "df_train = df[df.rlnI_updated.isin(train_rlnI)]\n",
    "df_val = df[df.rlnI_updated.isin(val_rlnI)]\n",
    "df_test = df[df.rlnI_updated.isin(test_rlnI)]\n",
    "\n",
    "print('Shape of df_train ', df_train.shape)\n",
    "print('Shape of df_val ', df_val.shape)\n",
    "print('Shape of df_test', df_test.shape)\n",
    "\n",
    "print('Unique patients in df_train ', df_train.rlnI_updated.nunique())\n",
    "print('Unique patients in df_val ', df_val.rlnI_updated.nunique())\n",
    "print('Unique patients in df_test ', df_test.rlnI_updated.nunique())\n",
    "\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_val.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">create input-output pairs</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_dt_prep_pred_all)\n",
    "df_train_in, df_train_out = utils_dt_prep_pred_all.input_output_pairs(df_train, config.PAT_MIN_LENGTH)\n",
    "df_val_in, df_val_out = utils_dt_prep_pred_all.input_output_pairs(df_val, config.PAT_MIN_LENGTH)\n",
    "df_test_in, df_test_out = utils_dt_prep_pred_all.input_output_pairs(df_test, config.PAT_MIN_LENGTH)\n",
    "\n",
    "# add df data to a dictionary and keep only cols of interest (used for Fairness tasks)\n",
    "cols = ['rlnI_updated', 'age', 'bthyearI', 'cntyresI', 'cntyresI_name', 'pm25I', 'wfeI', 'sexI', 'raceI', \n",
    "    'patcnty', 'raceM', 'meduc', 'precare', 'visitsM_9mpp', 'visitsM_1ypp', 'visitsI_1yol',\n",
    "    'bthresmb_name', 'prevsts']\n",
    "\n",
    "df_dict = {\n",
    "    'train_in': df_train_in[cols], 'val_in': df_val_in[cols], 'test_in': df_test_in[cols],\n",
    "    'train_out': df_train_out[cols], 'val_out': df_val_out[cols],'test_out': df_test_out[cols]\n",
    "}\n",
    "\n",
    "# drop duplicates\n",
    "for key in df_dict.keys():\n",
    "    df_dict[key].drop_duplicates(subset=['rlnI_updated'], inplace=True)\n",
    "    df_dict[key].reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print shapes\n",
    "for key in df_dict.keys():\n",
    "    print('Shape of df ' + key, df_dict[key].shape)\n",
    "    \n",
    "for key in df_dict.keys():\n",
    "    if 'out' in key:\n",
    "        print('Unique patients in df ' + key.split('_')[0], df_dict[key].rlnI_updated.nunique())\n",
    "        # drop rlnI_updated column\n",
    "        df_dict[key].drop(columns='rlnI_updated', inplace=True)\n",
    "    else:\n",
    "        df_dict[key].drop(columns='rlnI_updated', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print example patient in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_in[df_train_in.rlnI_updated.eq('00003PWWP')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_out[df_train_out.rlnI_updated.eq('00003PWWP')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">create one-hot diagnosis features from input data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.PRIMARY_DIAG_ONLY:\n",
    "    # find union of diag codes across train, val, and test sets\n",
    "    diag_union = np.union1d(df_train_in.diag00_2d.unique(), df_val_in.diag00_2d.unique())\n",
    "    diag_union = np.union1d(diag_union, df_test_in.diag00_2d.unique())\n",
    "    # find difference between train and test set diag00 codes (main diagnosis code)\n",
    "    setdif_train_union = np.setdiff1d(diag_union, df_train_in.diag00_2d.unique())\n",
    "    setdif_val_union = np.setdiff1d(diag_union, df_val_in.diag00_2d.unique())\n",
    "    setdif_test_union = np.setdiff1d(diag_union, df_test_in.diag00_2d.unique())\n",
    "    print('In union but not in train', setdif_train_union) \n",
    "    print('In union but not in val', setdif_val_union) \n",
    "    print('In union but not in test', setdif_test_union)\n",
    "\n",
    "    ## train set: create one-hot features ##\n",
    "    oh_train_in = pd.get_dummies(\n",
    "        df_train_in.copy(),\n",
    "        columns = [\"diag00_2d\"],#, \"diag01_2d\", \"diag02_2d\"],\n",
    "        drop_first=True\n",
    "    ) \n",
    "    # pull one-hot diag00 columns\n",
    "    oh_cols_train_in = [col for col in oh_train_in if col.startswith('diag00_2d_')]\n",
    "    # find max of one-hot diag00 columns\n",
    "    oh_train_in_final = oh_train_in.groupby('rlnI_updated', as_index=False)[oh_cols_train_in].max()\n",
    "    # add one-hot columns that are in union but not in train\n",
    "    if len(setdif_train_union)>0:\n",
    "        for i in range(len(setdif_train_union)):\n",
    "            oh_train_in_final['diag00_2d_'+setdif_train_union[i]] = 0\n",
    "            \n",
    "            \n",
    "    ## val set: create one-hot features ##\n",
    "    oh_val_in = pd.get_dummies(\n",
    "        df_val_in.copy(),\n",
    "        columns = [\"diag00_2d\"],#, \"diag01_2d\", \"diag02_2d\"],\n",
    "        drop_first=True\n",
    "    ) \n",
    "    # pull one-hot diag00 columns\n",
    "    oh_cols_val_in = [col for col in oh_val_in if col.startswith('diag00_2d_')]\n",
    "    # find max of one-hot diag00 columns\n",
    "    oh_val_in_final = oh_val_in.groupby('rlnI_updated', as_index=False)[oh_cols_val_in].max()\n",
    "    # add one-hot columns that are in union but not in val\n",
    "    if len(setdif_val_union)>0:\n",
    "        for i in range(len(setdif_val_union)):\n",
    "            oh_val_in_final['diag00_2d_'+setdif_val_union[i]] = 0\n",
    "\n",
    "            \n",
    "    ## test set: create one-hot features ##\n",
    "    oh_test_in = pd.get_dummies(\n",
    "        df_test_in.copy(),\n",
    "        columns = [\"diag00_2d\"],#, \"diag01_2d\", \"diag02_2d\"],\n",
    "        drop_first=True)\n",
    "    # pull one-hot diag00 columns\n",
    "    oh_cols_test_in = [col for col in oh_test_in if col.startswith('diag00_2d_')]\n",
    "    # find max of one-hot diag00 columns\n",
    "    oh_test_in_final = oh_test_in.groupby('rlnI_updated', as_index=False)[oh_cols_test_in].max()\n",
    "    # add columns that are in train but not in test set\n",
    "    if len(setdif_test_union)>0:\n",
    "        for i in range(len(setdif_test_union)):\n",
    "            oh_test_in_final['diag00_2d_'+setdif_test_union[i]] = 0\n",
    "\n",
    "    print('Training set length', len(oh_train_in_final.columns))\n",
    "    print('Val set length', len(oh_train_in_final.columns))\n",
    "    print('Test set length', len(oh_test_in_final.columns))\n",
    "\n",
    "else:\n",
    "    print('Write code to include more than the primary diag code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print one-hot diag00 features example (patient) from train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, print diag codes in non one-hot form\n",
    "df_train_in[df_train_in.rlnI_updated.eq(\"00003PWWP\")][[\"diag00_2d\"]]#, \"diag01_2d\", \"diag02_2d\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second, print one-hot diag00 features\n",
    "oh_train_in[oh_train_in.rlnI_updated.eq('00003PWWP')][['diag00_2d_V3', 'diag00_2d_46']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third, print max of one-hot diag00 (final features)\n",
    "oh_train_in_final[oh_train_in_final.rlnI_updated.eq('00003PWWP')][['diag00_2d_V3', 'diag00_2d_46']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all data for patient example\n",
    "oh_train_in_final[oh_train_in_final.rlnI_updated.eq('00003PWWP')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for diag00, diag01, diag02 (first 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.DIAG3:\n",
    "    oh_train_in_final = pd.DataFrame()\n",
    "    oh_val_in_final = pd.DataFrame()\n",
    "    oh_test_in_final = pd.DataFrame()\n",
    "\n",
    "    for idx, diag in enumerate(['diag00_2d', 'diag01_2d', 'diag02_2d']):\n",
    "        print(diag)\n",
    "        # find union of diag codes across train, val, and test sets\n",
    "        diag_union = np.union1d(df_train_in[diag].unique(), df_val_in[diag].unique())\n",
    "        diag_union = np.union1d(diag_union, df_test_in[diag].unique())\n",
    "        # find difference between train and test set diag00 codes (main diagnosis code)\n",
    "        setdif_train_union = np.setdiff1d(diag_union, df_train_in[diag].unique())\n",
    "        setdif_val_union = np.setdiff1d(diag_union, df_val_in[diag].unique())\n",
    "        setdif_test_union = np.setdiff1d(diag_union, df_test_in[diag].unique())\n",
    "        print('In union but not in train', setdif_train_union) \n",
    "        print('In union but not in val', setdif_val_union) \n",
    "        print('In union but not in test', setdif_test_union)\n",
    "\n",
    "        ## train set: create one-hot features ##\n",
    "        oh_train_in = pd.get_dummies(\n",
    "            df_train_in.copy(),\n",
    "            columns = [diag],#, \"diag01_2d\", \"diag02_2d\"],\n",
    "            drop_first=True\n",
    "        )\n",
    "        # pull one-hot diag00 columns\n",
    "        oh_cols_train_in = [col for col in oh_train_in if col.startswith(diag+'_')]\n",
    "        # find max of one-hot diag00 columns\n",
    "        temp_oh_train_in_final = oh_train_in.groupby('rlnI_updated', as_index=False)[oh_cols_train_in].max()\n",
    "        # add one-hot columns that are in train but not in test set\n",
    "        if len(setdif_train_union)>0:\n",
    "            for i in range(len(setdif_train_union)):\n",
    "                temp_oh_train_in_final[diag+'_'+setdif_train_union[i]] = 0\n",
    "        if idx>0:\n",
    "            temp_oh_train_in_final = temp_oh_train_in_final.iloc[:, 1:]\n",
    "        oh_train_in_final = pd.concat([oh_train_in_final,temp_oh_train_in_final], axis=1)\n",
    "        \n",
    "        \n",
    "        ## val set: create one-hot features ##\n",
    "        oh_val_in = pd.get_dummies(\n",
    "            df_val_in.copy(),\n",
    "            columns = [diag],#, \"diag01_2d\", \"diag02_2d\"],\n",
    "            drop_first=True\n",
    "        )\n",
    "        # pull one-hot diag00 columns\n",
    "        oh_cols_val_in = [col for col in oh_val_in if col.startswith(diag+'_')]\n",
    "        # find max of one-hot diag00 columns\n",
    "        temp_oh_val_in_final = oh_val_in.groupby('rlnI_updated', as_index=False)[oh_cols_val_in].max()\n",
    "        # add one-hot columns that are in train but not in test set\n",
    "        if len(setdif_val_union)>0:\n",
    "            for i in range(len(setdif_val_union)):\n",
    "                temp_oh_val_in_final[diag+'_'+setdif_val_union[i]] = 0\n",
    "        if idx>0:\n",
    "            temp_oh_val_in_final = temp_oh_val_in_final.iloc[:, 1:]\n",
    "        oh_val_in_final = pd.concat([oh_val_in_final,temp_oh_val_in_final], axis=1)\n",
    "\n",
    "            \n",
    "        ## test set: create one-hot features ##\n",
    "        oh_test_in = pd.get_dummies(\n",
    "            df_test_in.copy(),\n",
    "            columns = [diag],#, \"diag01_2d\", \"diag02_2d\"],\n",
    "            drop_first=True\n",
    "        )\n",
    "        # pull one-hot diag00 columns\n",
    "        oh_cols_test_in = [col for col in oh_test_in if col.startswith(diag+'_')]\n",
    "        # find max of one-hot diag00 columns\n",
    "        temp_oh_test_in_final = oh_test_in.groupby('rlnI_updated', as_index=False)[oh_cols_test_in].max()\n",
    "        # add columns that are in train but not in test set\n",
    "        if len(setdif_test_union)>0:\n",
    "            for i in range(len(setdif_test_union)):\n",
    "                temp_oh_test_in_final[diag+'_'+setdif_test_union[i]] = 0\n",
    "        if idx>0:\n",
    "            temp_oh_test_in_final = temp_oh_test_in_final.iloc[:, 1:]\n",
    "        oh_test_in_final = pd.concat([oh_test_in_final,temp_oh_test_in_final], axis=1)\n",
    "\n",
    "\n",
    "        print('Training set length', len(oh_train_in_final.columns))\n",
    "        print('Validation set length', len(oh_train_in_final.columns))\n",
    "        print('Test set length', len(oh_test_in_final.columns))\n",
    "        \n",
    "# print all data for patient example\n",
    "oh_train_in_final[oh_train_in_final.rlnI_updated.eq('00003PWWP')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style=\"color:chocolate\">Create features and labels</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features (X)\n",
    "X_train = oh_train_in_final.iloc[:, 1:]\n",
    "X_val = oh_val_in_final.iloc[:, 1:]\n",
    "X_test = oh_test_in_final.iloc[:, 1:]\n",
    "\n",
    "# labels (y)\n",
    "if config.PRIMARY_DIAG_ONLY:\n",
    "    y_train = df_train_out.diag00_2d # predict main diagnosis code in next visit\n",
    "    y_val = df_val_out.diag00_2d # predict main diagnosis code in next visit\n",
    "    y_test = df_test_out.diag00_2d # predict main diagnosis code in next visit\n",
    "else:\n",
    "    print('Write code to include more than the primary diag code')\n",
    "\n",
    "print('Shape of X_train ', X_train.shape)\n",
    "print('Shape of y_train ', y_train.shape)\n",
    "\n",
    "print('Shape of X_val ', X_val.shape)\n",
    "print('Shape of y_val ', y_val.shape)\n",
    "\n",
    "print('Shape of X_test ', X_test.shape)\n",
    "print('Shape of y_test ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">load vocab used in MLM</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vect layer\n",
    "vect_layer = {}\n",
    "key='diag'\n",
    "vect_layer[key] = tf.keras.models.load_model('../../../embeddings/vectorizers/vect_layer_'+key)\n",
    "vect_layer[key] = vect_layer[key].layers[0]\n",
    "\n",
    "# create maping\n",
    "id2token = {}\n",
    "token2id = {}\n",
    "id2token[key] = dict(enumerate(vect_layer[key].get_vocabulary()))\n",
    "token2id[key] = {y: x for x, y in id2token[key].items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">Encode outcomes (y)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# union of train and test\n",
    "y_union = np.union1d(y_train, y_val).tolist()\n",
    "y_union = np.union1d(y_union, y_test).tolist()\n",
    "y_union_tokenized = utils_dt_prep.encode(vect_layer['diag'], y_union)[:,0]\n",
    "y_union_tokenized = np.unique(y_union_tokenized, axis=0) #token 1 shows up two times\n",
    "\n",
    "# train\n",
    "y_train_tokenized = utils_dt_prep.encode(vect_layer['diag'], y_train)[:,0]\n",
    "y_train_tokenized = pd.get_dummies(y_train_tokenized, drop_first=False).reindex(columns = y_union_tokenized, fill_value=0)\n",
    "y_train_tokenized_cols = np.array(y_train_tokenized.columns)\n",
    "y_train_tokenized = y_train_tokenized.to_numpy()\n",
    "\n",
    "# val\n",
    "y_val_tokenized = utils_dt_prep.encode(vect_layer['diag'], y_val)[:,0]\n",
    "y_val_tokenized = pd.get_dummies(y_val_tokenized, drop_first=False).reindex(columns = y_union_tokenized, fill_value=0)\n",
    "y_val_tokenized_cols = np.array(y_val_tokenized.columns)\n",
    "y_val_tokenized = y_val_tokenized.to_numpy()\n",
    "\n",
    "# test\n",
    "y_test_tokenized = utils_dt_prep.encode(vect_layer['diag'], y_test)[:,0]\n",
    "y_test_tokenized = pd.get_dummies(y_test_tokenized, drop_first=False).reindex(columns = y_union_tokenized, fill_value=0)\n",
    "y_test_tokenized_cols = np.array(y_test_tokenized.columns)\n",
    "y_test_tokenized = y_test_tokenized.to_numpy()\n",
    "\n",
    "print('Shape y_train_tokenized ', y_train_tokenized.shape)\n",
    "print('Shape y_val_tokenized ', y_val_tokenized.shape)\n",
    "print('Shape y_test_tokenized ', y_test_tokenized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 7: Next visit diagnosis (downstream task)\n",
    "\n",
    "Run a logistic regression model to predict diag00 in the next visit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">define model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_rf_model = RandomForestClassifier(\n",
    "        bootstrap=True,\n",
    "        n_estimators=10,\n",
    "        max_depth=5,\n",
    "        max_features='sqrt',\n",
    "        #class_weight='balanced_subsample',\n",
    "        random_state=config.seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">fit model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">tune model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train score:', classifier_rf_model.score(X_train, y_train))\n",
    "print('Val score:', classifier_rf_model.score(X_val, y_val))\n",
    "print('Test score:', classifier_rf_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">predictions  (on train and test data)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_tokenized_rf_pred = classifier_rf_model.predict_proba(X_train)\n",
    "#y_train_tokenized_rf_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_tokenized_rf_pred = classifier_rf_model.predict_proba(X_test)\n",
    "y_test_tokenized_rf_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">Metrics (model evaluation)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a \"micro(sample)-average\": quantifying score on all classes jointly\n",
    "# precision and recall\n",
    "precision_micro, recall_micro, _ = PRC(\n",
    "    y_test_tokenized.ravel(),\n",
    "    y_test_tokenized_rf_pred.ravel()\n",
    ")\n",
    "\n",
    "\n",
    "# average precision score\n",
    "aps_samples_rf = APS(\n",
    "    y_test_tokenized,\n",
    "    y_test_tokenized_rf_pred,\n",
    "    average=\"samples\"\n",
    ")\n",
    "\n",
    "# ROC curve and ROC area (Micro-averaged One-vs-Rest ROC AUC score)\n",
    "fpr_micro, tpr_micro, _ = roc_curve(\n",
    "    y_test_tokenized.ravel(),\n",
    "    y_test_tokenized_rf_pred.ravel()\n",
    ")\n",
    "area_micro_rf = auc(fpr_micro, tpr_micro)\n",
    "\n",
    "print('Average precission score:',\n",
    "      np.round(aps_samples_rf,3)\n",
    ")\n",
    "print('ROC AUC:',\n",
    "      np.round(area_micro_rf,3)\n",
    ")\n",
    "\n",
    "# add APS and ROC areato a df\n",
    "temp_df = pd.DataFrame(\n",
    "        {'metric': ['APS', 'AUC'],\n",
    "         'value': [aps_samples_rf, area_micro_rf]\n",
    "        }\n",
    "    )\n",
    "\n",
    "temp_df['seed'] = config.seed\n",
    "\n",
    "# export metrics to csv\n",
    "#temp_df.to_csv('./results/ApsAucDownstream__base(RF).csv', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at the diagnosis level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_eval_downstream)\n",
    "start_time= time.time()\n",
    "recall_diag, precision_diag, fpr_diag, tpr_diag, df_aps_auc_diag, df_y_cols = utils_eval_downstream.metrics_each_diagnosis(\n",
    "    y_union_tokenized,\n",
    "    id2token,\n",
    "    y_test_tokenized_rf_pred,\n",
    "    y_test_tokenized,\n",
    "    y_test\n",
    ")\n",
    "\n",
    "# print execution time\n",
    "print('Execution time:', np.round((time.time()-start_time)/60, 2), 'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "metrics at the micro or samples level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time= time.time()\n",
    "precision_micro_logistic, recall_micro_logistic,\\\n",
    "fpr_micro_logistic, tpr_micro_logistic,\\\n",
    "aps_samples_logistic, area_micro_logistic = utils_eval_downstream.metrics_averages(\n",
    "    y_test_tokenized_cols,\n",
    "    id2token,\n",
    "    y_test_tokenized_rf_pred,\n",
    "    y_test_tokenized\n",
    ")\n",
    "\n",
    "# print execution time\n",
    "print('Execution time:', np.round((time.time()-start_time)/60, 2), 'minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average precission score:',\n",
    "      np.round(aps_samples_logistic,3)\n",
    ")\n",
    "print('ROC AUC:',\n",
    "      np.round(area_micro_logistic,3)\n",
    ")\n",
    "\n",
    "# add APS and ROC areato a df\n",
    "temp_df = pd.DataFrame(\n",
    "        {'metric': ['APS', 'AUC'],\n",
    "         'value': [aps_samples_logistic, area_micro_logistic]\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "temp_df['seed'] = config.seed\n",
    "\n",
    "# export metrics to csv\n",
    "temp_df.to_csv('./results/ApsAucDownstream__base(RF).csv', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot APS and AUC for each diag00-diag03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_eval_downstream)\n",
    "start_time= time.time()\n",
    "utils_eval_downstream.plot_pr_roc(\n",
    "    recall_diag, precision_diag, fpr_diag,\n",
    "    tpr_diag, df_aps_auc_diag, precision_micro_logistic,\n",
    "    recall_micro_logistic, fpr_micro_logistic, tpr_micro_logistic, aps_samples_logistic,\n",
    "    area_micro_logistic, config.top_diag)\n",
    "\n",
    "\n",
    "# save data to dictionary\n",
    "dict_metrics = {\n",
    "    'recall_diag': recall_diag,\n",
    "    'precision_diag': precision_diag,\n",
    "    'fpr_diag': fpr_diag,\n",
    "    'tpr_diag': tpr_diag,\n",
    "    'df_aps_auc_diag': df_aps_auc_diag,\n",
    "    'precision_micro': precision_micro_logistic,\n",
    "    'recall_micro': recall_micro_logistic,\n",
    "    'fpr_micro': fpr_micro_logistic,\n",
    "    'tpr_micro': tpr_micro_logistic,\n",
    "    'aps_samples': aps_samples_logistic,\n",
    "    'area_micro': area_micro_logistic,\n",
    "    'config.top_diag': config.top_diag\n",
    "}\n",
    "\n",
    "# print execution time\n",
    "print('Execution time:', np.round((time.time()-start_time)/60, 2), 'minutes')\n",
    "\n",
    "np.save('./results/EachApsAucDownstream__base(RF)_'+ str(config.seed)+ '_.npy', dict_metrics) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "``downstream task + extra features``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">create extra features</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_classifier_plus) \n",
    "X_train_subset_plus = utils_classifier_plus.create_extra_features(df_dict['train_in'], X_train.reset_index(drop=True, inplace=True))\n",
    "X_val_subset_plus = utils_classifier_plus.create_extra_features(df_dict['val_in'], X_val.reset_index(drop=True, inplace=True))\n",
    "X_test_subset_plus = utils_classifier_plus.create_extra_features(df_dict['test_in'], X_test.reset_index(drop=True, inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for columns that are extra between training and validation\n",
    "col_diff_train_val = np.setdiff1d(list(X_train_subset_plus.columns), list(X_val_subset_plus.columns))\n",
    "col_diff_train_val = list(col_diff_train_val)\n",
    "print('Columns difference train_val', col_diff_train_val)\n",
    "# drop column from X_train_tokenized_subset_plus\n",
    "X_train_subset_plus.drop(columns=col_diff_train_val, inplace=True)\n",
    "\n",
    "## check for columns that are extra between training and test\n",
    "col_diff_train_test = np.setdiff1d(list(X_train_subset_plus.columns), list(X_test_subset_plus.columns))\n",
    "col_diff_train_test = list(col_diff_train_test)\n",
    "print('Columns difference train_test', col_diff_train_test)\n",
    "# drop column from X_train_tokenized_subset_plus\n",
    "X_train_subset_plus.drop(columns=col_diff_train_test, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">define model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_rf_plus_model = RandomForestClassifier(\n",
    "        bootstrap=True,\n",
    "        n_estimators=10,\n",
    "        max_depth=5,\n",
    "        max_features='sqrt',\n",
    "        random_state=config.seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">fit model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "classifier_rf_plus_model.fit(X_train_subset_plus, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">tune model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train score:', classifier_rf_plus_model.score(X_train_subset_plus, y_train))\n",
    "print('Val score:', classifier_rf_plus_model.score(X_val_subset_plus, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">predictions  (on train and test data)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_tokenized_plus_pred = classifier_rf_plus_model.predict_proba(X_train_subset_plus)\n",
    "#y_train_tokenized_plus_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_tokenized_plus_pred = classifier_rf_plus_model.predict_proba(X_test_subset_plus)\n",
    "y_test_tokenized_plus_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">Metrics (model evaluation)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at the micro or samples level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time= time.time()\n",
    "precision_micro_plus, recall_micro_plus,\\\n",
    "fpr_micro_plus, tpr_micro_plus,\\\n",
    "aps_samples_plus, area_micro_plus = utils_eval_downstream.metrics_averages(\n",
    "    y_test_tokenized_cols,\n",
    "    id2token,\n",
    "    y_test_tokenized_plus_pred,\n",
    "    y_test_tokenized\n",
    ")\n",
    "\n",
    "# print execution time\n",
    "print('Execution time:', np.round((time.time()-start_time)/60, 2), 'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot APS and AUC for each diag00-diag03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average precission score:',\n",
    "      np.round(aps_samples_plus,3)\n",
    ")\n",
    "print('ROC AUC:',\n",
    "      np.round(area_micro_plus,3)\n",
    ")\n",
    "\n",
    "# add APS and ROC areato a df\n",
    "metrics_plus = pd.DataFrame(\n",
    "        {'metric': ['APS', 'AUC'],\n",
    "         'value': [aps_samples_plus, area_micro_plus]\n",
    "        }\n",
    "    )\n",
    "\n",
    "metrics_plus['seed'] = config.seed\n",
    "\n",
    "# export metrics to csv\n",
    "metrics_plus.to_csv('./results/ApsAucDownstreamExtra__base(RF).csv', mode='a')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
