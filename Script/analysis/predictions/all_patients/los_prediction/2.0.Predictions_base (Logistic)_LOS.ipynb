{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main script for Prediction Task\n",
    "\n",
    "Modules: N/A <br>\n",
    "Author: Cornelia Ilin <br>\n",
    "Email: cilin@wisc.edu <br>\n",
    "Date created: June 8, 2022 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import importlib\n",
    "import glob\n",
    "import re\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "# sklearn and others\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score as APS\n",
    "from sklearn.metrics import roc_auc_score as ROC_AUC\n",
    "from sklearn.metrics import precision_recall_curve as PRC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from itertools import cycle\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# user defined\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../../')\n",
    "from embeddings import utils_dt_prep\n",
    "from  embeddings import utils_MLM\n",
    "import utils_dt_prep_pred_all\n",
    "import utils_classifier_random_embed\n",
    "import utils_classifier_logistic\n",
    "import utils_eval_downstream\n",
    "from embeddings import utils_embeddings\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 2.1: Set-up config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    MAX_LEN = 40\n",
    "    BATCH_SIZE = 32\n",
    "    PAT_MIN_LENGTH = 3 #minimum number of visits\n",
    "    DIAG_PER_VISIT = 3 #diagnosis per visit to consider\n",
    "    DIAG_LENGTH = 2 # how many digits from diagnosis code to consider\n",
    "    PRIMARY_DIAG_ONLY = True\n",
    "    DIAG3 = True\n",
    "    train_pct = 0.8\n",
    "    val_pct = 0.1\n",
    "    seed = [1235, 1789, 2134, 1455, 1112] #1235\n",
    "    top_diag = 10 #top diagmosis based on rocauc or aps\n",
    "    draw_train_val_test = False\n",
    "    create_Xy=False\n",
    "    save_model=True\n",
    "    load_model=False\n",
    "    process_LOS = False\n",
    "\n",
    "config = Config()\n",
    "config.seed = config.seed[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 2.2: Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dates(df):\n",
    "    ''' Add dates for year, month, day of birth for patient\n",
    "        Add dates for year, month, day of hospital visit for patient\n",
    "    '''\n",
    "    # define dates\n",
    "    dates = ['bthdate', 'admtdate']\n",
    "    \n",
    "    for col in dates:\n",
    "        # transform to string\n",
    "        df[col] = df[col].astype(str)\n",
    "        # make sure date is Pandas compatible\n",
    "        df[col] = pd.to_datetime(df[col], errors = 'coerce')\n",
    "\n",
    "    # define bth variable to be added (year, month, day of birth)\n",
    "    newvars = [['bthyear', 'bthmonth', 'bthday'],\n",
    "              ['admtyear', 'admtmonth', 'admtday']]\n",
    "    \n",
    "    for i in range(len(dates)):\n",
    "        # add bth year\n",
    "        df[newvars[i][0]] = pd.DatetimeIndex(df[dates[i]]).year\n",
    "        # add bth month\n",
    "        df[newvars[i][1]] = pd.DatetimeIndex(df[dates[i]]).month\n",
    "        # add bth date\n",
    "        df[newvars[i][2]] = pd.DatetimeIndex(df[dates[i]]).day\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 2.3: Define working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pdd_dir = 'C:/Users/cilin/Research/CA_hospitals/Input/final_data/health/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 3: Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``los``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.process_LOS:\n",
    "    # read uncleaned PDD data\n",
    "    df_pdd = pd.read_csv(raw_pdd_dir + 'PDD_los.csv')\n",
    "    df_pdd.rename(columns={'rln':'rlnI_updated'}, inplace=True)\n",
    "    \n",
    "    # add dates\n",
    "    df_pdd = add_dates(df_pdd)\n",
    "    # keep only iacf bthyear >=1991\n",
    "    df_pdd = df_pdd[df_pdd.bthyear.ge(1991.)]\n",
    "\n",
    "    # reset index\n",
    "    df_pdd.reset_index(\n",
    "        drop=True,\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    # save data\n",
    "    df_pdd['data_source'] = 'PDD'\n",
    "    df_pdd.rename(columns={'rln':'rlnI_updated'}, inplace=True)\n",
    "    cols = ['rlnI_updated', 'admtdate', 'bthdate', 'data_source','los', 'los_adj']\n",
    "    df_pdd[cols].to_csv(raw_pdd_dir + 'pdd_los.csv')\n",
    "    \n",
    "else:\n",
    "  # load data  \n",
    "    df_pdd = pd.read_csv(raw_pdd_dir + 'pdd_los.csv')\n",
    "    \n",
    "df_pdd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``all health data``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_dt_prep)\n",
    "# read medical records for all patients with SSN and birth records\n",
    "df_init = utils_dt_prep.read_data_bpe(keep_all_cols=True)\n",
    "\n",
    "# print shapes and head\n",
    "print('Unique patients ', df_init.rlnI_updated.nunique())\n",
    "print('Number of encounters (shape of data) ', df_init.shape)\n",
    "df_init.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``merge LOS``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with df \n",
    "df_init2 = df_init.merge(\n",
    "    df_pdd,\n",
    "    on = ['rlnI_updated', 'admtdate', 'bthdate','data_source'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print('Shape of df_init after LOS merge', df_init.shape) #why the difference to above?\n",
    "\n",
    "# set ER LOS to 0\n",
    "df_init2['los'] = np.where((df_init2.data_source.eq('EDD')), 0, df_init2.los)\n",
    "\n",
    "# from birth data, if admtdate=bthdate set los to 0 (mean is 3.59, 75% is 3.0)\n",
    "df_init2['los'] = np.where((df_init2.data_source.eq('Birth')) & (df_init2.admtdate.eq(df_init2.bthdate)), 0, df_init2.lenstayI)\n",
    "\n",
    "df_init2['los2'] = np.where(df_init2.los.isna(), 0, df_init2.los)\n",
    "\n",
    "# set PDD LOS to LOS (no NAN values found). some PDD LOS have values of 0, which means the patient was discarged the same day\n",
    "\n",
    "# keep only cols of interest\n",
    "columns = [\n",
    "'rlnI_updated', 'bthdateI', 'bthyearI', 'cntyresI', 'cntyresI_name',\n",
    "'pm25I', 'wfeI', 'sexI', 'raceI', \n",
    "'patcnty', 'admtdate', 'admtyear', 'admtmonth',\n",
    "'raceM', 'meduc', 'precare', 'visitsM_9mpp', 'visitsM_1ypp', 'visitsI_1yol',\n",
    "'bthresmb_name', 'prevsts',\n",
    "'diag00', 'diag01', 'diag02', 'diag03', 'diag04', 'data_source', 'data_source2', 'los', 'lenstayI', 'los2'\n",
    "]\n",
    "\n",
    "df_init2 = df_init2[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``drop observations and add features``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_dt_prep)\n",
    "print('Unique patients before preprocessing', df_init2.rlnI_updated.nunique())\n",
    "\n",
    "# drop pbervations\n",
    "%time df = utils_dt_prep.drop_observations(df_init2, config.PAT_MIN_LENGTH)\n",
    "# add features, includes visit summary (for diag, age, cnty)\n",
    "%time df = utils_dt_prep.add_features(df, config.DIAG_PER_VISIT, config.DIAG_LENGTH)\n",
    "\n",
    "# print stats\n",
    "print('Unique patients after preprocessing', df.rlnI_updated.nunique())\n",
    "print('Number of encounters after preprocessing (shape of data) ', df.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``define multiclass task``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['los_bins'] = np.where(df.los2.le(1), 0,\n",
    "                          np.where(df.los2.le(3), 1, 2))\n",
    "df.los_bins.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``create train, val, and test datasets``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.draw_train_val_test:\n",
    "    # find unique rlnIs in df\n",
    "    rlnIs = df.rlnI_updated.unique()\n",
    "\n",
    "    # split rlnIs into training, val, and test\n",
    "    np.random.seed(config.seed)\n",
    "    train_rlnI = np.random.choice(rlnIs, int(rlnIs.shape[0]*Config.train_pct), replace=False)\n",
    "    val_rlnI = np.random.choice(train_rlnI, int(train_rlnI.shape[0]*Config.val_pct), replace=False)\n",
    "    test_rlnI = list(set(rlnIs) - set(train_rlnI) - set (val_rlnI))\n",
    "    # save train_rlnIs, val_rlnIs, and test_rlnIs\n",
    "    np.save(\"../diagnosis_prediction/data/train_rlnI.npy\", train_rlnI)\n",
    "    np.save(\"../diagnosis_prediction/data/val_rlnI.npy\", val_rlnI)\n",
    "    np.save(\"../diagnosis_prediction/data/test_rlnI.npy\", test_rlnI)\n",
    "    \n",
    "else:\n",
    "    # load\n",
    "    train_rlnI = np.load(\"../diagnosis_prediction/data/train_rlnI.npy\", allow_pickle=\"TRUE\")\n",
    "    val_rlnI = np.load(\"../diagnosis_prediction/data/val_rlnI.npy\", allow_pickle=\"TRUE\")\n",
    "    test_rlnI = np.load(\"../diagnosis_prediction/data/test_rlnI.npy\", allow_pickle=\"TRUE\")\n",
    "    \n",
    "\n",
    "# pull train and test from df\n",
    "df_train = df[df.rlnI_updated.isin(train_rlnI)]\n",
    "df_val = df[df.rlnI_updated.isin(val_rlnI)]\n",
    "df_test = df[df.rlnI_updated.isin(test_rlnI)]\n",
    "\n",
    "print('Shape of df_train ', df_train.shape)\n",
    "print('Shape of df_val ', df_val.shape)\n",
    "print('Shape of df_test', df_test.shape)\n",
    "\n",
    "print('Unique patients in df_train ', df_train.rlnI_updated.nunique())\n",
    "print('Unique patients in df_val ', df_val.rlnI_updated.nunique())\n",
    "print('Unique patients in df_test ', df_test.rlnI_updated.nunique())\n",
    "\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_val.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">create input-output pairs</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_dt_prep_pred_all)\n",
    "df_train_in, df_train_out = utils_dt_prep_pred_all.input_output_pairs(df_train, config.PAT_MIN_LENGTH)\n",
    "df_val_in, df_val_out = utils_dt_prep_pred_all.input_output_pairs(df_val, config.PAT_MIN_LENGTH)\n",
    "df_test_in, df_test_out = utils_dt_prep_pred_all.input_output_pairs(df_test, config.PAT_MIN_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print example patient in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_in[df_train_in.rlnI_updated.eq('00003PWWP')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_out[df_train_out.rlnI_updated.eq('00003PWWP')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">create one-hot diagnosis features from input data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.PRIMARY_DIAG_ONLY:\n",
    "    # find union of diag codes across train, val, and test sets\n",
    "    diag_union = np.union1d(df_train_in.diag00_2d.unique(), df_val_in.diag00_2d.unique())\n",
    "    diag_union = np.union1d(diag_union, df_test_in.diag00_2d.unique())\n",
    "    # find difference between train and test set diag00 codes (main diagnosis code)\n",
    "    setdif_train_union = np.setdiff1d(diag_union, df_train_in.diag00_2d.unique())\n",
    "    setdif_val_union = np.setdiff1d(diag_union, df_val_in.diag00_2d.unique())\n",
    "    setdif_test_union = np.setdiff1d(diag_union, df_test_in.diag00_2d.unique())\n",
    "    print('In union but not in train', setdif_train_union) \n",
    "    print('In union but not in val', setdif_val_union) \n",
    "    print('In union but not in test', setdif_test_union)\n",
    "\n",
    "    ## train set: create one-hot features ##\n",
    "    oh_train_in = pd.get_dummies(\n",
    "        df_train_in.copy(),\n",
    "        columns = [\"diag00_2d\"],#, \"diag01_2d\", \"diag02_2d\"],\n",
    "        drop_first=True\n",
    "    ) \n",
    "    # pull one-hot diag00 columns\n",
    "    oh_cols_train_in = [col for col in oh_train_in if col.startswith('diag00_2d_')]\n",
    "    # find max of one-hot diag00 columns\n",
    "    oh_train_in_final = oh_train_in.groupby('rlnI_updated', as_index=False)[oh_cols_train_in].max()\n",
    "    # add one-hot columns that are in union but not in train\n",
    "    if len(setdif_train_union)>0:\n",
    "        for i in range(len(setdif_train_union)):\n",
    "            oh_train_in_final['diag00_2d_'+setdif_train_union[i]] = 0\n",
    "            \n",
    "            \n",
    "    ## val set: create one-hot features ##\n",
    "    oh_val_in = pd.get_dummies(\n",
    "        df_val_in.copy(),\n",
    "        columns = [\"diag00_2d\"],#, \"diag01_2d\", \"diag02_2d\"],\n",
    "        drop_first=True\n",
    "    ) \n",
    "    # pull one-hot diag00 columns\n",
    "    oh_cols_val_in = [col for col in oh_val_in if col.startswith('diag00_2d_')]\n",
    "    # find max of one-hot diag00 columns\n",
    "    oh_val_in_final = oh_val_in.groupby('rlnI_updated', as_index=False)[oh_cols_val_in].max()\n",
    "    # add one-hot columns that are in union but not in val\n",
    "    if len(setdif_val_union)>0:\n",
    "        for i in range(len(setdif_val_union)):\n",
    "            oh_val_in_final['diag00_2d_'+setdif_val_union[i]] = 0\n",
    "\n",
    "            \n",
    "    ## test set: create one-hot features ##\n",
    "    oh_test_in = pd.get_dummies(\n",
    "        df_test_in.copy(),\n",
    "        columns = [\"diag00_2d\"],#, \"diag01_2d\", \"diag02_2d\"],\n",
    "        drop_first=True)\n",
    "    # pull one-hot diag00 columns\n",
    "    oh_cols_test_in = [col for col in oh_test_in if col.startswith('diag00_2d_')]\n",
    "    # find max of one-hot diag00 columns\n",
    "    oh_test_in_final = oh_test_in.groupby('rlnI_updated', as_index=False)[oh_cols_test_in].max()\n",
    "    # add columns that are in train but not in test set\n",
    "    if len(setdif_test_union)>0:\n",
    "        for i in range(len(setdif_test_union)):\n",
    "            oh_test_in_final['diag00_2d_'+setdif_test_union[i]] = 0\n",
    "\n",
    "    print('Training set length', len(oh_train_in_final.columns))\n",
    "    print('Val set length', len(oh_train_in_final.columns))\n",
    "    print('Test set length', len(oh_test_in_final.columns))\n",
    "\n",
    "else:\n",
    "    print('Write code to include more than the primary diag code')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print one-hot diag00 features example (patient) from train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, print diag codes in non one-hot form\n",
    "df_train_in[df_train_in.rlnI_updated.eq(\"00003PWWP\")][[\"diag00_2d\"]]#, \"diag01_2d\", \"diag02_2d\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second, print one-hot diag00 features\n",
    "oh_train_in[oh_train_in.rlnI_updated.eq('00003PWWP')][['diag00_2d_V3', 'diag00_2d_46']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third, print max of one-hot diag00 (final features)\n",
    "oh_train_in_final[oh_train_in_final.rlnI_updated.eq('00003PWWP')][['diag00_2d_V3', 'diag00_2d_46']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print all data for patient example\n",
    "oh_train_in_final[oh_train_in_final.rlnI_updated.eq('00003PWWP')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for diag00, diag01, diag02 (first 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.DIAG3:\n",
    "    oh_train_in_final = pd.DataFrame()\n",
    "    oh_val_in_final = pd.DataFrame()\n",
    "    oh_test_in_final = pd.DataFrame()\n",
    "\n",
    "    for idx, diag in enumerate(['diag00_2d', 'diag01_2d', 'diag02_2d']):\n",
    "        print(diag)\n",
    "        # find union of diag codes across train, val, and test sets\n",
    "        diag_union = np.union1d(df_train_in[diag].unique(), df_val_in[diag].unique())\n",
    "        diag_union = np.union1d(diag_union, df_test_in[diag].unique())\n",
    "        # find difference between train and test set diag00 codes (main diagnosis code)\n",
    "        setdif_train_union = np.setdiff1d(diag_union, df_train_in[diag].unique())\n",
    "        setdif_val_union = np.setdiff1d(diag_union, df_val_in[diag].unique())\n",
    "        setdif_test_union = np.setdiff1d(diag_union, df_test_in[diag].unique())\n",
    "        print('In union but not in train', setdif_train_union) \n",
    "        print('In union but not in val', setdif_val_union) \n",
    "        print('In union but not in test', setdif_test_union)\n",
    "\n",
    "        ## train set: create one-hot features ##\n",
    "        oh_train_in = pd.get_dummies(\n",
    "            df_train_in.copy(),\n",
    "            columns = [diag],#, \"diag01_2d\", \"diag02_2d\"],\n",
    "            drop_first=True\n",
    "        )\n",
    "        # pull one-hot diag00 columns\n",
    "        oh_cols_train_in = [col for col in oh_train_in if col.startswith(diag+'_')]\n",
    "        # find max of one-hot diag00 columns\n",
    "        temp_oh_train_in_final = oh_train_in.groupby('rlnI_updated', as_index=False)[oh_cols_train_in].max()\n",
    "        # add one-hot columns that are in train but not in test set\n",
    "        if len(setdif_train_union)>0:\n",
    "            for i in range(len(setdif_train_union)):\n",
    "                temp_oh_train_in_final[diag+'_'+setdif_train_union[i]] = 0\n",
    "        if idx>0:\n",
    "            temp_oh_train_in_final = temp_oh_train_in_final.iloc[:, 1:]\n",
    "        oh_train_in_final = pd.concat([oh_train_in_final,temp_oh_train_in_final], axis=1)\n",
    "        \n",
    "        \n",
    "        ## val set: create one-hot features ##\n",
    "        oh_val_in = pd.get_dummies(\n",
    "            df_val_in.copy(),\n",
    "            columns = [diag],#, \"diag01_2d\", \"diag02_2d\"],\n",
    "            drop_first=True\n",
    "        )\n",
    "        # pull one-hot diag00 columns\n",
    "        oh_cols_val_in = [col for col in oh_val_in if col.startswith(diag+'_')]\n",
    "        # find max of one-hot diag00 columns\n",
    "        temp_oh_val_in_final = oh_val_in.groupby('rlnI_updated', as_index=False)[oh_cols_val_in].max()\n",
    "        # add one-hot columns that are in train but not in test set\n",
    "        if len(setdif_val_union)>0:\n",
    "            for i in range(len(setdif_val_union)):\n",
    "                temp_oh_val_in_final[diag+'_'+setdif_val_union[i]] = 0\n",
    "        if idx>0:\n",
    "            temp_oh_val_in_final = temp_oh_val_in_final.iloc[:, 1:]\n",
    "        oh_val_in_final = pd.concat([oh_val_in_final,temp_oh_val_in_final], axis=1)\n",
    "\n",
    "            \n",
    "        ## test set: create one-hot features ##\n",
    "        oh_test_in = pd.get_dummies(\n",
    "            df_test_in.copy(),\n",
    "            columns = [diag],#, \"diag01_2d\", \"diag02_2d\"],\n",
    "            drop_first=True\n",
    "        )\n",
    "        # pull one-hot diag00 columns\n",
    "        oh_cols_test_in = [col for col in oh_test_in if col.startswith(diag+'_')]\n",
    "        # find max of one-hot diag00 columns\n",
    "        temp_oh_test_in_final = oh_test_in.groupby('rlnI_updated', as_index=False)[oh_cols_test_in].max()\n",
    "        # add columns that are in train but not in test set\n",
    "        if len(setdif_test_union)>0:\n",
    "            for i in range(len(setdif_test_union)):\n",
    "                temp_oh_test_in_final[diag+'_'+setdif_test_union[i]] = 0\n",
    "        if idx>0:\n",
    "            temp_oh_test_in_final = temp_oh_test_in_final.iloc[:, 1:]\n",
    "        oh_test_in_final = pd.concat([oh_test_in_final,temp_oh_test_in_final], axis=1)\n",
    "\n",
    "\n",
    "        print('Training set length', len(oh_train_in_final.columns))\n",
    "        print('Validation set length', len(oh_train_in_final.columns))\n",
    "        print('Test set length', len(oh_test_in_final.columns))\n",
    "        \n",
    "# print all data for patient example\n",
    "oh_train_in_final[oh_train_in_final.rlnI_updated.eq('00003PWWP')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<span style=\"color:chocolate\">Create features and labels</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features (X)\n",
    "X_train = oh_train_in_final.iloc[:, 1:]\n",
    "X_val = oh_val_in_final.iloc[:, 1:]\n",
    "X_test = oh_test_in_final.iloc[:, 1:]\n",
    "\n",
    "# labels (y)\n",
    "if config.PRIMARY_DIAG_ONLY:\n",
    "    y_train = df_train_out.los_bins # predict LOS in next visit\n",
    "    y_val = df_val_out.los_bins \n",
    "    y_test = df_test_out.los_bins \n",
    "else:\n",
    "    print('Write code to include more than the primary diag code')\n",
    "    ## find out examples by class\n",
    "for idx in range(3):\n",
    "    class_pct_train = y_train[y_train.eq(idx)].shape[0]\n",
    "    print('Class ' + str(idx) + ' pct in train', class_pct_train)\n",
    "for idx in range(3):\n",
    "    class_pct_val = y_val[y_val.eq(idx)].shape[0]\n",
    "    print('Class ' + str(idx) + ' pct in train', class_pct_val)\n",
    "for idx in range(3):\n",
    "    class_pct_test = y_test[y_test.eq(idx)].shape[0]\n",
    "    print('Class ' + str(idx) + ' pct in test', class_pct_test)\n",
    "\n",
    "## downsample - randomly exclude examples from the majority class (class 0)\n",
    "idx_y_train_is0 = np.where(y_train.eq(0))[0] #indexes where y_train is class 0\n",
    "idx_y_train_is1 = np.where(y_train.eq(1))[0]\n",
    "idx_y_train_is2 = np.where(y_train.eq(2))[0]\n",
    "idx_train_0_rnd = np.random.choice(idx_y_train_is0, int((y_train[y_train.eq(1)].shape[0]+y_train[y_train.eq(2)].shape[0])/2)) # create the average of the two other classes\n",
    "idx_train_all = np.array(list(idx_train_0_rnd) + list(idx_y_train_is1) + list(idx_y_train_is2))\n",
    "np.random.shuffle(idx_train_all)\n",
    "y_train = y_train[idx_train_all]\n",
    "\n",
    "idx_y_val_is0 = np.where(y_val.eq(0))[0] #indexes where y_train is class 0\n",
    "idx_y_val_is1 = np.where(y_val.eq(1))[0]\n",
    "idx_y_val_is2 = np.where(y_val.eq(2))[0]\n",
    "idx_val_0_rnd = np.random.choice(idx_y_val_is0, int((y_val[y_val.eq(1)].shape[0]+y_val[y_val.eq(2)].shape[0])/2)) # create the average of the two other classes\n",
    "idx_val_all = np.array(list(idx_val_0_rnd) + list(idx_y_val_is1) + list(idx_y_val_is2))\n",
    "np.random.shuffle(idx_val_all)\n",
    "y_val = y_val[idx_val_all]\n",
    "\n",
    "idx_y_test_is0 = np.where(y_test.eq(0))[0]\n",
    "idx_y_test_is1 = np.where(y_test.eq(1))[0]\n",
    "idx_y_test_is2 = np.where(y_test.eq(2))[0]\n",
    "idx_test_0_rnd = np.random.choice(idx_y_test_is0, int((y_test[y_test.eq(1)].shape[0]+y_test[y_test.eq(2)].shape[0])/2)) # create the average of the two other classes\n",
    "idx_test_all = np.array(list(idx_test_0_rnd) + list(idx_y_test_is1) + list(idx_y_test_is2))\n",
    "np.random.shuffle(np.array(idx_test_all))\n",
    "y_test = y_test[idx_test_all]\n",
    "\n",
    "# X\n",
    "X_train = X_train.iloc[idx_train_all,:]\n",
    "X_val = X_val.iloc[idx_val_all,:]\n",
    "X_test = X_test.iloc[idx_test_all,:]\n",
    "\n",
    "print('Shape of X_train ', X_train.shape)\n",
    "print('Shape of y_train ', y_train.shape)\n",
    "\n",
    "print('Shape of X_val ', X_val.shape)\n",
    "print('Shape of y_val ', y_val.shape)\n",
    "\n",
    "print('Shape of X_test ', X_test.shape)\n",
    "print('Shape of y_test ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">load vocab used in MLM</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vect layer\n",
    "vect_layer = {}\n",
    "key='diag'\n",
    "vect_layer[key] = tf.keras.models.load_model('../../../embeddings/vectorizers/vect_layer_'+key)\n",
    "vect_layer[key] = vect_layer[key].layers[0]\n",
    "\n",
    "# create maping\n",
    "id2token = {}\n",
    "token2id = {}\n",
    "id2token[key] = dict(enumerate(vect_layer[key].get_vocabulary()))\n",
    "token2id[key] = {y: x for x, y in id2token[key].items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">Encode outcomes (y)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# union of train and test\n",
    "y_union = np.union1d(y_train, y_val).tolist()\n",
    "y_union = np.union1d(y_union, y_test).tolist()\n",
    "y_union_tokenized = y_union\n",
    "\n",
    "# train\n",
    "y_train_tokenized = pd.get_dummies(y_train, drop_first=False).reindex(columns = y_union_tokenized, fill_value=0)\n",
    "y_train_tokenized_cols = np.array(y_train_tokenized.columns)\n",
    "y_train_tokenized = y_train_tokenized.to_numpy()\n",
    "\n",
    "# val\n",
    "y_val_tokenized = pd.get_dummies(y_val, drop_first=False).reindex(columns = y_union_tokenized, fill_value=0)\n",
    "y_val_tokenized_cols = np.array(y_val_tokenized.columns)\n",
    "y_val_tokenized = y_val_tokenized.to_numpy()\n",
    "\n",
    "# test\n",
    "y_test_tokenized = pd.get_dummies(y_test, drop_first=False).reindex(columns = y_union_tokenized, fill_value=0)\n",
    "y_test_tokenized_cols = np.array(y_test_tokenized.columns)\n",
    "y_test_tokenized = y_test_tokenized.to_numpy()\n",
    "\n",
    "print('Shape y_train_tokenized ', y_train_tokenized.shape)\n",
    "print('Shape y_val_tokenized ', y_val_tokenized.shape)\n",
    "print('Shape y_test_tokenized ', y_test_tokenized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">Convert train, val, and test subsets to tensors</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(config.seed)\n",
    "train_tensor = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_train, y_train_tokenized)))\n",
    "train_tensor = train_tensor.shuffle(1000).batch(config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(config.seed)\n",
    "val_tensor = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_val, y_val_tokenized)))\n",
    "val_tensor = val_tensor.shuffle(1000).batch(config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(config.seed)\n",
    "test_tensor = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_test, y_test_tokenized)))\n",
    "test_tensor = test_tensor.shuffle(1000).batch(config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 7: Next visit LOS (downstream task)\n",
    "\n",
    "Run a logistic regression model to predict diag00 in the next visit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">define model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = True\n",
    "if early_stopping:\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    verbose=1,\n",
    "    patience=2,\n",
    "    mode='min',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_classifier_logistic)\n",
    "classifier_logistic_model = utils_classifier_logistic.classifier_logistic_model(\n",
    "    X_train.shape[1],\n",
    "    y_train_tokenized.shape[1]\n",
    ")\n",
    "classifier_logistic_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">fit model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "hist = classifier_logistic_model.fit(\n",
    "    train_tensor,\n",
    "    validation_data=val_tensor,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">plot loss and accuracy</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab history\n",
    "history = hist.history\n",
    "\n",
    "# plot loss for train and validation\n",
    "fig = plt.figure(figsize=(12, 2))\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "plt.plot(history['loss'], lw=2, color='darkgoldenrod')\n",
    "plt.plot(history['val_loss'], lw=2, color='indianred')\n",
    "plt.legend(['Train', 'Validation'], fontsize=10)\n",
    "#plt.ylim(0,0.2)\n",
    "ax.set_xlabel('Epochs', size=10)\n",
    "ax.set_title('Loss');\n",
    "\n",
    "# plot accuracy for train and validation\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "plt.plot(history['accuracy'], lw=2, color='darkgoldenrod')\n",
    "plt.plot(history['val_accuracy'], lw=2, color='indianred')\n",
    "plt.legend(['Train', 'Validation'], fontsize=10)\n",
    "#plt.ylim(0.7,1)\n",
    "ax.set_xlabel('Epochs', size=10)\n",
    "ax.set_title('Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">save or load</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.save_model:\n",
    "    classifier_logistic_model.save(\"./cls_model_base(Logistic)_los.h5\", include_optimizer=False)\n",
    "if config.load_model:\n",
    "    classifier_logistic_model = keras.models.load_model(\"./cls_model_base(Logistic)_los.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">predictions  (on train and test data)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_tokenized_logistic_pred = classifier_logistic_model.predict(X_train)\n",
    "#y_train_tokenized_logistic_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_tokenized_logistic_pred = classifier_logistic_model.predict(X_test)\n",
    "y_test_tokenized_logistic_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">Metrics (model evaluation)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Print BEHRT (micro/samples) metrics``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a \"micro(sample)-average\": quantifying score on all classes jointly\n",
    "# precision and recall\n",
    "precision_micro, recall_micro, _ = PRC(\n",
    "    y_test_tokenized.ravel(),\n",
    "    y_test_tokenized_rf_pred.ravel()\n",
    ")\n",
    "\n",
    "\n",
    "# average precision score\n",
    "aps_samples_rf = APS(\n",
    "    y_test_tokenized,\n",
    "    y_test_tokenized_rf_pred,\n",
    "    average=\"samples\"\n",
    ")\n",
    "\n",
    "# ROC curve and ROC area (Micro-averaged One-vs-Rest ROC AUC score)\n",
    "fpr_micro, tpr_micro, _ = roc_curve(\n",
    "    y_test_tokenized.ravel(),\n",
    "    y_test_tokenized_rf_pred.ravel()\n",
    ")\n",
    "area_micro_rf = auc(fpr_micro, tpr_micro)\n",
    "\n",
    "print('Average precission score:',\n",
    "      np.round(aps_samples_rf,3)\n",
    ")\n",
    "print('ROC AUC:',\n",
    "      np.round(area_micro_rf,3)\n",
    ")\n",
    "\n",
    "# add APS and ROC areato a df\n",
    "temp_df = pd.DataFrame(\n",
    "        {'metric': ['APS', 'AUC'],\n",
    "         'value': [aps_samples_rf, area_micro_rf]\n",
    "        }\n",
    "    )\n",
    "\n",
    "temp_df['seed'] = config.seed\n",
    "\n",
    "# export metrics to csv\n",
    "temp_df.to_csv('./results/ApsAucDownstream___base(Logistic)_los.csv', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Print ROC AUC curve by class``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the fpr, tpr, and roc_auc for all averaging strategies\n",
    "fpr, tpr, roc_auc = dict(), dict(), dict()\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_tokenized.ravel(), y_test_tokenized_logistic_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "n_classes = len(set(y_union))\n",
    "target_names = ['class 0 (los <= 1 day)', 'class 1 (los <=3 days)', 'class 2 (los > 3 days)']\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "plt.plot(\n",
    "    fpr[\"micro\"],\n",
    "    tpr[\"micro\"],\n",
    "    label=f\"micro-average ROC curve (AUC = {roc_auc['micro']:.2f})\",\n",
    "    color=\"deeppink\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "\n",
    "colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "for class_id, color in zip(range(n_classes), colors):\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        y_test_tokenized[:, class_id],\n",
    "        y_test_tokenized_logistic_pred[:, class_id],\n",
    "        name=f\"ROC curve for {target_names[class_id]}\",\n",
    "        color=color,\n",
    "        ax=ax,\n",
    "        #chance_level=True,\n",
    "    )\n",
    "    \n",
    "# random classifier\n",
    "ax.plot(\n",
    "    [0, 1],\n",
    "    [0, 1],\n",
    "    \"k--\",\n",
    "    color=\"black\",\n",
    "    linewidth=1,\n",
    "    label='random classifier'\n",
    ")\n",
    "\n",
    "_ = ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=\"Extension of Receiver Operating Characteristic\\nto One-vs-Rest multiclass\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "``downstream task + extra features``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">create extra features</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_classifier_plus) \n",
    "X_train_subset_plus = utils_classifier_plus.create_extra_features(df_dict['train_in'], X_train.reset_index(drop=True, inplace=True))\n",
    "X_val_subset_plus = utils_classifier_plus.create_extra_features(df_dict['val_in'], X_val.reset_index(drop=True, inplace=True))\n",
    "X_test_subset_plus = utils_classifier_plus.create_extra_features(df_dict['test_in'], X_test.reset_index(drop=True, inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for columns that are extra between training and validation\n",
    "col_diff_train_val = np.setdiff1d(list(X_train_subset_plus.columns), list(X_val_subset_plus.columns))\n",
    "col_diff_train_val = list(col_diff_train_val)\n",
    "print('Columns difference train_val', col_diff_train_val)\n",
    "# drop column from X_train_tokenized_subset_plus\n",
    "X_train_subset_plus.drop(columns=col_diff_train_val, inplace=True)\n",
    "\n",
    "## check for columns that are extra between training and test\n",
    "col_diff_train_test = np.setdiff1d(list(X_train_subset_plus.columns), list(X_test_subset_plus.columns))\n",
    "col_diff_train_test = list(col_diff_train_test)\n",
    "print('Columns difference train_test', col_diff_train_test)\n",
    "# drop column from X_train_tokenized_subset_plus\n",
    "X_train_subset_plus.drop(columns=col_diff_train_test, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">convert train and test sets to tensors</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(config.seed)\n",
    "\n",
    "train_plus_tensor = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_train_subset_plus, y_train_tokenized)))\n",
    "train_plus_tensor = train_plus_tensor.shuffle(1000).batch(config.BATCH_SIZE)\n",
    "\n",
    "val_plus_tensor = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_val_subset_plus, y_val_tokenized)))\n",
    "val_plus_tensor = val_plus_tensor.shuffle(1000).batch(config.BATCH_SIZE)\n",
    "\n",
    "test_plus_tensor = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_test_subset_plus, y_test_tokenized)))\n",
    "test_plus_tensor = test_plus_tensor.shuffle(1000).batch(config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">define model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_classifier_plus)\n",
    "classifier_plus_model = utils_classifier_logistic.classifier_logistic_model(\n",
    "    X_train_subset_plus.shape[1],\n",
    "    y_train_tokenized.shape[1]\n",
    ")\n",
    "classifier_plus_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">fit model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "hist = classifier_plus_model.fit(\n",
    "    train_plus_tensor,\n",
    "    validation_data=val_plus_tensor,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">plot loss and accuracy</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab history\n",
    "history = hist.history\n",
    "\n",
    "# plot loss for train and validation\n",
    "fig = plt.figure(figsize=(12, 2))\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "plt.plot(history['loss'], lw=2, color='darkgoldenrod')\n",
    "plt.plot(history['val_loss'], lw=2, color='indianred')\n",
    "plt.legend(['Train', 'Validation'], fontsize=10)\n",
    "#plt.ylim(0,0.2)\n",
    "ax.set_xlabel('Epochs', size=10)\n",
    "ax.set_title('Loss');\n",
    "\n",
    "# plot accuracy for train and validation\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "plt.plot(history['accuracy'], lw=2, color='darkgoldenrod')\n",
    "plt.plot(history['val_accuracy'], lw=2, color='indianred')\n",
    "plt.legend(['Train', 'Validation'], fontsize=10)\n",
    "#plt.ylim(0.7,1)\n",
    "ax.set_xlabel('Epochs', size=10)\n",
    "ax.set_title('Accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.save_model:\n",
    "    classifier_plus_model.save(\"./cls_model_plus_base(Logistic).h5\", include_optimizer=False)\n",
    "if config.load_model:\n",
    "    classifier_plus_model = keras.models.load_model(\"./cls_model_plus_base(Logistic).h5\", custom_objects={\"MaskedLanguageModel\": utils_MLM.MaskedLanguageModel})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">predictions  (on train and test data)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_tokenized_plus_pred = classifier_plus_model.predict(X_train_subset_plus)\n",
    "#y_train_tokenized_plus_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_tokenized_plus_pred = classifier_plus_model.predict(X_test_subset_plus)\n",
    "y_test_tokenized_plus_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">Metrics (model evaluation)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Print BEHRT (micro/samples) metrics``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a \"micro(sample)-average\": quantifying score on all classes jointly\n",
    "# precision and recall\n",
    "precision_micro, recall_micro, _ = PRC(\n",
    "    y_test_tokenized.ravel(),\n",
    "    y_test_tokenized_plus_pred.ravel()\n",
    ")\n",
    "\n",
    "\n",
    "# average precision score\n",
    "aps_samples = APS(\n",
    "    y_test_tokenized,\n",
    "    y_test_tokenized_plus_pred,\n",
    "    average=\"samples\"\n",
    ")\n",
    "\n",
    "# ROC curve and ROC area (Micro-averaged One-vs-Rest ROC AUC score)\n",
    "fpr_micro, tpr_micro, _ = roc_curve(\n",
    "    y_test_tokenized.ravel(),\n",
    "    y_test_tokenized_plus_pred.ravel()\n",
    ")\n",
    "area_micro = auc(fpr_micro, tpr_micro)\n",
    "\n",
    "print('Average precission score:',\n",
    "      np.round(aps_samples,3)\n",
    ")\n",
    "print('ROC AUC:',\n",
    "      np.round(area_micro,3)\n",
    ")\n",
    "\n",
    "# add APS and ROC areato a df\n",
    "metrics_plus = pd.DataFrame(\n",
    "        {'metric': ['APS', 'AUC'],\n",
    "         'value': [aps_samples, area_micro]\n",
    "        }\n",
    "    )\n",
    "\n",
    "metrics_plus['seed'] = config.seed\n",
    "\n",
    "# export metrics to csv\n",
    "metrics_plus.to_csv('./results/ApsAucDownstreamExtra__base(Logistic)_los.csv', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Print ROC AUC curve by class``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the fpr, tpr, and roc_auc for all averaging strategies\n",
    "fpr, tpr, roc_auc = dict(), dict(), dict()\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_tokenized.ravel(), y_test_tokenized_plus_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "n_classes = len(set(y_union))\n",
    "target_names = ['class 0 (los <= 1 day)', 'class 1 (los <=3 days)', 'class 2 (los > 3 days)']\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "plt.plot(\n",
    "    fpr[\"micro\"],\n",
    "    tpr[\"micro\"],\n",
    "    label=f\"micro-average ROC curve (AUC = {roc_auc['micro']:.2f})\",\n",
    "    color=\"deeppink\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "\n",
    "colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "for class_id, color in zip(range(n_classes), colors):\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        y_test_tokenized[:, class_id],\n",
    "        y_test_tokenized_plus_pred[:, class_id],\n",
    "        name=f\"ROC curve for {target_names[class_id]}\",\n",
    "        color=color,\n",
    "        ax=ax,\n",
    "        #chance_level=True,\n",
    "    )\n",
    "    \n",
    "# random classifier\n",
    "ax.plot(\n",
    "    [0, 1],\n",
    "    [0, 1],\n",
    "    \"k--\",\n",
    "    color=\"black\",\n",
    "    linewidth=1,\n",
    "    label='random classifier'\n",
    ")\n",
    "\n",
    "_ = ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=\"Extension of Receiver Operating Characteristic\\nto One-vs-Rest multiclass\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
