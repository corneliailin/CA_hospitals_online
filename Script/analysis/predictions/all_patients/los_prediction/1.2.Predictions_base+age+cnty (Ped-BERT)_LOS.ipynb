{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main script for Prediction Task\n",
    "\n",
    "Modules: N/A <br>\n",
    "Author: Cornelia Ilin <br>\n",
    "Email: cilin@wisc.edu <br>\n",
    "Date created: June 8, 2022 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 1: Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import importlib\n",
    "import glob\n",
    "import re\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "#tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from dataclasses import dataclass\n",
    "\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "# sklearn and others\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score as APS\n",
    "from sklearn.metrics import roc_auc_score as ROC_AUC\n",
    "from sklearn.metrics import precision_recall_curve as PRC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from itertools import cycle\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# user defined\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../../')\n",
    "from embeddings import utils_dt_prep\n",
    "from  embeddings import utils_MLM\n",
    "from embeddings import utils_embeddings\n",
    "import utils_dt_prep_pred_all\n",
    "import utils_classifier\n",
    "import utils_classifier_plus\n",
    "import utils_eval_downstream\n",
    "\n",
    "from sklearn.metrics import average_precision_score as APS\n",
    "from sklearn.metrics import precision_recall_curve as PRC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from itertools import cycle\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 2.1: Set-up config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    MAX_LEN = 40\n",
    "    BATCH_SIZE = 32\n",
    "    PAT_MIN_LENGTH = 3 #minimum number of visits\n",
    "    DIAG_PER_VISIT = 3 #diagnosis per visit to consider\n",
    "    DIAG_LENGTH = 2 # how many digits from diagnosis code to consider\n",
    "    train_pct = 0.8\n",
    "    val_pct = 0.1\n",
    "    seed = [1235, 1789, 2134, 1455, 1112] #1235\n",
    "    KEYS_diag = ['diag']\n",
    "    KEYS_diag_age = ['diag', 'age']\n",
    "    KEYS_diag_cnty = ['diag', 'cnty']\n",
    "    KEYS_diag_age_cnty = ['diag', 'age', 'cnty']\n",
    "    top_diag=10 #top diagmosis based on rocauc or aps\n",
    "    draw_train_val_test = False\n",
    "    create_Xy=False\n",
    "    save_model=True\n",
    "    load_model=False\n",
    "    process_LOS = False\n",
    "    \n",
    "config = Config()\n",
    "config.seed = config.seed[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 2.2: Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dates(df):\n",
    "    ''' Add dates for year, month, day of birth for patient\n",
    "        Add dates for year, month, day of hospital visit for patient\n",
    "    '''\n",
    "    # define dates\n",
    "    dates = ['bthdate', 'admtdate']\n",
    "    \n",
    "    for col in dates:\n",
    "        # transform to string\n",
    "        df[col] = df[col].astype(str)\n",
    "        # make sure date is Pandas compatible\n",
    "        df[col] = pd.to_datetime(df[col], errors = 'coerce')\n",
    "\n",
    "    # define bth variable to be added (year, month, day of birth)\n",
    "    newvars = [['bthyear', 'bthmonth', 'bthday'],\n",
    "              ['admtyear', 'admtmonth', 'admtday']]\n",
    "    \n",
    "    for i in range(len(dates)):\n",
    "        # add bth year\n",
    "        df[newvars[i][0]] = pd.DatetimeIndex(df[dates[i]]).year\n",
    "        # add bth month\n",
    "        df[newvars[i][1]] = pd.DatetimeIndex(df[dates[i]]).month\n",
    "        # add bth date\n",
    "        df[newvars[i][2]] = pd.DatetimeIndex(df[dates[i]]).day\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 2.3: Define working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_pdd_dir = 'C:/Users/cilin/Research/CA_hospitals/Input/final_data/health/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 3: Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``los``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.process_LOS:\n",
    "    # read uncleaned PDD data\n",
    "    df_pdd = pd.read_csv(raw_pdd_dir + 'PDD_los.csv')\n",
    "    df_pdd.rename(columns={'rln':'rlnI_updated'}, inplace=True)\n",
    "    \n",
    "    # add dates\n",
    "    df_pdd = add_dates(df_pdd)\n",
    "    # keep only iacf bthyear >=1991\n",
    "    df_pdd = df_pdd[df_pdd.bthyear.ge(1991.)]\n",
    "\n",
    "    # reset index\n",
    "    df_pdd.reset_index(\n",
    "        drop=True,\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    # save data\n",
    "    df_pdd['data_source'] = 'PDD'\n",
    "    df_pdd.rename(columns={'rln':'rlnI_updated'}, inplace=True)\n",
    "    cols = ['rlnI_updated', 'admtdate', 'bthdate', 'data_source','los', 'los_adj']\n",
    "    df_pdd[cols].to_csv(raw_pdd_dir + 'pdd_los.csv')\n",
    "    \n",
    "else:\n",
    "  # load data  \n",
    "    df_pdd = pd.read_csv(raw_pdd_dir + 'pdd_los.csv')\n",
    "    \n",
    "df_pdd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``all health data``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_dt_prep)\n",
    "# read medical records for all patients with SSN and birth records\n",
    "df_init = utils_dt_prep.read_data_bpe(keep_all_cols=True)\n",
    "\n",
    "# print shapes and head\n",
    "print('Unique patients ', df_init.rlnI_updated.nunique())\n",
    "print('Number of encounters (shape of data) ', df_init.shape)\n",
    "df_init.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``merge LOS``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with df \n",
    "df_init2 = df_init.merge(\n",
    "    df_pdd,\n",
    "    on = ['rlnI_updated', 'admtdate', 'bthdate','data_source'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print('Shape of df_init after LOS merge', df_init.shape) #why the difference to above?\n",
    "\n",
    "# set ER LOS to 0\n",
    "df_init2['los'] = np.where((df_init2.data_source.eq('EDD')), 0, df_init2.los)\n",
    "\n",
    "# from birth data, if admtdate=bthdate set los to 0 (mean is 3.59, 75% is 3.0)\n",
    "df_init2['los'] = np.where((df_init2.data_source.eq('Birth')) & (df_init2.admtdate.eq(df_init2.bthdate)), 0, df_init2.lenstayI)\n",
    "\n",
    "df_init2['los2'] = np.where(df_init2.los.isna(), 0, df_init2.los)\n",
    "\n",
    "# set PDD LOS to LOS (no NAN values found). some PDD LOS have values of 0, which means the patient was discarged the same day\n",
    "\n",
    "# keep only cols of interest\n",
    "columns = [\n",
    "'rlnI_updated', 'bthdateI', 'bthyearI', 'cntyresI', 'cntyresI_name',\n",
    "'pm25I', 'wfeI', 'sexI', 'raceI', \n",
    "'patcnty', 'admtdate', 'admtyear', 'admtmonth',\n",
    "'raceM', 'meduc', 'precare', 'visitsM_9mpp', 'visitsM_1ypp', 'visitsI_1yol',\n",
    "'bthresmb_name', 'prevsts',\n",
    "'diag00', 'diag01', 'diag02', 'diag03', 'diag04', 'data_source', 'data_source2', 'los', 'lenstayI', 'los2'\n",
    "]\n",
    "\n",
    "df_init2 = df_init2[columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``drop observations and add features``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_dt_prep)\n",
    "print('Unique patients before preprocessing', df_init2.rlnI_updated.nunique())\n",
    "\n",
    "# drop pbervations\n",
    "%time df = utils_dt_prep.drop_observations(df_init2, config.PAT_MIN_LENGTH)\n",
    "# add features, includes visit summary (for diag, age, cnty)\n",
    "%time df = utils_dt_prep.add_features(df, config.DIAG_PER_VISIT, config.DIAG_LENGTH)\n",
    "\n",
    "# print stats\n",
    "print('Unique patients after preprocessing', df.rlnI_updated.nunique())\n",
    "print('Number of encounters after preprocessing (shape of data) ', df.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``define multiclass task``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['los_bins'] = np.where(df.los2.le(1), 0,\n",
    "                          np.where(df.los2.le(3), 1, 2))\n",
    "df.los_bins.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``create train, val, and test datasets``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.draw_train_val_test:\n",
    "    # find unique rlnIs in df\n",
    "    rlnIs = df.rlnI_updated.unique()\n",
    "\n",
    "    # split rlnIs into training, val, and test\n",
    "    np.random.seed(config.seed)\n",
    "    train_rlnI = np.random.choice(rlnIs, int(rlnIs.shape[0]*Config.train_pct), replace=False)\n",
    "    val_rlnI = np.random.choice(train_rlnI, int(train_rlnI.shape[0]*Config.val_pct), replace=False)\n",
    "    test_rlnI = list(set(rlnIs) - set(train_rlnI) - set (val_rlnI))\n",
    "    # save train_rlnIs, val_rlnIs, and test_rlnIs\n",
    "    np.save(\"../diagnosis_prediction/data/train_rlnI.npy\", train_rlnI)\n",
    "    np.save(\"../diagnosis_prediction/data/val_rlnI.npy\", val_rlnI)\n",
    "    np.save(\"../diagnosis_prediction/data/test_rlnI.npy\", test_rlnI)\n",
    "    \n",
    "else:\n",
    "    # load\n",
    "    train_rlnI = np.load(\"../diagnosis_prediction/data/train_rlnI.npy\", allow_pickle=\"TRUE\")\n",
    "    val_rlnI = np.load(\"../diagnosis_prediction/data/val_rlnI.npy\", allow_pickle=\"TRUE\")\n",
    "    test_rlnI = np.load(\"../diagnosis_prediction/data/test_rlnI.npy\", allow_pickle=\"TRUE\")\n",
    "    \n",
    "\n",
    "# pull train and test from df\n",
    "df_train = df[df.rlnI_updated.isin(train_rlnI)]\n",
    "df_val = df[df.rlnI_updated.isin(val_rlnI)]\n",
    "df_test = df[df.rlnI_updated.isin(test_rlnI)]\n",
    "\n",
    "print('Shape of df_train ', df_train.shape)\n",
    "print('Shape of df_val ', df_val.shape)\n",
    "print('Shape of df_test', df_test.shape)\n",
    "\n",
    "print('Unique patients in df_train ', df_train.rlnI_updated.nunique())\n",
    "print('Unique patients in df_val ', df_val.rlnI_updated.nunique())\n",
    "print('Unique patients in df_test ', df_test.rlnI_updated.nunique())\n",
    "\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_val.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">create input-output pairs</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_dt_prep_pred_all)\n",
    "df_train_in, df_train_out = utils_dt_prep_pred_all.input_output_pairs(df_train, config.PAT_MIN_LENGTH)\n",
    "df_val_in, df_val_out = utils_dt_prep_pred_all.input_output_pairs(df_val, config.PAT_MIN_LENGTH)\n",
    "df_test_in, df_test_out = utils_dt_prep_pred_all.input_output_pairs(df_test, config.PAT_MIN_LENGTH)\n",
    "\n",
    "# add df data to a dictionary and keep only cols of interest (used for Fairness tasks)\n",
    "cols = ['rlnI_updated', 'age', 'bthyearI', 'cntyresI', 'cntyresI_name', 'pm25I', 'wfeI', 'sexI', 'raceI', \n",
    "    'patcnty', 'raceM', 'meduc', 'precare', 'visitsM_9mpp', 'visitsM_1ypp', 'visitsI_1yol',\n",
    "    'bthresmb_name', 'prevsts']\n",
    "\n",
    "df_dict = {\n",
    "    'train_in': df_train_in[cols], 'val_in': df_val_in[cols], 'test_in': df_test_in[cols],\n",
    "    'train_out': df_train_out[cols], 'val_out': df_val_out[cols],'test_out': df_test_out[cols]\n",
    "}\n",
    "\n",
    "# drop duplicates\n",
    "for key in df_dict.keys():\n",
    "    df_dict[key].drop_duplicates(subset=['rlnI_updated'], inplace=True)\n",
    "    df_dict[key].reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print shapes\n",
    "for key in df_dict.keys():\n",
    "    print('Shape of df ' + key, df_dict[key].shape)\n",
    "    \n",
    "for key in df_dict.keys():\n",
    "    if 'out' in key:\n",
    "        print('Unique patients in df ' + key.split('_')[0], df_dict[key].rlnI_updated.nunique())\n",
    "        # drop rlnI_updated column\n",
    "        df_dict[key].drop(columns='rlnI_updated', inplace=True)\n",
    "    else:\n",
    "        df_dict[key].drop(columns='rlnI_updated', inplace=True)\n",
    "        \n",
    "# save data dict\n",
    "np.save('../diagnosis_prediction/data/df_dict.npy', df_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">create patient history for df_in data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(utils_dt_prep)\n",
    "\n",
    "print('df_train_in')\n",
    "print('-----------')\n",
    "%time hist_dict_train_in = utils_dt_prep.add_history(df_train_in)\n",
    "\n",
    "print('df_train_in')\n",
    "print('-----------')\n",
    "%time hist_dict_val_in = utils_dt_prep.add_history(df_val_in)\n",
    "\n",
    "print('\\ndf_test_in')\n",
    "print('-----------')\n",
    "%time hist_dict_test_in = utils_dt_prep.add_history(df_test_in)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print example patient in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_in[df_train_in.rlnI_updated.eq('00003PWWP')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_out[df_train_out.rlnI_updated.eq('00003PWWP')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Step 5: Create vocab used in MLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">import data used in MLM</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mlm = np.load(\"../../../embeddings/data/X.npy\", allow_pickle=\"TRUE\").item()\n",
    "\n",
    "print('X', X_mlm.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">load vocab used in MLM</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load vect layer\n",
    "vect_layer = {}\n",
    "for key in config.KEYS_diag_age_cnty:\n",
    "    vect_layer[key] = tf.keras.models.load_model('../../../embeddings/vectorizers/vect_layer_'+key)\n",
    "    vect_layer[key] = vect_layer[key].layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mask token id for masked language model\n",
    "mask_token_id = vect_layer['diag']([\"[MASK]\"]).numpy()[0][0]\n",
    "print('ID of masked token', mask_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">Create id2token and token2id mappings</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty dict\n",
    "id2token = {}\n",
    "token2id = {}\n",
    "\n",
    "for key in config.KEYS_diag_age_cnty:\n",
    "    id2token[key] = dict(enumerate(vect_layer[key].get_vocabulary()))\n",
    "    token2id[key] = {y: x for x, y in id2token[key].items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 6: Encode downstream data based on MLM vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">Create features and labels</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(config.seed)\n",
    "# create empty dict\n",
    "X_train = {}\n",
    "X_val = {}\n",
    "X_test = {}\n",
    "\n",
    "# add key and value for each feature\n",
    "for key in config.KEYS_diag_age_cnty:\n",
    "    X_train[key] = hist_dict_train_in[key]['pat_'+key+'_hist'].values\n",
    "    X_val[key] = hist_dict_val_in[key]['pat_'+key+'_hist'].values\n",
    "    X_test[key] = hist_dict_test_in[key]['pat_'+key+'_hist'].values\n",
    "\n",
    "# create outcome for each patient\n",
    "y_train = df_train_out.los_bins # predict los\n",
    "y_val = df_val_out.los_bins # predict los\n",
    "y_test = df_test_out.los_bins # predict los\n",
    "\n",
    "\n",
    "## find out examples by class\n",
    "for idx in range(3):\n",
    "    class_pct_train = y_train[y_train.eq(idx)].shape[0]\n",
    "    print('Class ' + str(idx) + ' pct in train', class_pct_train)\n",
    "for idx in range(3):\n",
    "    class_pct_val = y_val[y_val.eq(idx)].shape[0]\n",
    "    print('Class ' + str(idx) + ' pct in train', class_pct_val)\n",
    "for idx in range(3):\n",
    "    class_pct_test = y_test[y_test.eq(idx)].shape[0]\n",
    "    print('Class ' + str(idx) + ' pct in test', class_pct_test)\n",
    "\n",
    "## downsample - randomly exclude examples from the majority class (class 0)\n",
    "idx_y_train_is0 = np.where(y_train.eq(0))[0] #indexes where y_train is class 0\n",
    "idx_y_train_is1 = np.where(y_train.eq(1))[0]\n",
    "idx_y_train_is2 = np.where(y_train.eq(2))[0]\n",
    "idx_train_0_rnd = np.random.choice(idx_y_train_is0, int((y_train[y_train.eq(1)].shape[0]+y_train[y_train.eq(2)].shape[0])/2)) # create the average of the two other classes\n",
    "idx_train_all = np.array(list(idx_train_0_rnd) + list(idx_y_train_is1) + list(idx_y_train_is2))\n",
    "np.random.shuffle(idx_train_all)\n",
    "y_train = y_train[idx_train_all]\n",
    "\n",
    "idx_y_val_is0 = np.where(y_val.eq(0))[0] #indexes where y_train is class 0\n",
    "idx_y_val_is1 = np.where(y_val.eq(1))[0]\n",
    "idx_y_val_is2 = np.where(y_val.eq(2))[0]\n",
    "idx_val_0_rnd = np.random.choice(idx_y_val_is0, int((y_val[y_val.eq(1)].shape[0]+y_val[y_val.eq(2)].shape[0])/2)) # create the average of the two other classes\n",
    "idx_val_all = np.array(list(idx_val_0_rnd) + list(idx_y_val_is1) + list(idx_y_val_is2))\n",
    "np.random.shuffle(idx_val_all)\n",
    "y_val = y_val[idx_val_all]\n",
    "\n",
    "idx_y_test_is0 = np.where(y_test.eq(0))[0]\n",
    "idx_y_test_is1 = np.where(y_test.eq(1))[0]\n",
    "idx_y_test_is2 = np.where(y_test.eq(2))[0]\n",
    "idx_test_0_rnd = np.random.choice(idx_y_test_is0, int((y_test[y_test.eq(1)].shape[0]+y_test[y_test.eq(2)].shape[0])/2)) # create the average of the two other classes\n",
    "idx_test_all = np.array(list(idx_test_0_rnd) + list(idx_y_test_is1) + list(idx_y_test_is2))\n",
    "np.random.shuffle(np.array(idx_test_all))\n",
    "y_test = y_test[idx_test_all]\n",
    "\n",
    "# X\n",
    "for key in config.KEYS_diag_age_cnty:\n",
    "    X_train[key] = X_train[key][idx_train_all]\n",
    "    X_val[key] = X_val[key][idx_val_all]\n",
    "    X_test[key] = X_test[key][idx_test_all]\n",
    "    \n",
    "# redefine df_dictionary\n",
    "for key in df_dict:\n",
    "    if key.startswith('train'):\n",
    "        df_dict[key] = df_dict[key].iloc[idx_train_all, :].reset_index(drop=True)\n",
    "    if key.startswith('val'):\n",
    "        df_dict[key] = df_dict[key].iloc[idx_val_all, :].reset_index(drop=True)\n",
    "    if key.startswith('test'):\n",
    "        df_dict[key] = df_dict[key].iloc[idx_test_all, :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">Encode features (train data)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty dict\n",
    "X_train_tokenized = {}\n",
    "X_val_tokenized = {}\n",
    "X_test_tokenized = {}\n",
    "\n",
    "for key in config.KEYS_diag_age_cnty:\n",
    "    X_train_tokenized[key] = utils_dt_prep.encode(vect_layer[key], X_train[key])\n",
    "    X_val_tokenized[key] = utils_dt_prep.encode(vect_layer[key], X_val[key])\n",
    "    X_test_tokenized[key] = utils_dt_prep.encode(vect_layer[key], X_test[key])\n",
    "\n",
    "# print shape\n",
    "print('Shape of X_train_tokenized ', X_train_tokenized['diag'].shape)\n",
    "print('Shape of X_val_tokenized ', X_val_tokenized['diag'].shape)\n",
    "print('Shape of X_test_tokenized ', X_test_tokenized['age'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">Encode outcomes (test data)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# union of train and test\n",
    "y_union = np.union1d(y_train, y_val).tolist()\n",
    "y_union = np.union1d(y_union, y_test).tolist()\n",
    "y_union_tokenized = y_union\n",
    "\n",
    "# train\n",
    "y_train_tokenized = pd.get_dummies(y_train, drop_first=False).reindex(columns = y_union_tokenized, fill_value=0)\n",
    "y_train_tokenized_cols = np.array(y_train_tokenized.columns)\n",
    "y_train_tokenized = y_train_tokenized.to_numpy()\n",
    "\n",
    "# val\n",
    "y_val_tokenized = pd.get_dummies(y_val, drop_first=False).reindex(columns = y_union_tokenized, fill_value=0)\n",
    "y_val_tokenized_cols = np.array(y_val_tokenized.columns)\n",
    "y_val_tokenized = y_val_tokenized.to_numpy()\n",
    "\n",
    "# test\n",
    "y_test_tokenized = pd.get_dummies(y_test, drop_first=False).reindex(columns = y_union_tokenized, fill_value=0)\n",
    "y_test_tokenized_cols = np.array(y_test_tokenized.columns)\n",
    "y_test_tokenized = y_test_tokenized.to_numpy()\n",
    "\n",
    "print('Shape y_train_tokenized ', y_train_tokenized.shape)\n",
    "print('Shape y_val_tokenized ', y_val_tokenized.shape)\n",
    "print('Shape y_test_tokenized ', y_test_tokenized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect non-encoded and encoded histories and outcome in next visit for the first patient in my training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient history\n",
    "for key in config.KEYS_diag_age_cnty:\n",
    "    print(key, 'nenc: ', X_train[key][0])\n",
    "    print(key, 'enc: ', X_train_tokenized[key][0])\n",
    "    print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patient outcome in the next visit (first 20)\n",
    "y_train_tokenized[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tokenized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:orange\">!! Decide what embeddings you will use</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = config.KEYS_diag_age_cnty\n",
    "\n",
    "# define subset of X_train_tokenized\n",
    "X_train_tokenized_subset = {}\n",
    "for key in keys:\n",
    "    X_train_tokenized_subset[key] = X_train_tokenized[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = config.KEYS_diag_age_cnty\n",
    "\n",
    "# define subset of X_train_tokenized\n",
    "X_val_tokenized_subset = {}\n",
    "for key in keys:\n",
    "    X_val_tokenized_subset[key] = X_val_tokenized[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = config.KEYS_diag_age_cnty\n",
    "# other options are config.KEYS_diag_seg_pos_age_zip, config.KEYS_diag_seg_pos\n",
    "\n",
    "# define subset of X_train_tokenized\n",
    "X_test_tokenized_subset = {}\n",
    "for key in keys:\n",
    "    X_test_tokenized_subset[key] = X_test_tokenized[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">Convert train and test subsets to tensors</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(config.seed)\n",
    "\n",
    "# create sample_weights (this is how the MLM was trained)\n",
    "sample_weights_train = np.ones(y_train_tokenized.shape[0])\n",
    "\n",
    "train_tensor = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_train_tokenized_subset, y_train_tokenized, sample_weights_train)))\n",
    "train_tensor = train_tensor.shuffle(1000).batch(config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(config.seed)\n",
    "\n",
    "# create sample_weights (this is how the MLM was trained)\n",
    "sample_weights_val = np.ones(y_val_tokenized.shape[0])\n",
    "\n",
    "val_tensor = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_val_tokenized_subset, y_val_tokenized, sample_weights_val)))\n",
    "val_tensor = val_tensor.shuffle(1000).batch(config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(config.seed)\n",
    "\n",
    "# create sample_weights (this is how the MLM was trained)\n",
    "sample_weights_test = np.ones(y_test_tokenized.shape[0])\n",
    "\n",
    "test_tensor = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_test_tokenized_subset, y_test_tokenized, sample_weights_test)))\n",
    "test_tensor = test_tensor.shuffle(1000).batch(config.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 7: Next visit LOS (downstream task)\n",
    "\n",
    "I will use my self-supervised MLM model on a downstream task of next visit diagnosis classification.\n",
    "To do this, I will import the trained MLM model, and I will create a multilabel classifier by adding a pooling layer and a Dense layer on top of the pretrained MLM features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``import MLM model``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained bert model\n",
    "mlm_model = keras.models.load_model(\n",
    "    \"../../../embeddings/bert_mlm_age_cnty.h5\", custom_objects={\"MaskedLanguageModel\": utils_MLM.MaskedLanguageModel}\n",
    ")\n",
    "\n",
    "# remove the classification layer\n",
    "pretrained_bert_model = tf.keras.Model(\n",
    "    mlm_model.input, mlm_model.get_layer(\"encoder_0/ffn_layernormalization\").output\n",
    ")\n",
    "\n",
    "pretrained_bert_model.trainable = True\n",
    "\n",
    "# Freeze it\n",
    "#pretrained_bert_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "temp =  train_tensor.take(10)\n",
    "temp_embeddings = pretrained_bert_model.predict(temp)\n",
    "temp_embeddings.shape\n",
    "\n",
    "\n",
    "token_emb = mlm_model.get_layer(\"encoder_0/ffn_layernormalization\").output\n",
    "token_emb_average = tf.keras.layers.GlobalAveragePooling1D()(token_emb)\n",
    "token_emb_averageg\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">extract token (patient visit) embeddings</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this only prints the output of the encoder_0/ffn_layernormalization of the mlm model\n",
    "#train_token_embeddings = pretrained_bert_model.predict(X_train_tokenized)\n",
    "#train_token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this only prints the output of the encoder_0/ffn_layernormalization of the mlm model\n",
    "#test_token_embeddings = pretrained_bert_model.predict(X_test_tokenized)\n",
    "#test_token_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">extract sentence (patient history) embeddings</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_pool_embeddings = tf.keras.layers.GlobalAveragePooling1D()(train_token_embeddings).numpy()\n",
    "#train_pool_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_pool_embeddings = tf.keras.layers.GlobalAveragePooling1D()(test_token_embeddings).numpy()\n",
    "#test_pool_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Downstream task``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">calculate initial bias</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "calc_init_bias = False\n",
    "if calc_init_bias:\n",
    "    importlib.reload(utils_classifier) \n",
    "    bias_init, class_weight = utils_classifier.initial_weights(vect_layer, df, y_union, y_train_tokenized_cols)\n",
    "    print('Length of initial bias', len(bias_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">add early stopping</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = True\n",
    "if early_stopping:\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    verbose=1,\n",
    "    patience=2,\n",
    "    mode='min',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">define model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(utils_classifier) \n",
    "classifier_model = utils_classifier.classifier_model(\n",
    "    pretrained_bert_model,\n",
    "    y_train_tokenized.shape[1],\n",
    "    keys,\n",
    "    #bias_init\n",
    ")\n",
    "classifier_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">fit model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the classifier with unfrozen BERT MLM layers\n",
    "hist = classifier_model.fit(\n",
    "    train_tensor,\n",
    "    validation_data=val_tensor,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">plot loss and accuracy</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab history\n",
    "history = hist.history\n",
    "\n",
    "# plot loss for train and validation\n",
    "fig = plt.figure(figsize=(12, 2))\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "plt.plot(history['loss'], lw=2, color='darkgoldenrod')\n",
    "plt.plot(history['val_loss'], lw=2, color='indianred')\n",
    "plt.legend(['Train', 'Validation'], fontsize=10)\n",
    "#plt.ylim(0,0.2)\n",
    "ax.set_xlabel('Epochs', size=10)\n",
    "ax.set_title('Loss');\n",
    "\n",
    "# plot accuracy for train and validation\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "plt.plot(history['accuracy'], lw=2, color='darkgoldenrod')\n",
    "plt.plot(history['val_accuracy'], lw=2, color='indianred')\n",
    "plt.legend(['Train', 'Validation'], fontsize=10)\n",
    "#plt.ylim(0.7,1)\n",
    "ax.set_xlabel('Epochs', size=10)\n",
    "ax.set_title('Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">save or load model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.save_model:\n",
    "    classifier_model.save(\"./cls_model_base+age+cnty(Ped-BERT)_los.h5\", include_optimizer=False)\n",
    "if config.load_model:\n",
    "    classifier_model = keras.models.load_model(\"./cls_model_base+age+cnty(Ped-BERT)_los.h5\", custom_objects={\"MaskedLanguageModel\": utils_MLM.MaskedLanguageModel})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">predictions  (on test data)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_tokenized_pred = classifier_model.predict(X_train_tokenized_subset)\n",
    "#y_train_tokenized_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_tokenized_pred = classifier_model.predict(X_test_tokenized_subset)\n",
    "y_test_tokenized_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">Metrics (model evaluation)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Print BEHRT (micro/samples) metrics``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a \"micro(sample)-average\": quantifying score on all classes jointly\n",
    "# precision and recall\n",
    "precision_micro, recall_micro, _ = PRC(\n",
    "    y_test_tokenized.ravel(),\n",
    "    y_test_tokenized_pred.ravel()\n",
    ")\n",
    "\n",
    "\n",
    "# average precision score\n",
    "aps_samples = APS(\n",
    "    y_test_tokenized,\n",
    "    y_test_tokenized_pred,\n",
    "    average=\"samples\"\n",
    ")\n",
    "\n",
    "# ROC curve and ROC area (Micro-averaged One-vs-Rest ROC AUC score)\n",
    "fpr_micro, tpr_micro, _ = roc_curve(\n",
    "    y_test_tokenized.ravel(),\n",
    "    y_test_tokenized_pred.ravel()\n",
    ")\n",
    "area_micro = auc(fpr_micro, tpr_micro)\n",
    "\n",
    "print('Average precission score:',\n",
    "      np.round(aps_samples,3)\n",
    ")\n",
    "print('ROC AUC:',\n",
    "      np.round(area_micro,3)\n",
    ")\n",
    "\n",
    "# add APS and ROC areato a df\n",
    "temp_df = pd.DataFrame(\n",
    "        {'metric': ['APS', 'AUC'],\n",
    "         'value': [aps_samples, area_micro]\n",
    "        }\n",
    "    )\n",
    "\n",
    "temp_df['seed'] = config.seed\n",
    "\n",
    "# export metrics to csv\n",
    "temp_df.to_csv('./results/ApsAucDownstream__base+age+cnty(Ped-BERT)_los.csv', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Print ROC AUC curve by class``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the fpr, tpr, and roc_auc for all averaging strategies\n",
    "fpr, tpr, roc_auc = dict(), dict(), dict()\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_tokenized.ravel(), y_test_tokenized_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "n_classes = len(set(y_union))\n",
    "target_names = ['class 0 (los <= 1 day)', 'class 1 (los <=3 days)', 'class 2 (los > 3 days)']\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "plt.plot(\n",
    "    fpr[\"micro\"],\n",
    "    tpr[\"micro\"],\n",
    "    label=f\"micro-average ROC curve (AUC = {roc_auc['micro']:.2f})\",\n",
    "    color=\"deeppink\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "\n",
    "colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "for class_id, color in zip(range(n_classes), colors):\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        y_test_tokenized[:, class_id],\n",
    "        y_test_tokenized_pred[:, class_id],\n",
    "        name=f\"ROC curve for {target_names[class_id]}\",\n",
    "        color=color,\n",
    "        ax=ax,\n",
    "        #chance_level=True,\n",
    "    )\n",
    "    \n",
    "# random classifier\n",
    "ax.plot(\n",
    "    [0, 1],\n",
    "    [0, 1],\n",
    "    \"k--\",\n",
    "    color=\"black\",\n",
    "    linewidth=1,\n",
    "    label='random classifier'\n",
    ")\n",
    "\n",
    "_ = ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=\"Extension of Receiver Operating Characteristic\\nto One-vs-Rest multiclass\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "`FairAware tasks`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time= time.time()\n",
    "temp_df_test_out = df_dict['test_out'].copy()\n",
    "importlib.reload(utils_eval_downstream)\n",
    "\n",
    "temp_df_test_out = utils_eval_downstream.fairaware_cleaning(temp_df_test_out)\n",
    "utils_eval_downstream.fairaware_plots(\n",
    "    temp_df_test_out, y_test_tokenized_cols,\n",
    "    id2token, y_test_tokenized_pred, y_test_tokenized\n",
    ")\n",
    "\n",
    "# print execution time\n",
    "print('Execution time:', np.round((time.time()-start_time)/60, 2), 'minutes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "``downstream task + extra features``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">extract patient (sentence) embeddings from classifier_model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define embeddings model \n",
    "classifier_model_embed = tf.keras.Model(\n",
    "    classifier_model.input, classifier_model.get_layer(\"global_max_pooling1d\").output\n",
    ")\n",
    "\n",
    "# extract embeddings from classification model\n",
    "train_embeddings_pool = classifier_model_embed.predict(X_train_tokenized_subset)\n",
    "val_embeddings_pool = classifier_model_embed.predict(X_val_tokenized_subset)\n",
    "test_embeddings_pool = classifier_model_embed.predict(X_test_tokenized_subset)\n",
    "\n",
    "print('Shape of train:', train_embeddings_pool.shape)\n",
    "print('Shape of train:', val_embeddings_pool.shape)\n",
    "print('Shape of test:', test_embeddings_pool.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">create extra features</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(utils_classifier_plus) \n",
    "X_train_tokenized_subset_plus = utils_classifier_plus.create_extra_features(df_dict['train_in'], train_embeddings_pool)\n",
    "X_val_tokenized_subset_plus = utils_classifier_plus.create_extra_features(df_dict['val_in'], val_embeddings_pool)\n",
    "X_test_tokenized_subset_plus = utils_classifier_plus.create_extra_features(df_dict['test_in'], test_embeddings_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for columns that are extra between training and validation\n",
    "col_diff_train_val = np.setdiff1d(list(X_train_tokenized_subset_plus.columns), list(X_val_tokenized_subset_plus.columns))\n",
    "col_diff_train_val = list(col_diff_train_val)\n",
    "print('Columns difference train_val', col_diff_train_val)\n",
    "# drop column from X_train_tokenized_subset_plus\n",
    "X_train_tokenized_subset_plus.drop(columns=col_diff_train_val, inplace=True)\n",
    "\n",
    "## check for columns that are extra between training and test\n",
    "col_diff_train_test = np.setdiff1d(list(X_train_tokenized_subset_plus.columns), list(X_test_tokenized_subset_plus.columns))\n",
    "col_diff_train_test = list(col_diff_train_test)\n",
    "print('Columns difference train_test', col_diff_train_test)\n",
    "# drop column from X_train_tokenized_subset_plus\n",
    "X_train_tokenized_subset_plus.drop(columns=col_diff_train_test, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">convert train, val, and test sets to tensors</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(config.seed)\n",
    "\n",
    "train_plus_tensor = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_train_tokenized_subset_plus, y_train_tokenized)))\n",
    "train_plus_tensor = train_plus_tensor.shuffle(1000).batch(config.BATCH_SIZE)\n",
    "\n",
    "val_plus_tensor = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_val_tokenized_subset_plus, y_val_tokenized)))\n",
    "val_plus_tensor = val_plus_tensor.shuffle(1000).batch(config.BATCH_SIZE)\n",
    "\n",
    "test_plus_tensor = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_test_tokenized_subset_plus, y_test_tokenized)))\n",
    "test_plus_tensor = test_plus_tensor.shuffle(1000).batch(config.BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">define model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils_classifier_plus)\n",
    "classifier_plus_model = utils_classifier_plus.classifier_plus_model(\n",
    "    X_train_tokenized_subset_plus.shape[1],\n",
    "    y_train_tokenized.shape[1]\n",
    ")\n",
    "classifier_plus_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">fit model</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "hist = classifier_plus_model.fit(\n",
    "    train_plus_tensor,\n",
    "    validation_data=val_plus_tensor,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">plot loss and accuracy</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab history\n",
    "history = hist.history\n",
    "\n",
    "# plot loss for train and validation\n",
    "fig = plt.figure(figsize=(12, 2))\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "plt.plot(history['loss'], lw=2, color='darkgoldenrod')\n",
    "plt.plot(history['val_loss'], lw=2, color='indianred')\n",
    "plt.legend(['Train', 'Validation'], fontsize=10)\n",
    "#plt.ylim(0,0.2)\n",
    "ax.set_xlabel('Epochs', size=10)\n",
    "ax.set_title('Loss');\n",
    "\n",
    "# plot accuracy for train and validation\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "plt.plot(history['accuracy'], lw=2, color='darkgoldenrod')\n",
    "plt.plot(history['val_accuracy'], lw=2, color='indianred')\n",
    "plt.legend(['Train', 'Validation'], fontsize=10)\n",
    "#plt.ylim(0.7,1)\n",
    "ax.set_xlabel('Epochs', size=10)\n",
    "ax.set_title('Accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">save or load</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.save_model:\n",
    "    classifier_plus_model.save(\"./cls_model_plus_base+age+cnty(Ped-BERT)_los.h5\", include_optimizer=False)\n",
    "if config.load_model:\n",
    "    classifier_plus_model = keras.models.load_model(\"./cls_model_plus_base+age+cnty(Ped-BERT)_los.h5\", custom_objects={\"MaskedLanguageModel\": utils_MLM.MaskedLanguageModel})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">predictions  (on train and test data)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_tokenized_plus_pred = classifier_plus_model.predict(X_train_tokenized_subset_plus)\n",
    "#y_train_tokenized_plus_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_tokenized_plus_pred = classifier_plus_model.predict(X_test_tokenized_subset_plus)\n",
    "y_test_tokenized_plus_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:chocolate\">Metrics (model evaluation)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a \"micro(sample)-average\": quantifying score on all classes jointly\n",
    "# precision and recall\n",
    "precision_micro, recall_micro, _ = PRC(\n",
    "    y_test_tokenized.ravel(),\n",
    "    y_test_tokenized_plus_pred.ravel()\n",
    ")\n",
    "\n",
    "\n",
    "# average precision score\n",
    "aps_samples = APS(\n",
    "    y_test_tokenized,\n",
    "    y_test_tokenized_plus_pred,\n",
    "    average=\"samples\"\n",
    ")\n",
    "\n",
    "# ROC curve and ROC area (Micro-averaged One-vs-Rest ROC AUC score)\n",
    "fpr_micro, tpr_micro, _ = roc_curve(\n",
    "    y_test_tokenized.ravel(),\n",
    "    y_test_tokenized_plus_pred.ravel()\n",
    ")\n",
    "area_micro = auc(fpr_micro, tpr_micro)\n",
    "\n",
    "print('Average precission score:',\n",
    "      np.round(aps_samples,3)\n",
    ")\n",
    "print('ROC AUC:',\n",
    "      np.round(area_micro,3)\n",
    ")\n",
    "\n",
    "# add APS and ROC areato a df\n",
    "metrics_plus = pd.DataFrame(\n",
    "        {'metric': ['APS', 'AUC'],\n",
    "         'value': [aps_samples, area_micro]\n",
    "        }\n",
    "    )\n",
    "\n",
    "metrics_plus['seed'] = config.seed\n",
    "\n",
    "# export metrics to csv\n",
    "metrics_plus.to_csv('./results/ApsAucDownstreamExtra__base+age+cnty(Ped-BERT)_los.csv', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``Print ROC AUC curve by class``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the fpr, tpr, and roc_auc for all averaging strategies\n",
    "fpr, tpr, roc_auc = dict(), dict(), dict()\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_tokenized.ravel(), y_test_tokenized_plus_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "n_classes = len(set(y_union))\n",
    "target_names = ['class 0 (los <= 1 day)', 'class 1 (los <=3 days)', 'class 2 (los > 3 days)']\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "plt.plot(\n",
    "    fpr[\"micro\"],\n",
    "    tpr[\"micro\"],\n",
    "    label=f\"micro-average ROC curve (AUC = {roc_auc['micro']:.2f})\",\n",
    "    color=\"deeppink\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "\n",
    "colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "for class_id, color in zip(range(n_classes), colors):\n",
    "    RocCurveDisplay.from_predictions(\n",
    "        y_test_tokenized[:, class_id],\n",
    "        y_test_tokenized_plus_pred[:, class_id],\n",
    "        name=f\"ROC curve for {target_names[class_id]}\",\n",
    "        color=color,\n",
    "        ax=ax,\n",
    "        #chance_level=True,\n",
    "    )\n",
    "    \n",
    "# random classifier\n",
    "ax.plot(\n",
    "    [0, 1],\n",
    "    [0, 1],\n",
    "    \"k--\",\n",
    "    color=\"black\",\n",
    "    linewidth=1,\n",
    "    label='random classifier'\n",
    ")\n",
    "\n",
    "_ = ax.set(\n",
    "    xlabel=\"False Positive Rate\",\n",
    "    ylabel=\"True Positive Rate\",\n",
    "    title=\"Extension of Receiver Operating Characteristic\\nto One-vs-Rest multiclass\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
